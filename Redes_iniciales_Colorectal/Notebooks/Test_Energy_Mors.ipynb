{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6988d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Nets  import GetNeuralNetworkModel\n",
    "from StatsReadWrite import WeightQuantization, ActivationStats, CheckAccuracyAndLoss, QuantizationEffect, GetReadAndWrites\n",
    "from Training import GetDatasets, GetPilotNetDataset\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import VeryBadWords,FlipPatchBetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e042cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mask = load_obj('MoRS/Modelo3_mas_fallos_col_8_experimentos/mask/error_mask_0')\n",
    "locs = load_obj('MoRS/Modelo3_mas_fallos_col_8_experimentos/mask/locs_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589d42f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word_size  = 16\n",
    "afrac_size = 11\n",
    "aint_size  = 4\n",
    "wfrac_size = 11\n",
    "wint_size  = 4\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (227, 227), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'AlexNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a16df6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x KerasTensor(type_spec=TensorSpec(shape=(None, 227, 227, 3), dtype=tf.float32, name=None), name='lambda_1/TensorScatterUpdate:0', description=\"created by layer 'lambda_1'\")\n"
     ]
    }
   ],
   "source": [
    "activation_aging = [True]*11\n",
    "AlexNet = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                aging_active=activation_aging, word_size=word_size, frac_size=afrac_size,\n",
    "                               batch_size = testBatchSize)\n",
    "AlexNet.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model=AlexNet, frac_bits=wfrac_size, int_bits=wint_size)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "AlexNet.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "#loss,acc =AlexNet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c365d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0\n",
      "0                   input_1\n",
      "1                    lambda\n",
      "2                  lambda_1\n",
      "3                     Conv1\n",
      "4                  lambda_2\n",
      "5                     re_lu\n",
      "6       batch_normalization\n",
      "7                  lambda_3\n",
      "8                  lambda_4\n",
      "9             max_pooling2d\n",
      "10                 lambda_5\n",
      "11                    Conv2\n",
      "12                 lambda_6\n",
      "13                  re_lu_1\n",
      "14    batch_normalization_1\n",
      "15                 lambda_7\n",
      "16                 lambda_8\n",
      "17          max_pooling2d_1\n",
      "18                 lambda_9\n",
      "19                    Conv3\n",
      "20                lambda_10\n",
      "21                  re_lu_2\n",
      "22    batch_normalization_2\n",
      "23                lambda_11\n",
      "24                lambda_12\n",
      "25                    Conv4\n",
      "26                lambda_13\n",
      "27                  re_lu_3\n",
      "28    batch_normalization_3\n",
      "29                lambda_14\n",
      "30                lambda_15\n",
      "31                    Conv5\n",
      "32                lambda_16\n",
      "33                  re_lu_4\n",
      "34    batch_normalization_4\n",
      "35                lambda_17\n",
      "36                lambda_18\n",
      "37          max_pooling2d_2\n",
      "38                lambda_19\n",
      "39                  flatten\n",
      "40                    dense\n",
      "41                lambda_20\n",
      "42                  re_lu_5\n",
      "43                  dropout\n",
      "44                lambda_21\n",
      "45                  dense_1\n",
      "46                lambda_22\n",
      "47                  re_lu_6\n",
      "48                dropout_1\n",
      "49                lambda_23\n",
      "50                  dense_2\n",
      "51                lambda_24\n",
      "52  tf.compat.v1.nn.softmax\n",
      "53                lambda_25          0      1      2\n",
      "0      NaN    NaN    NaN\n",
      "1    227.0  227.0    3.0\n",
      "2    227.0  227.0    3.0\n",
      "3    227.0  227.0    3.0\n",
      "4     55.0   55.0   96.0\n",
      "5     55.0   55.0   96.0\n",
      "6     55.0   55.0   96.0\n",
      "7     55.0   55.0   96.0\n",
      "8     55.0   55.0   96.0\n",
      "9     55.0   55.0   96.0\n",
      "10    27.0   27.0   96.0\n",
      "11    27.0   27.0   96.0\n",
      "12    27.0   27.0  256.0\n",
      "13    27.0   27.0  256.0\n",
      "14    27.0   27.0  256.0\n",
      "15    27.0   27.0  256.0\n",
      "16    27.0   27.0  256.0\n",
      "17    27.0   27.0  256.0\n",
      "18    13.0   13.0  256.0\n",
      "19    13.0   13.0  256.0\n",
      "20    13.0   13.0  384.0\n",
      "21    13.0   13.0  384.0\n",
      "22    13.0   13.0  384.0\n",
      "23    13.0   13.0  384.0\n",
      "24    13.0   13.0  384.0\n",
      "25    13.0   13.0  384.0\n",
      "26    13.0   13.0  384.0\n",
      "27    13.0   13.0  384.0\n",
      "28    13.0   13.0  384.0\n",
      "29    13.0   13.0  384.0\n",
      "30    13.0   13.0  384.0\n",
      "31    13.0   13.0  384.0\n",
      "32    13.0   13.0  256.0\n",
      "33    13.0   13.0  256.0\n",
      "34    13.0   13.0  256.0\n",
      "35    13.0   13.0  256.0\n",
      "36    13.0   13.0  256.0\n",
      "37    13.0   13.0  256.0\n",
      "38     6.0    6.0  256.0\n",
      "39     6.0    6.0  256.0\n",
      "40  9216.0    NaN    NaN\n",
      "41  4096.0    NaN    NaN\n",
      "42  4096.0    NaN    NaN\n",
      "43  4096.0    NaN    NaN\n",
      "44  4096.0    NaN    NaN\n",
      "45  4096.0    NaN    NaN\n",
      "46  4096.0    NaN    NaN\n",
      "47  4096.0    NaN    NaN\n",
      "48  4096.0    NaN    NaN\n",
      "49  4096.0    NaN    NaN\n",
      "50  4096.0    NaN    NaN\n",
      "51     8.0    NaN    NaN\n",
      "52     8.0    NaN    NaN\n",
      "53     8.0    NaN    NaN\n",
      "                 layer_name       h      w     ch\n",
      "0                   input_1     NaN    NaN    NaN\n",
      "1                    lambda   227.0  227.0    3.0\n",
      "2                  lambda_1   227.0  227.0    3.0\n",
      "3                     Conv1   227.0  227.0    3.0\n",
      "4                  lambda_2    55.0   55.0   96.0\n",
      "5                     re_lu    55.0   55.0   96.0\n",
      "6       batch_normalization    55.0   55.0   96.0\n",
      "7                  lambda_3    55.0   55.0   96.0\n",
      "8                  lambda_4    55.0   55.0   96.0\n",
      "9             max_pooling2d    55.0   55.0   96.0\n",
      "10                 lambda_5    27.0   27.0   96.0\n",
      "11                    Conv2    27.0   27.0   96.0\n",
      "12                 lambda_6    27.0   27.0  256.0\n",
      "13                  re_lu_1    27.0   27.0  256.0\n",
      "14    batch_normalization_1    27.0   27.0  256.0\n",
      "15                 lambda_7    27.0   27.0  256.0\n",
      "16                 lambda_8    27.0   27.0  256.0\n",
      "17          max_pooling2d_1    27.0   27.0  256.0\n",
      "18                 lambda_9    13.0   13.0  256.0\n",
      "19                    Conv3    13.0   13.0  256.0\n",
      "20                lambda_10    13.0   13.0  384.0\n",
      "21                  re_lu_2    13.0   13.0  384.0\n",
      "22    batch_normalization_2    13.0   13.0  384.0\n",
      "23                lambda_11    13.0   13.0  384.0\n",
      "24                lambda_12    13.0   13.0  384.0\n",
      "25                    Conv4    13.0   13.0  384.0\n",
      "26                lambda_13    13.0   13.0  384.0\n",
      "27                  re_lu_3    13.0   13.0  384.0\n",
      "28    batch_normalization_3    13.0   13.0  384.0\n",
      "29                lambda_14    13.0   13.0  384.0\n",
      "30                lambda_15    13.0   13.0  384.0\n",
      "31                    Conv5    13.0   13.0  384.0\n",
      "32                lambda_16    13.0   13.0  256.0\n",
      "33                  re_lu_4    13.0   13.0  256.0\n",
      "34    batch_normalization_4    13.0   13.0  256.0\n",
      "35                lambda_17    13.0   13.0  256.0\n",
      "36                lambda_18    13.0   13.0  256.0\n",
      "37          max_pooling2d_2    13.0   13.0  256.0\n",
      "38                lambda_19     6.0    6.0  256.0\n",
      "39                  flatten     6.0    6.0  256.0\n",
      "40                    dense  9216.0    NaN    NaN\n",
      "41                lambda_20  4096.0    NaN    NaN\n",
      "42                  re_lu_5  4096.0    NaN    NaN\n",
      "43                  dropout  4096.0    NaN    NaN\n",
      "44                lambda_21  4096.0    NaN    NaN\n",
      "45                  dense_1  4096.0    NaN    NaN\n",
      "46                lambda_22  4096.0    NaN    NaN\n",
      "47                  re_lu_6  4096.0    NaN    NaN\n",
      "48                dropout_1  4096.0    NaN    NaN\n",
      "49                lambda_23  4096.0    NaN    NaN\n",
      "50                  dense_2  4096.0    NaN    NaN\n",
      "51                lambda_24     8.0    NaN    NaN\n",
      "52  tf.compat.v1.nn.softmax     8.0    NaN    NaN\n",
      "53                lambda_25     8.0    NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "input_shape = []\n",
    "layer_name = []\n",
    "for index, layer in enumerate(AlexNet.layers):\n",
    "    layer_name.append(layer.name)\n",
    "    input_shape.append(layer.input_shape[1:])\n",
    "    # print(index,layer.name)\n",
    "    # print(index,layer.input_shape[1:])\n",
    "\n",
    "df_layer_name = pd.DataFrame(layer_name)\n",
    "df_layer_size = pd.DataFrame(input_shape)\n",
    "print(df_layer_name,df_layer_size)\n",
    "result = pd.concat([df_layer_name,df_layer_size], axis=1, join='outer')\n",
    "result.columns =['layer_name', 'h','w','ch']\n",
    "result.to_excel('AlexNet_shape_layers.xlsx',  index=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c06f851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network AlexNet\n",
      "[0, 3, 9, 11, 17, 19, 25, 31, 37, 40, 45, 50] [0, 3, 9, 11, 17, 19, 25, 31, 37, 40, 45, 50]\n",
      "addresses_entrada 1048576\n",
      "capas de escrituras\n",
      " capa, tamaño InputLayer 154587\n",
      "suma de las escrituras [0 0 0 ... 0 0 0]\n",
      "escrituras bloque de 16 9661.6875\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas.......................................... (None, 227, 227, 3)\n",
      " capa, tamaño Conv2D 154587\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 9661.6875\n",
      "padding................ valid\n",
      "dentro de valid\n",
      "layer.strides (4, 4)\n",
      "recorrido del kernel total y 55\n",
      "recorrido del kernel total x 3025\n",
      "Kernel_Y1 220\n",
      "Kernel_Y2 231\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño MaxPooling2D 69984\n",
      "suma de las escrituras [1 1 1 ... 1 1 1]\n",
      "escrituras bloque de 16 4374.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas.......................................... (None, 27, 27, 96)\n",
      " capa, tamaño Conv2D 69984\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 26244.0\n",
      "padding................ same\n",
      "dentro del elese por tanto padding!=valid\n",
      "layer.strides (1, 1)\n",
      "recorrido del kernel total y 27\n",
      "recorrido del kernel total x 729\n",
      "Kernel_Y1 27\n",
      "Kernel_Y2 32\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño MaxPooling2D 43264\n",
      "suma de las escrituras [2 2 2 ... 2 2 2]\n",
      "escrituras bloque de 16 2704.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas.......................................... (None, 13, 13, 256)\n",
      " capa, tamaño Conv2D 43264\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 43264.0\n",
      "padding................ same\n",
      "dentro del elese por tanto padding!=valid\n",
      "layer.strides (1, 1)\n",
      "recorrido del kernel total y 13\n",
      "recorrido del kernel total x 169\n",
      "Kernel_Y1 13\n",
      "Kernel_Y2 16\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 64896\n",
      "suma de las escrituras [3 3 3 ... 2 2 2]\n",
      "escrituras bloque de 16 4056.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas.......................................... (None, 13, 13, 384)\n",
      " capa, tamaño Conv2D 64896\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 97344.0\n",
      "padding................ same\n",
      "dentro del elese por tanto padding!=valid\n",
      "layer.strides (1, 1)\n",
      "recorrido del kernel total y 13\n",
      "recorrido del kernel total x 169\n",
      "Kernel_Y1 13\n",
      "Kernel_Y2 14\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño MaxPooling2D 9216\n",
      "suma de las escrituras [4 4 4 ... 4 4 4]\n",
      "escrituras bloque de 16 576.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Dense\n",
      "FC Dense\n",
      "input_size 9216\n",
      "output_size 4096\n",
      "lecturas bloque de 16 576.0\n",
      "actual_values en Dense [29 29 29 ... 43 43 43]\n",
      "data_read_write_Reads [147485 147485 147485 ...      0      0      0]\n",
      "suma diccionario d electura 1361414811\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Dense 4096\n",
      "suma de las escrituras [5 5 5 ... 5 5 5]\n",
      "escrituras bloque de 16 256.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Dense\n",
      "FC Dense\n",
      "input_size 4096\n",
      "output_size 8\n",
      "lecturas bloque de 16 256.0\n",
      "actual_values en Dense [147485 147485 147485 ... 147499 147499 147499]\n",
      "data_read_write_Reads [151581 151581 151581 ...      0      0      0]\n",
      "suma diccionario d electura 1378192027\n",
      "                  Capa  Read_write_block\n",
      "0     InputLayer_write         9661.6875\n",
      "1          Conv2D_read         9661.6875\n",
      "2   MaxPooling2D_write         4374.0000\n",
      "3          Conv2D_read        26244.0000\n",
      "4   MaxPooling2D_write         2704.0000\n",
      "5          Conv2D_read        43264.0000\n",
      "6         Conv2D_write         4056.0000\n",
      "7          Conv2D_read        97344.0000\n",
      "8   MaxPooling2D_write          576.0000\n",
      "9           Dense_read          576.0000\n",
      "10         Dense_write          256.0000\n",
      "11          Dense_read          256.0000\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'read_write_blocks_testAlexNet.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m samples      \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#Numero de imagenes\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Sin Power Gating:\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m Data         \u001b[38;5;241m=\u001b[39m \u001b[43mGetReadAndWrites\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAlexNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mIndices\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mCNN_gating\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnetwork_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlexNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m stats        \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLecturas\u001b[39m\u001b[38;5;124m'\u001b[39m: Data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReads\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEscrituras\u001b[39m\u001b[38;5;124m'\u001b[39m: Data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrites\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m      9\u001b[0m Baseline_Acceses   \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stats)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\StatsReadWrite.py:701\u001b[0m, in \u001b[0;36mGetReadAndWrites\u001b[1;34m(network, layer_indices, addresses, samples, CNN_gating, network_name)\u001b[0m\n\u001b[0;32m    699\u001b[0m \tdf_Block\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x: [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor: red\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_Block[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor: black\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    700\u001b[0m \t\u001b[38;5;28mprint\u001b[39m(df_Block)\n\u001b[1;32m--> 701\u001b[0m \t\u001b[43mdf_Block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread_write_blocks_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnetwork_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfichero_707\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \t\u001b[38;5;66;03m# df_w_r_Block = pd.concat([df_read_layers, df_read_block,df_write_layers,df_write_block ], axis=1, join='outer')\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \t\u001b[38;5;66;03m# df_w_r_Block.columns = ['capa_red', 'Read_block', 'capa_write', 'write_block']\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \t\u001b[38;5;66;03m# # print('df_read_Block', df_read_Block)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    713\u001b[0m \n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m#el codigo original debuelve data pero yo devuelvo la variable que cree nueva\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m data_read_write\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    884\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:191\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1103\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1104\u001b[0m )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheets: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'read_write_blocks_testAlexNet.xlsx'"
     ]
    }
   ],
   "source": [
    "num_address  =1048576\n",
    "Indices      = [0,3,9,11,17,19,25,31,37,40,45,50] #Capas con la informacion de procesamiento\n",
    "#locs_VBW = [101102, 124520, 302065, 331634, 340492, 340493, 360087, 360088, 377722, 377723, 419841, 458633, 458634, 465007, 465008, 465034, 465197, 465389, 544769, 544770, 545758, 590341, 590402, 590403, 590404, 590405, 590406, 590407, 590408, 590409, 590424, 590610, 590706, 590707, 590790, 590804, 611329, 807694, 596228, 371814, 153245, 431863, 870432, 431606, 854134, 464132, 75599, 984684, 957428, 144540, 155294, 449309, 343438, 224550, 515399, 278216, 103082, 153193, 910945, 685437, 504077, 450176, 49594, 699634, 734341, 635221, 639518, 276509, 385631, 40833, 887620, 259787, 105166, 487082, 421367, 829519, 1002831, 827753, 750402, 342656, 641683, 132117, 846177, 670210, 507666, 183528, 108520, 335181, 645235, 306439, 986119, 910692, 870824, 260319, 435744, 768399, 94637, 525999, 1026694, 26510, 816438, 225078, 190841, 422703, 463124, 467197, 1030806, 379426, 871962, 746460, 360883, 971049, 559437, 989409, 145877, 845559, 1018805, 283649, 79627, 912268, 1042255, 676817, 309244, 682316, 493406, 151515, 58733, 403778, 402881, 793085, 416518, 4606, 305748, 143466, 16917, 28154, 504505, 91708, 1013618, 350501, 367555, 993020, 563837, 128, 77845, 697509, 448560, 25033]\n",
    "\n",
    "samples      = 1 #Numero de imagenes\n",
    "# Sin Power Gating:\n",
    "Data         = GetReadAndWrites(AlexNet,Indices,num_address,samples,CNN_gating=False,network_name='AlexNet')\n",
    "stats        = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "Baseline_Acceses   = pd.DataFrame(stats).reset_index(drop=False)\n",
    "df_writes_Read =  pd.concat([Baseline_Acceses], axis=1, join='outer')\n",
    "df_writes_Read .columns = ['index','Lecturas','Escrituras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835d6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "Buffer  = load_obj('Data/Stats/AlexNet/cycles/buffer')\n",
    "ciclos  = load_obj('Data/Stats/AlexNet/cycles/cycles')\n",
    "config  = load_obj('Data/Stats/AlexNet/cycles/config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b30b22ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3192016"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b69de174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of Addresses': 524288,\n",
       " 'Data': array([0, 0, 0, ..., 0, 0, 0], dtype=int8),\n",
       " 'HighCyclesCount': array([3541616, 1222405,  637804, ...,       0,       0,       0],\n",
       "       dtype=uint32),\n",
       " 'OffCyclesCount': array([0, 0, 0, ..., 0, 0, 0], dtype=uint32),\n",
       " 'LowCyclesCount': array([4294617696,    1969611,    2554212, ...,    3192016,    3192016,\n",
       "           3192016], dtype=uint32),\n",
       " 'Flips': array([2, 2, 2, ..., 0, 0, 0], dtype=uint32),\n",
       " 'offset': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a83549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word size': 16,\n",
       " 'frac size': 11,\n",
       " 'invert bits': 0,\n",
       " 'bitshift': 0,\n",
       " 'CNN-Gated': False,\n",
       " 'write mode': 'default',\n",
       " 'Number of switchable sections': 8}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40f02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer sections:  [0, 65536, 131072, 196608, 262144, 327680, 393216, 458752, 524288]\n",
      "Simulation Started, time: 12:41:40 cycles:  0 offset:  0\n",
      "--now processing CPULayer input_1\n",
      "----layer size:  154587\n",
      "------Current Address:  0\n",
      "------Wrap:  False\n"
     ]
    },
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m LI \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m17\u001b[39m,\u001b[38;5;241m19\u001b[39m,\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m31\u001b[39m,\u001b[38;5;241m37\u001b[39m,\u001b[38;5;241m40\u001b[39m,\u001b[38;5;241m45\u001b[39m,\u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m      3\u001b[0m AI \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m24\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m36\u001b[39m,\u001b[38;5;241m38\u001b[39m,\u001b[38;5;241m44\u001b[39m,\u001b[38;5;241m49\u001b[39m,\u001b[38;5;241m53\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m Buffer,ciclos \u001b[38;5;241m=\u001b[39m  \u001b[43mbuffer_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAlexNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteger_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfractional_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_from\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbit_invertion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit_shifting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCNN_gating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1048576\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlexNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Stats/AlexNet/mask_x/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mlayer_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLI\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_indixes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m()\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m operación ciclos completada: \u001b[39m\u001b[38;5;124m'\u001b[39m, datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:513\u001b[0m, in \u001b[0;36mbuffer_simulation\u001b[1;34m(network, dataset, samples, integer_bits, fractional_bits, bit_invertion, bit_shifting, write_mode, CNN_gating, buffer_size, start_from, results_dir, layer_indexes, activation_indixes, save_results, network_type)\u001b[0m\n\u001b[0;32m    508\u001b[0m \tactivacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m activacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,activacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msize))\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# una variable [] donde guardaré los ciclos de cada iteración sin sumar\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# una variable [arreglo] donde guardaré el nombre de las capas de cada iteración sin sumar\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;66;03m# cycles_capa.append(cycles)\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m cycles \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msimulate_one_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivacions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcycles\u001b[39m\u001b[38;5;124m'\u001b[39m,cycles)\n\u001b[0;32m    516\u001b[0m buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cycles \u001b[38;5;241m-\u001b[39m  buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHighCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m-\u001b[39m  buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOffCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:429\u001b[0m, in \u001b[0;36msimulate_one_image\u001b[1;34m(network_type, layers, activations, config, buffer, first_buffer)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layers):\n\u001b[0;32m    428\u001b[0m \ttmp \u001b[38;5;241m=\u001b[39m cycles\n\u001b[1;32m--> 429\u001b[0m \tcycles_temp\u001b[38;5;241m=\u001b[39m\u001b[43mhandle_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \tlayer_list\u001b[38;5;241m.\u001b[39mappend(layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    431\u001b[0m \tcycles_by_layer\u001b[38;5;241m.\u001b[39mappend(cycles_temp)\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:421\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.handle_layer\u001b[1;34m(buffer, layer, layer_outputs, out_buffer_id)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    420\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--now processing CPULayer\u001b[39m\u001b[38;5;124m'\u001b[39m, layer\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 421\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msim_CPULayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_buffer_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:348\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.sim_CPULayer\u001b[1;34m(buffer, layer, layer_outputs, write_buffer_id)\u001b[0m\n\u001b[0;32m    346\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(layer_outputs\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39macts_per_cycle))\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m \tcycles \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_Loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----elapsed layer simulation time: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m t0)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    350\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m cycles\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:202\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.write_Loop\u001b[1;34m(buffer, layer, activations, manual_offset, params)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m#Update stats after the initial delay\u001b[39;00m\n\u001b[0;32m    201\u001b[0m cycles \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Delay\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 202\u001b[0m \u001b[43mupdate_high_cycle_count\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblockspergrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreadsperblock\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhigh_cycles_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInitial Delay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m#Acceleration of GPU Memory Transfer using small representation\u001b[39;00m\n\u001b[0;32m    204\u001b[0m tmp_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:821\u001b[0m, in \u001b[0;36m_KernelConfiguration.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgriddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharedmem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:964\u001b[0m, in \u001b[0;36mDispatcher.call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    962\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 964\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m kernel\u001b[38;5;241m.\u001b[39mlaunch(args, griddim, blockdim, stream, sharedmem)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:972\u001b[0m, in \u001b[0;36mDispatcher._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kws\n\u001b[0;32m    971\u001b[0m argtypes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeof_pyval(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:1102\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert(c_sig, kernel, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads[argtypes] \u001b[38;5;241m=\u001b[39m kernel\n\u001b[1;32m-> 1102\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigs\u001b[38;5;241m.\u001b[39mappend(sig)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:590\u001b[0m, in \u001b[0;36m_Kernel.bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m    Force binding to current CUDA context\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:433\u001b[0m, in \u001b[0;36mCachedCUFunction.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 433\u001b[0m     cuctx \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     device \u001b[38;5;241m=\u001b[39m cuctx\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    435\u001b[0m     cufunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(device\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:212\u001b[0m, in \u001b[0;36mget_context\u001b[1;34m(devnum)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(devnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    return the CUDA context.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    136\u001b[0m attached_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_attached_context()\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attached_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_context_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:151\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mThis version does not read the cache.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mget_active_context() \u001b[38;5;28;01mas\u001b[39;00m ac:\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ac:\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activate_context_for(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:393\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# Not cached. Query the driver API.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m drvapi\u001b[38;5;241m.\u001b[39mcu_context(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxGetCurrent\u001b[49m(byref(hctx))\n\u001b[0;32m    394\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m hctx \u001b[38;5;28;01mif\u001b[39;00m hctx\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:283\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CudaSupportError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at driver init: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    284\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# Find function in driver library\u001b[39;00m\n\u001b[0;32m    287\u001b[0m libfn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_api(fname)\n",
      "\u001b[1;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "samples = 1\n",
    "LI = [0,3,9,11,17,19,25,31,37,40,45,50]\n",
    "AI = [2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "Buffer,ciclos =  buffer_simulation(AlexNet, test_dataset, integer_bits = 4, fractional_bits = 11, samples = samples, start_from = 0,\n",
    "                                  bit_invertion = False, bit_shifting = False, CNN_gating = False,\n",
    "                                  buffer_size = 1048576, write_mode ='default', save_results = True, network_type = 'AlexNet',\n",
    "                                  results_dir = 'Data/Stats/AlexNet/mask_x/',\n",
    "                                  layer_indexes = LI , activation_indixes = AI)\n",
    "\n",
    "print(str()+' operación ciclos completada: ', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f011fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "word_size  = 16\n",
    "afrac_size = 9\n",
    "aint_size  = 6\n",
    "wfrac_size = 15\n",
    "wint_size  = 0\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99680562",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_aging = [True]*22\n",
    "\n",
    "\n",
    "#Acá la creamos, notese que como no se introduciran fallos en activaciones no es necesario pasar locs ni masks\n",
    "SqueezeNet = GetNeuralNetworkModel('SqueezeNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=activation_aging, word_size=word_size, frac_size=afrac_size,\n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "SqueezeNet.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "SqueezeNet.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model=SqueezeNet, frac_bits=wfrac_size, int_bits=wint_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "493ff015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network SqueezeNet\n",
      "[0, 3, 7, 9, (13, 14), 20, (24, 25), 31, (35, 36), 42, 44, (48, 49), 55, (59, 60), 66, (70, 71), 77, (81, 82), 88, 90, (94, 95), 101, 104] [0, 3, 7, 9, (13, 14), 20, (24, 25), 31, (35, 36), 42, 44, (48, 49), 55, (59, 60), 66, (70, 71), 77, (81, 82), 88, 90, (94, 95), 101, 104]\n",
      "addresses_entrada 1048576\n",
      "capas de escrituras\n",
      " capa, tamaño InputLayer 150528\n",
      "suma de las escrituras [0 0 0 ... 0 0 0]\n",
      "escrituras bloque de 16 9408.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 224, 224, 3)\n",
      " capa, tamaño Conv2D 150528\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 9408.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño MaxPooling2D 301056\n",
      "suma de las escrituras [1 1 1 ... 0 0 0]\n",
      "escrituras bloque de 16 18816.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 56, 56, 96)\n",
      " capa, tamaño Conv2D 301056\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 112896.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 200704\n",
      "suma de las escrituras [2 2 2 ... 1 1 1]\n",
      "escrituras bloque de 16 12544.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 200704\n",
      "suma de las escrituras [3 3 3 ... 2 2 2]\n",
      "escrituras bloque de 16 12544.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 56, 56, 128)\n",
      " capa, tamaño Conv2D 401408\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 200704.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 200704\n",
      "suma de las escrituras [4 4 4 ... 3 3 3]\n",
      "escrituras bloque de 16 12544.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 200704\n",
      "suma de las escrituras [5 5 5 ... 4 4 4]\n",
      "escrituras bloque de 16 12544.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 56, 56, 128)\n",
      " capa, tamaño Conv2D 401408\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 200704.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capas de escrituras\n",
      " capa, tamaño Conv2D 401408\n",
      "suma de las escrituras [6 6 6 ... 0 0 0]\n",
      "escrituras bloque de 16 25088.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 401408\n",
      "suma de las escrituras [7 7 7 ... 1 1 1]\n",
      "escrituras bloque de 16 25088.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa MaxPooling2D\n",
      "layer.input_shape[1:]) (56, 56, 256)\n",
      "actual_values [5 5 5 ... 0 0 0]\n",
      "shape de estas capas (None, 56, 56, 256)\n",
      " capa, tamaño MaxPooling2D 802816\n",
      "suma de las lecturas [5 5 5 ... 0 0 0]\n",
      "lecturas bloque de 16 50176.0\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 25088\n",
      "suma de las escrituras [8 8 8 ... 8 8 8]\n",
      "escrituras bloque de 16 1568.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 32)\n",
      " capa, tamaño Conv2D 25088\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 3136.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 32)\n",
      " capa, tamaño Conv2D 25088\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 3136.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las escrituras [9 9 9 ... 8 8 8]\n",
      "escrituras bloque de 16 2352.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 48)\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 7056.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 48)\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 7056.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las escrituras [10 10 10 ...  9  9  9]\n",
      "escrituras bloque de 16 2352.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 48)\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 7056.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 48)\n",
      " capa, tamaño Conv2D 37632\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 7056.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 50176\n",
      "suma de las escrituras [11 11 11 ...  8  8  8]\n",
      "escrituras bloque de 16 3136.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 64)\n",
      " capa, tamaño Conv2D 50176\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 12544.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 28, 28, 64)\n",
      " capa, tamaño Conv2D 50176\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 12544.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño MaxPooling2D 100352\n",
      "suma de las escrituras [12 12 12 ...  8  8  8]\n",
      "escrituras bloque de 16 6272.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 14, 14, 512)\n",
      " capa, tamaño Conv2D 100352\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 200704.0\n",
      "dentro de valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capas de escrituras\n",
      " capa, tamaño Conv2D 50176\n",
      "suma de las escrituras [13 13 13 ... 10 10 10]\n",
      "escrituras bloque de 16 3136.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "capas de escrituras\n",
      " capa, tamaño Conv2D 50176\n",
      "suma de las escrituras [14 14 14 ... 11 11 11]\n",
      "escrituras bloque de 16 3136.0\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "bid 1\n",
      "capas de leturas\n",
      " capa Conv2D\n",
      "layer==4 Conv2D\n",
      "shape de estas capas (None, 14, 14, 512)\n",
      " capa, tamaño Conv2D 100352\n",
      "suma de las lecturas no las calculo aquí, debo analizar \n",
      "lecturas bloque de 16 200704.0\n",
      "dentro del elese por tanto padding!=valid\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "recorrido del kernel\n",
      "condicional conv2D.......................................\n",
      "Conv2D Conv2D\n",
      "condicional padding==same\n",
      "bid 0\n",
      "capas de escrituras\n",
      " capa, tamaño GlobalAveragePooling2D 8\n",
      "suma de las escrituras [15 15 15 15 15 15 15 15]\n",
      "escrituras bloque de 16 0.5\n",
      "buffer_divitions [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "                            Capa  Read_write_block\n",
      "0               InputLayer_write         9661.6875\n",
      "1                    Conv2D_read         9661.6875\n",
      "2             MaxPooling2D_write         4374.0000\n",
      "3                    Conv2D_read        26244.0000\n",
      "4             MaxPooling2D_write         2704.0000\n",
      "5                    Conv2D_read        43264.0000\n",
      "6                   Conv2D_write         4056.0000\n",
      "7                    Conv2D_read        97344.0000\n",
      "8             MaxPooling2D_write          576.0000\n",
      "9                     Dense_read          576.0000\n",
      "10                   Dense_write          256.0000\n",
      "11                    Dense_read          256.0000\n",
      "12              InputLayer_write         9408.0000\n",
      "13                   Conv2D_read         9408.0000\n",
      "14            MaxPooling2D_write        18816.0000\n",
      "15                   Conv2D_read       112896.0000\n",
      "16                  Conv2D_write        12544.0000\n",
      "17                  Conv2D_write        12544.0000\n",
      "18                   Conv2D_read       200704.0000\n",
      "19                  Conv2D_write        12544.0000\n",
      "20                  Conv2D_write        12544.0000\n",
      "21                   Conv2D_read       200704.0000\n",
      "22                  Conv2D_write        25088.0000\n",
      "23                  Conv2D_write        25088.0000\n",
      "24             MaxPooling2D_read        50176.0000\n",
      "25                  Conv2D_write         1568.0000\n",
      "26                   Conv2D_read         3136.0000\n",
      "27                   Conv2D_read         3136.0000\n",
      "28                  Conv2D_write         2352.0000\n",
      "29                   Conv2D_read         7056.0000\n",
      "30                   Conv2D_read         7056.0000\n",
      "31                  Conv2D_write         2352.0000\n",
      "32                   Conv2D_read         7056.0000\n",
      "33                   Conv2D_read         7056.0000\n",
      "34                  Conv2D_write         3136.0000\n",
      "35                   Conv2D_read        12544.0000\n",
      "36                   Conv2D_read        12544.0000\n",
      "37            MaxPooling2D_write         6272.0000\n",
      "38                   Conv2D_read       200704.0000\n",
      "39                  Conv2D_write         3136.0000\n",
      "40                  Conv2D_write         3136.0000\n",
      "41                   Conv2D_read       200704.0000\n",
      "42  GlobalAveragePooling2D_write            0.5000\n"
     ]
    }
   ],
   "source": [
    "num_address  =1048576\n",
    "samples      = 1\n",
    "Indices = [0,3,7, 9,(13,14),20,(24,25),31,(35,36),42,44,(48,49),55,(59,60),66,(70,71),77,(81,82),88,90,(94,95),101,104]\n",
    "Data    = GetReadAndWrites(SqueezeNet,Indices,num_address,samples,CNN_gating=False,network_name='SqueezeNet')\n",
    "stats   = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "Baseline_Acceses   = pd.DataFrame(stats).reset_index(drop=False)\n",
    "df_writes_Read =  pd.concat([Baseline_Acceses], axis=1, join='outer')\n",
    "df_writes_Read.columns = ['index','Lecturas','Escrituras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae71dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_first",
   "language": "python",
   "name": "env_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
