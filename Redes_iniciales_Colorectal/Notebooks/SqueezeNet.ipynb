{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e3a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Training import GetDatasets\n",
    "from Nets  import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, ActivationStats, CheckAccuracyAndLoss, QuantizationEffect, GetReadAndWrites\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3bd36c",
   "metadata": {},
   "source": [
    "a) Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88476071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_batch_size = test_batch_size = 32\n",
    "#train_set,valid_set,test_set = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, train_batch_size, test_batch_size)\n",
    "train_batch_size = test_batch_size = 32\n",
    "train_set,valid_set,test_set = GetDatasets('colorectal_histology',(80,5,15),(224,224), 8, train_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6dfd213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 224, 224, 3), (None, 8)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613396d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SqueezeNet     = GetNeuralNetworkModel('SqueezeNet',(224,224,3),8, quantization = False, aging_active=False)\n",
    "loss      = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "SqueezeNet.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b66d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 224, 224, 3)  0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 96) 14208       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 112, 112, 96) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 112, 112, 96) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 112, 112, 96) 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 96)   0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 56, 56, 96)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 16)   1552        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 56, 56, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 56, 56, 16)   0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 56, 56, 16)   0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   1088        lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   9280        lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 56, 56, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 56, 56, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 56, 56, 128)  0           re_lu_2[0][0]                    \n",
      "                                                                 re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 56, 56, 128)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 56, 56, 128)  0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 16)   2064        lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 56, 56, 16)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 56, 56, 16)   0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 56, 56, 16)   0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 64)   1088        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   9280        lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 56, 56, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 56, 56, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 128)  0           re_lu_5[0][0]                    \n",
      "                                                                 re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 56, 56, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 56, 56, 128)  0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 32)   4128        lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 56, 56, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 56, 56, 32)   0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 56, 56, 32)   0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 128)  4224        lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 128)  36992       lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 56, 56, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 56, 56, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 56, 56, 256)  0           re_lu_8[0][0]                    \n",
      "                                                                 re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 56, 56, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 56, 56, 256)  0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 256)  0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 28, 28, 256)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 32)   8224        lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 28, 28, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 28, 28, 32)   0           re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 28, 28, 32)   0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  4224        lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  36992       lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 28, 28, 128)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 28, 28, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 256)  0           re_lu_11[0][0]                   \n",
      "                                                                 re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 28, 28, 256)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 28, 28, 256)  0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 48)   12336       lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 28, 28, 48)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 28, 28, 48)   0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 28, 28, 48)   0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 192)  9408        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 192)  83136       lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 28, 28, 192)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 28, 28, 192)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 28, 28, 384)  0           re_lu_14[0][0]                   \n",
      "                                                                 re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 28, 28, 384)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 28, 28, 384)  0           lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 48)   18480       lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 28, 28, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 28, 28, 48)   0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 28, 28, 48)   0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 192)  9408        lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 192)  83136       lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 28, 28, 192)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 28, 28, 192)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 28, 28, 384)  0           re_lu_17[0][0]                   \n",
      "                                                                 re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 28, 28, 384)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 28, 28, 384)  0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 64)   24640       lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 28, 28, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 28, 28, 64)   0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 28, 28, 64)   0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 256)  16640       lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 256)  147712      lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 28, 28, 256)  0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 28, 28, 256)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28, 28, 512)  0           re_lu_20[0][0]                   \n",
      "                                                                 re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 28, 28, 512)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 28, 28, 512)  0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 512)  0           lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 14, 14, 512)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 14, 14, 64)   32832       lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 14, 14, 64)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 14, 14, 64)   0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 14, 14, 64)   0           lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 256)  16640       lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 256)  147712      lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 14, 14, 256)  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 14, 14, 256)  0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 14, 14, 512)  0           re_lu_23[0][0]                   \n",
      "                                                                 re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 14, 14, 512)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 14, 14, 512)  0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 8)    4104        lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 14, 14, 8)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 14, 14, 8)    0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 8)            0           lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 8)            0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.softmax (TFOpLa (None, 8)            0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 8)            0           tf.compat.v1.nn.softmax[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 739,528\n",
      "Trainable params: 739,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SqueezeNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c52261",
   "metadata": {},
   "source": [
    "a) Get Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2d166",
   "metadata": {},
   "source": [
    "Se crea la red, sin activar la cuantización ni el efecto de envejecimiento\n",
    "Las dimensiones de entrada de la imagen (224,224), el número de clases (8) y el tamaño de los batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f0ca6",
   "metadata": {},
   "source": [
    " b) Load/Save Weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd37e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x13e04278580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Weights') \n",
    "SqueezeNet.load_weights(wgt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faad11f",
   "metadata": {},
   "source": [
    "Evaluación del accuracy y loss de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d957c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 15s 638ms/step - loss: 0.2379 - accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "(OrigLoss,OrigAcc) = SqueezeNet.evaluate(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba7b28",
   "metadata": {},
   "source": [
    "2) Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49ba71",
   "metadata": {},
   "source": [
    " Write/Read Stats¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c741a4",
   "metadata": {},
   "source": [
    "Se identifican (manualmente) las capas procesadadas(Convoluciones, Full conectadas y Pooling) junto a las capas que contienen los resultados que se escribiran en el buffer (capas luego de la funcion de activacion y/o Normalizacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0170f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 lambda_43\n",
      "2 lambda_44\n",
      "3 conv2d_26\n",
      "4 re_lu_25\n",
      "5 lambda_45\n",
      "6 lambda_46\n",
      "7 max_pooling2d_3\n",
      "8 lambda_47\n",
      "9 conv2d_27\n",
      "10 re_lu_26\n",
      "11 lambda_48\n",
      "12 lambda_49\n",
      "13 conv2d_28\n",
      "14 conv2d_29\n",
      "15 re_lu_27\n",
      "16 re_lu_28\n",
      "17 concatenate_8\n",
      "18 lambda_50\n",
      "19 lambda_51\n",
      "20 conv2d_30\n",
      "21 re_lu_29\n",
      "22 lambda_52\n",
      "23 lambda_53\n",
      "24 conv2d_31\n",
      "25 conv2d_32\n",
      "26 re_lu_30\n",
      "27 re_lu_31\n",
      "28 concatenate_9\n",
      "29 lambda_54\n",
      "30 lambda_55\n",
      "31 conv2d_33\n",
      "32 re_lu_32\n",
      "33 lambda_56\n",
      "34 lambda_57\n",
      "35 conv2d_34\n",
      "36 conv2d_35\n",
      "37 re_lu_33\n",
      "38 re_lu_34\n",
      "39 concatenate_10\n",
      "40 lambda_58\n",
      "41 lambda_59\n",
      "42 max_pooling2d_4\n",
      "43 lambda_60\n",
      "44 conv2d_36\n",
      "45 re_lu_35\n",
      "46 lambda_61\n",
      "47 lambda_62\n",
      "48 conv2d_37\n",
      "49 conv2d_38\n",
      "50 re_lu_36\n",
      "51 re_lu_37\n",
      "52 concatenate_11\n",
      "53 lambda_63\n",
      "54 lambda_64\n",
      "55 conv2d_39\n",
      "56 re_lu_38\n",
      "57 lambda_65\n",
      "58 lambda_66\n",
      "59 conv2d_40\n",
      "60 conv2d_41\n",
      "61 re_lu_39\n",
      "62 re_lu_40\n",
      "63 concatenate_12\n",
      "64 lambda_67\n",
      "65 lambda_68\n",
      "66 conv2d_42\n",
      "67 re_lu_41\n",
      "68 lambda_69\n",
      "69 lambda_70\n",
      "70 conv2d_43\n",
      "71 conv2d_44\n",
      "72 re_lu_42\n",
      "73 re_lu_43\n",
      "74 concatenate_13\n",
      "75 lambda_71\n",
      "76 lambda_72\n",
      "77 conv2d_45\n",
      "78 re_lu_44\n",
      "79 lambda_73\n",
      "80 lambda_74\n",
      "81 conv2d_46\n",
      "82 conv2d_47\n",
      "83 re_lu_45\n",
      "84 re_lu_46\n",
      "85 concatenate_14\n",
      "86 lambda_75\n",
      "87 lambda_76\n",
      "88 max_pooling2d_5\n",
      "89 lambda_77\n",
      "90 conv2d_48\n",
      "91 re_lu_47\n",
      "92 lambda_78\n",
      "93 lambda_79\n",
      "94 conv2d_49\n",
      "95 conv2d_50\n",
      "96 re_lu_48\n",
      "97 re_lu_49\n",
      "98 concatenate_15\n",
      "99 lambda_80\n",
      "100 lambda_81\n",
      "101 conv2d_51\n",
      "102 lambda_82\n",
      "103 lambda_83\n",
      "104 global_average_pooling2d_1\n",
      "105 lambda_84\n",
      "106 tf.compat.v1.nn.softmax_1\n",
      "107 lambda_85\n",
      "Las capas 0,3,9,11,17,19,25,31,37,40,45 y 50  contienen la informacion para su procesamiento en MMU\n",
      "Las capas 2,8,10,16,18,24,30,36,38,44,49 y 53 contienen las activaciones que son escritas en memoria\n"
     ]
    }
   ],
   "source": [
    "for index,layer in enumerate(SqueezeNet.layers):\n",
    "    print(index,layer.name)\n",
    "print('Las capas 0,3,9,11,17,19,25,31,37,40,45 y 50  contienen la informacion para su procesamiento en MMU')\n",
    "print('Las capas 2,8,10,16,18,24,30,36,38,44,49 y 53 contienen las activaciones que son escritas en memoria')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41489311",
   "metadata": {},
   "source": [
    "Con el siguiente bloque obtenemos el número de lecturas y escrituras por posición de memoria tanto usando la estrategia de CNN Gating o sin usarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47a1bd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesados:  25\n",
      "procesados:  50\n",
      "procesados:  75\n",
      "procesados:  100\n",
      "procesados:  125\n",
      "procesados:  150\n"
     ]
    }
   ],
   "source": [
    "num_address= 1024*1024\n",
    "samples      = 10\n",
    "Indices = [0,3,7, 9,(13,14),20,(24,25),31,(35,36),42,44,(48,49),55,(59,60),66,(70,71),77,(81,82),88,90,(94,95),101,104]\n",
    "Data    = GetReadAndWrites(SqueezeNet,Indices,801816,150,CNN_gating=False,network_name='SqueezeNet')\n",
    "stats   = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "Baseline_Acceses   = pd.DataFrame(stats).reset_index(drop=False)\n",
    "Data    = GetReadAndWrites(SqueezeNet,Indices,num_address,samples,CNN_gating=True,network_name='SqueezeNet')\n",
    "stats    = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "CNN_gating_Acceses = pd.DataFrame(stats).reset_index(drop=False)\n",
    "save_obj(Baseline_Acceses,'Data/Acceses/SqueezeNet/Baseline_v2')\n",
    "save_obj(CNN_gating_Acceses,'Data/Acceses/SqueezeNet/CNN_gating_Fix_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fd968",
   "metadata": {},
   "source": [
    "# a) Number of bits analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce52271",
   "metadata": {},
   "source": [
    " Ahora veremos como afecta la cuantizacion, tanto en pesos como en activaciones a la accuracy y loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d589931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation fraction part\n",
      "0  bits results:  acc:  0.2213333398103714 loss:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.4346666634082794 loss:  8.266940116882324\n",
      "2  bits results:  acc:  0.6666666865348816 loss:  3.216773509979248\n",
      "3  bits results:  acc:  0.8320000171661377 loss:  1.4068776369094849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.9306666851043701 loss:  0.4856926202774048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.9293333292007446 loss:  0.3766774833202362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.9306666851043701 loss:  0.33778485655784607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.9293333292007446 loss:  0.2928098738193512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.9293333292007446 loss:  0.26740729808807373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.9319999814033508 loss:  0.2533944845199585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.9319999814033508 loss:  0.2539820671081543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.9319999814033508 loss:  0.2430734634399414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.9319999814033508 loss:  0.24369901418685913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.9319999814033508 loss:  0.2431771606206894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.9319999814033508 loss:  0.2431861162185669\n",
      "Weights fraction part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:227: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  bits results:  acc:  0.11733333021402359 loss:  2.0794413089752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.11733333021402359 loss:  2.0794413089752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.11733333021402359 loss:  2.0794413089752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.11733333021402359 loss:  2.2098710536956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.2919999957084656 loss:  8.50405216217041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.7559999823570251 loss:  0.7510754466056824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.9200000166893005 loss:  0.29581940174102783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.9333333373069763 loss:  0.2379211187362671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.9333333373069763 loss:  0.2436547428369522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.9333333373069763 loss:  0.23597237467765808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.9319999814033508 loss:  0.24359886348247528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.9306666851043701 loss:  0.24323511123657227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.9319999814033508 loss:  0.2434196025133133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.9319999814033508 loss:  0.24325382709503174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.9319999814033508 loss:  0.24328099191188812\n",
      "Activation integer part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:233: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  bits results:  acc:  0.25600001215934753 loss:  2.0746827125549316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.6039999723434448 loss:  1.2279582023620605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.7440000176429749 loss:  0.7012795209884644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.9120000004768372 loss:  0.3543921709060669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.918666660785675 loss:  0.2511349320411682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.9240000247955322 loss:  0.23931172490119934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.9319999814033508 loss:  0.24338509142398834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:239: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    }
   ],
   "source": [
    "df = QuantizationEffect('SqueezeNet',test_set,wgt_dir,(224,224,3),8,test_batch_size)\n",
    "#save_obj(df,'Data/Quantization/AlexNet/Colorectal Dataset/Quantization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3429bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 24s 987ms/step - loss: 0.4706 - accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracyAndLoss('SqueezeNet', test_set, wgt_dir, act_frac_size = 9, act_int_size = 6, wgt_frac_size = 15, wgt_int_size = 0, \n",
    "                    input_shape = (224,224,3), output_shape = 8, batch_size = test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a428795",
   "metadata": {},
   "source": [
    " c) Activation Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74f73d",
   "metadata": {},
   "source": [
    "Para la configuración anterior, se observa el valor medio,maximo,minimo y el ratio de saturación tanto de las activaciones procesadas dentro de la unidad matricial de multiplicacion como de las almacenadas en el buffer. Nota: el ultimo parametro indica el numero de iteraciones que se deben realizar hasta agotar el dataset, se obtiene como numero de imagenes del dataset dividido en el batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f830b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value (MMU): -0.16231656\n",
      "mean value (Buffer): 0.14423333\n",
      "maximum (MMU): 106.956314\n",
      "minimum (MMU): -188.0446\n",
      "maximum (Buffer): 106.956314\n",
      "minimum (Buffer): -131.6606\n",
      "saturation ratio (MMU): 0.0022129352593187345\n",
      "saturation ratio (Buffer): 0.00017893128801773947\n"
     ]
    }
   ],
   "source": [
    "ActivationStats(SqueezeNet,test_set,9,6,24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812b0a9",
   "metadata": {},
   "source": [
    "3) Buffer Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ea1ad",
   "metadata": {},
   "source": [
    " a) Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bfc484",
   "metadata": {},
   "source": [
    "Ahora para el Baseline simularemos el comportamiento de 1 buffer durante la inferencia de 3 imagenes (solo 3 como ejemplo), la red se crea ahora activando la cuantizacion pero no el envejecimiento. LI y AI son los definidos en el item 2) Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2b73a",
   "metadata": {},
   "source": [
    "......estos ficheros ya están , solo cargar e interpretarlos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7739546",
   "metadata": {},
   "source": [
    "Sin inyectar errores original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d5ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x' 'x' 'x' ... 'x' 'x' 'x']\n",
      "0.8080000281333923\n",
      "4646400 completada:  09:01:54\n"
     ]
    }
   ],
   "source": [
    "# from copy import deepcopy\n",
    "from Stats import CheckAccuracyAndLoss\n",
    "from Simulation import save_obj, load_obj\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from Training import GetDatasets\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "    \n",
    "\n",
    "trainBatchSize = testBatchSize = 16\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "Accs_x= []\n",
    "\n",
    "\n",
    "\n",
    "network_size   = 290400*16   # Tamaño del buffer (en bits)\n",
    "num_of_samples = 1       # Numero de muestras de distintas configuraciones de fallos a testear por cada valor de Accs/Loss\n",
    "    \n",
    "n_bits_total = np.ceil(network_size).astype(int)    #numero de bits totales\n",
    "    \n",
    "buffer = np.array(['x']*(network_size))\n",
    "print(buffer)\n",
    "for index in range(0,num_of_samples):\n",
    "        \n",
    "    loss,acc_x   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (224,224,3),\n",
    "                                            act_frac_size = 9, act_int_size = 6, wgt_frac_size = 15, wgt_int_size = 0,\n",
    "                                            batch_size=testBatchSize, verbose = 0, aging_active = False, weights_faults = False)\n",
    "       \n",
    "        \n",
    "    print(acc_x)\n",
    "        \n",
    "      \n",
    "        \n",
    "    Accs_x.append(acc_x)\n",
    "        \n",
    "print(str(n_bits_total)+' completada: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "#save_obj(Accs_x,'Data/Errors/SqueezeNet/Colorectal Dataset/Accs_x')\n",
    "#save_obj(Loss,'Data/Errors/SqueezeNet/Colorectal Dataset/Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f07cb",
   "metadata": {},
   "source": [
    "# Analizando el fichero en su estado original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2a2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de errores de todo el fihero: 23706\n",
      "Cantidad de elementos por tipo : Counter({'x': 16766856, '0': 10360})\n",
      "16777216\n",
      "16777216\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model/lambda_1/GatherNd\n\t [[node model/lambda_1/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_5368]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/lambda_1/GatherNd:\n model/lambda/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0e4e1d8ca366>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0merror_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbuffer_vectores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         loss,acc   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n\u001b[0m\u001b[0;32m     52\u001b[0m                                             \u001b[0mact_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestBatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maging_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_faults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CNN_Gating\\Stats.py\u001b[0m in \u001b[0;36mCheckAccuracyAndLoss\u001b[1;34m(architecture, test_dataset, wgt_dir, act_frac_size, act_int_size, wgt_frac_size, wgt_int_size, input_shape, output_shape, faulty_addresses, masked_faults, aging_active, batch_size, verbose, weights_faults)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Cleaning Memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model/lambda_1/GatherNd\n\t [[node model/lambda_1/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_5368]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/lambda_1/GatherNd:\n model/lambda/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "## from copy import deepcopy\n",
    "from Stats import CheckAccuracyAndLoss\n",
    "from Simulation import save_obj, load_obj\n",
    "from FileAnalize import analize_file, analize_file_uno,analize_file_uno_ceros, save_file, load_file\n",
    "from funciones import buffer_vectores\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from Training import GetDatasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    " \n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "    \n",
    "\n",
    "trainBatchSize = testBatchSize = 16\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(224,224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "Accs = []\n",
    "Accs_w = []\n",
    "Accs_a_w = []\n",
    "\n",
    "\n",
    "\n",
    "buffer_size= 16777216\n",
    "\n",
    "       \n",
    "ruta_bin = 'Data\\Fault Characterization\\VC707\\RawData'\n",
    "#ruta_bin = 'Data/Fault Characterization/KC705_B/RowData/'\n",
    "directorio = pathlib.Path(ruta_bin)\n",
    "num_of_samples = 1\n",
    "\n",
    "variantes= [analize_file, analize_file_uno, analize_file_uno_ceros]\n",
    "ficheros = [fichero.name for fichero in directorio.iterdir()]\n",
    "for index in range(0,num_of_samples):\n",
    "    for i, j in enumerate(ficheros):\n",
    "        directorio= os.path.join(ruta_bin, j)\n",
    "        buffer= (analize_file(directorio, buffer_size))\n",
    "        error_mask, locs = (buffer_vectores(buffer))\n",
    "    \n",
    "        loss,acc   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (224,224,3),\n",
    "                                            act_frac_size = 9, act_int_size = 5, wgt_frac_size = 15, wgt_int_size = 0,\n",
    "                                            batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = False,\n",
    "                                            faulty_addresses = locs, masked_faults = error_mask)\n",
    "    \n",
    "        loss,acc_w   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (224,224,3),\n",
    "                                            act_frac_size = 9, act_int_size = 5, wgt_frac_size = 15, wgt_int_size = 0,\n",
    "                                            batch_size=testBatchSize, verbose = 0, aging_active = False, weights_faults = True,\n",
    "                                            faulty_addresses = locs, masked_faults = error_mask)\n",
    "    \n",
    "        loss,acc_a_w   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (224,224,3),\n",
    "                                            act_frac_size = 9, act_int_size = 5, wgt_frac_size = 15, wgt_int_size = 0,\n",
    "                                            batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = True,\n",
    "                                            faulty_addresses = locs, masked_faults = error_mask)\n",
    "    \n",
    "    \n",
    "        Accs.append(acc)\n",
    "        Accs_w.append(acc_w)\n",
    "        Accs_a_w.append(acc_a_w)                                      \n",
    "\n",
    "\n",
    "Acc=pd.DataFrame(Accs)\n",
    "Acc_w =pd.DataFrame(Accs_w)\n",
    "Acc_a_w =pd.DataFrame(Accs_w)                                         \n",
    "#buf_cero = pd.concat([Acc,Acc_w, Acc_a_w], axis=1, join='outer')\n",
    "#buf_cero.columns =['Acc_cero', 'A_w_cero', 'Acc_a_w_cero'] \n",
    "#buf_cero.to_excel('resultado.xlsx', sheet_name='ceros_707', index=False)\n",
    "\n",
    "\n",
    "Acc.head()\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "print(str()+' operación completada: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "#lsave_file(Accs,'Data/Fault Characterization/Accs')\n",
    "\n",
    "#save_obj(Loss,'Data/Errors/SqueezeNet/Colorectal Dataset/Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f29a6",
   "metadata": {},
   "source": [
    "# Inyectando errores en 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1db6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\Fault Characterization\\VC707\\RawData\n",
      "Cantidad de errores de todo el fihero: 23706\n",
      "Cantidad de elementos por tipo : Counter({'x': 16766856, '1': 10360})\n",
      "16777216\n",
      "Data\\Fault Characterization\\VC707\\RawData\\VC707-0.54.bin\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model_1/lambda_44/GatherNd\n\t [[node model_1/lambda_44/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_10827]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/lambda_44/GatherNd:\n model_1/lambda_43/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a0a8f239264e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectorio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         loss,acc_1   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n\u001b[0m\u001b[0;32m     58\u001b[0m                                                 \u001b[0mact_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestBatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maging_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_faults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CNN_Gating\\Stats.py\u001b[0m in \u001b[0;36mCheckAccuracyAndLoss\u001b[1;34m(architecture, test_dataset, wgt_dir, act_frac_size, act_int_size, wgt_frac_size, wgt_int_size, input_shape, output_shape, faulty_addresses, masked_faults, aging_active, batch_size, verbose, weights_faults)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Cleaning Memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model_1/lambda_44/GatherNd\n\t [[node model_1/lambda_44/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_10827]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/lambda_44/GatherNd:\n model_1/lambda_43/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "from Stats import CheckAccuracyAndLoss\n",
    "from Simulation import save_obj, load_obj\n",
    "from FileAnalize import analize_file, analize_file_uno,analize_file_uno_ceros, save_file, load_file\n",
    "from funciones import buffer_vectores\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from Training import GetDatasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "trainBatchSize = testBatchSize = 16\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "    \n",
    "\n",
    "Accs_1 = []\n",
    "Accs_w_1 = []\n",
    "Accs_a_w_1 = []\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['Accs', 'Acc_w'])\n",
    "buffer_size= 16777216\n",
    "num_of_samples = 1\n",
    "\n",
    "\n",
    "       \n",
    "ruta_bin = 'Data\\Fault Characterization\\VC707\\RawData'\n",
    "#ruta_bin = 'Data/Fault Characterization/KC705_B/RowData/'\n",
    "directorio = pathlib.Path(ruta_bin)\n",
    "\n",
    "variantes= [analize_file, analize_file_uno, analize_file_uno_ceros]\n",
    "ficheros = [fichero.name for fichero in directorio.iterdir()]\n",
    "print(directorio)\n",
    "for index in range(0,num_of_samples):\n",
    "    for i, j in enumerate(ficheros):\n",
    "        directorio= os.path.join(ruta_bin, j)\n",
    "        buffer= (analize_file_uno(directorio, buffer_size))\n",
    "        error_mask, locs = (buffer_vectores(buffer))\n",
    "        print(directorio)\n",
    "        \n",
    "        loss,acc_1   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = False,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        loss,acc_w_1   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = False, weights_faults = True,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        loss,acc_a_w_1   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = True,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        \n",
    "        Accs_1.append(acc_1)\n",
    "        Accs_w_1.append(acc_w_1)\n",
    "        Accs_a_w_1.append(acc_a_w_1)                                      \n",
    "\n",
    "\n",
    "Acc_1=pd.DataFrame(Accs_1)\n",
    "Acc_w_1 =pd.DataFrame(Accs_w_1)\n",
    "Acc_a_w_1 =pd.DataFrame(Accs_w_1)                                         \n",
    "#buf_cero = pd.concat([Acc_1,Acc_w_1, Acc_a_w_1], axis=1, join='outer')\n",
    "#buf_cero.columns =['Acc_uno', 'A_w_uno', 'Acc_a_w_uno'] \n",
    "#buf_cero.to_excel('resultado.xlsx', sheet_name='unos_707', index=False)\n",
    "\n",
    "#buf_cero = pd.concat([Acc,Acc_w, Acc_a_w], axis=1, join='outer')\n",
    "#buf_cero.columns =['Acc_cero', 'A_w_cero', 'Acc_a_w_cero'] \n",
    "#buf_cero.to_excel('resultado.xlsx', sheet_name='ceros_707', index=False)\n",
    "\n",
    "\n",
    "\n",
    "Acc.head()\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "print(str()+' operación completada: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "save_file(Accs_1,'Data/Fault Characterization/Accs')\n",
    "\n",
    "#save_obj(Loss,'Data/Errors/AlexNet/Colorectal Dataset/Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fb42e",
   "metadata": {},
   "source": [
    "# Inyectando errores aleatorios ceros y unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a9f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de errores de todo el fihero: 23706\n",
      "Cantidad de elementos por tipo : Counter({'x': 16766856, '0': 5196, '1': 5164})\n",
      "16777216\n",
      "Data\\Fault Characterization\\VC707\\RawData\\VC707-0.54.bin\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model_2/lambda_87/GatherNd\n\t [[node model_2/lambda_87/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_15907]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_2/lambda_87/GatherNd:\n model_2/lambda_86/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e4bbd6b06bb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectorio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         loss,acc_1_0   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n\u001b[0m\u001b[0;32m     30\u001b[0m                                                 \u001b[0mact_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_frac_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwgt_int_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtestBatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maging_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_faults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\CNN_Gating\\Stats.py\u001b[0m in \u001b[0;36mCheckAccuracyAndLoss\u001b[1;34m(architecture, test_dataset, wgt_dir, act_frac_size, act_int_size, wgt_frac_size, wgt_int_size, input_shape, output_shape, faulty_addresses, masked_faults, aging_active, batch_size, verbose, weights_faults)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mqNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Cleaning Memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[8447] = [15, 199, 142, 2] does not index into param shape [14,227,227,3], node name: model_2/lambda_87/GatherNd\n\t [[node model_2/lambda_87/GatherNd (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:79) ]] [Op:__inference_test_function_15907]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_2/lambda_87/GatherNd:\n model_2/lambda_86/Maximum (defined at C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets.py:54)\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "buffer_size= 16777216\n",
    "Accs_1_0 = []\n",
    "Accs_w_1_0 = []\n",
    "Accs_a_w_1_0 = []\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['Accs', 'Acc_w'])\n",
    "buffer_size= 16777216\n",
    "num_of_samples = 1\n",
    "\n",
    "\n",
    "       \n",
    "ruta_bin = 'Data\\Fault Characterization\\VC707\\RawData'\n",
    "#ruta_bin = 'Data/Fault Characterization/KC705_B/RowData/'\n",
    "directorio = pathlib.Path(ruta_bin)\n",
    "\n",
    "variantes= [analize_file, analize_file_uno, analize_file_uno_ceros]\n",
    "ficheros = [fichero.name for fichero in directorio.iterdir()]\n",
    "\n",
    "for index in range(0,num_of_samples):\n",
    "\n",
    "    for i, j in enumerate(ficheros):\n",
    "        directorio= os.path.join(ruta_bin, j)\n",
    "        buffer= (analize_file_uno_ceros(directorio, buffer_size))\n",
    "        error_mask, locs = (buffer_vectores(buffer))\n",
    "        print(directorio)\n",
    "        \n",
    "        loss,acc_1_0   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = False,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        loss,acc_w_1_0   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = False, weights_faults = True,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        loss,acc_a_w_1_0   = CheckAccuracyAndLoss('SqueezeNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                                act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                                batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = True,\n",
    "                                                faulty_addresses = locs, masked_faults = error_mask)\n",
    "        \n",
    "        \n",
    "        Accs_1_0.append(acc_1_0)\n",
    "        Accs_w_1_0.append(acc_w_1_0)\n",
    "        Accs_a_w_1_0.append(acc_a_w_1_0)                                      \n",
    "\n",
    "\n",
    "Acc_1_0=pd.DataFrame(Accs_1_0)\n",
    "Acc_w_1_0 =pd.DataFrame(Accs_w_1_0)\n",
    "Acc_a_w_1_0 =pd.DataFrame(Accs_w_1_0)                                         \n",
    "buf_cero = pd.concat([Acc,Acc_w, Acc_a_w,Acc_1,Acc_w_1, Acc_a_w_1,Acc_1_0,Acc_w_1_0, Acc_a_w_1_0], axis=1, join='outer')\n",
    "buf_cero.columns =['Acc_cero', 'A_w_cero', 'Acc_a_w_cero', 'Acc_uno', 'A_w_uno', 'Acc_a_w_uno' ,'Acc_uno_cero', 'A_w_uno_cero', 'Acc_a_w_uno_cero'] \n",
    "buf_cero.to_excel('resultado.xlsx', sheet_name='fichero_707', index=False)\n",
    "\n",
    "#buf_cero = pd.concat([Acc_1,Acc_w_1, Acc_a_w_1], axis=1, join='outer')\n",
    "#buf_cero.columns =['Acc_uno', 'A_w_uno', 'Acc_a_w_uno'] \n",
    "#buf_cero.to_excel('resultado.xlsx', sheet_name='unos_707', index=False)\n",
    "\n",
    "#buf_cero = pd.concat([Acc,Acc_w, Acc_a_w], axis=1, join='outer')\n",
    "#buf_cero.columns =['Acc_cero', 'A_w_cero', 'Acc_a_w_cero'] \n",
    "#buf_cero.to_excel('resultado.xlsx', sheet_name='ceros_707', index=False)\n",
    "Acc.head()\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "print(str()+' operación completada: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "#save_file(Accs_1,'Data/Fault Characterization/Accs')\n",
    "\n",
    "#save_obj(Loss,'Data/Errors/SqueezeNet/Colorectal Dataset/Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e900b",
   "metadata": {},
   "source": [
    "# Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93734f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_first",
   "language": "python",
   "name": "env_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
