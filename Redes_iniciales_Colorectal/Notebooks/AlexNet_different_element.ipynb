{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fcde9e4",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620799d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from Stats import WeightQuantization,IntroduceFaultsInWeights,GenerateFaultsList\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList, CheckAccuracyAndLoss\n",
    "from Nets import GetNeuralNetworkModel\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200bac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Esta funcion convierte un valor de flotante a su equivalente binario de signo magnitud, asumiendo 11 bits\n",
    "## para parte fraccionaria (los usados en AlexNet \n",
    "def convert(value):\n",
    "    shift   = 2**(16-1)\n",
    "    factor  = 2**11\n",
    "    new_val = value*factor\n",
    "    new_val = -new_val + shift if new_val < 0 else new_val\n",
    "    new_val = int(new_val)\n",
    "    return format(new_val, '#018b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9f7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3a670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size  = 16\n",
    "afrac_size = 11  \n",
    "aint_size  = 4\n",
    "wfrac_size = 11\n",
    "wint_size  = 4\n",
    "# Tamaño del buffer de pesos == al tamaño de la capa con mayor numero de pesos (885120 pesos de 16 bits cada uno)\n",
    "#wbuffer_size = 885120*word_size\n",
    "# Tamaño del buffer de activaciones == al tamaño de la capa con mayor numero de activaciones (290400 pesos de 16 bits cada uno)\n",
    "#abuffer_size = (1024*1024)*word_size\n",
    "# Directorio de los pesos\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'AlexNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404fae1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69573a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostrando las 5 primeras direcciones con fallos\n",
      "direcciones: [4141, 4181, 4199, 4241, 4249]\n",
      "mascara de fallos: ['x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x1xxxxxxx0xxxxxx']\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "Cargar_errores = True\n",
    "\n",
    "#print(load_file('Data/Fault Characterization/wgt/Accs_w_707_55'))\n",
    "\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/error_mask_054')\n",
    "locs= locs[0:5]  \n",
    "error_mask=error_mask[0:5]\n",
    "    \n",
    "print('mostrando las 5 primeras direcciones con fallos')\n",
    "print('direcciones:',locs)\n",
    "print('mascara de fallos:',error_mask)\n",
    "print(len(error_mask))\n",
    "print(len(locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8268ede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/error_mask_054')\n",
    "locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/locs_054')\n",
    "#error_mask=error_mask[0:9]\n",
    "#locs=locs[0:9]\n",
    "\n",
    "#locs=locs[100:109]\n",
    "print(len(error_mask))\n",
    "print(len(locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec9b9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs      = [0,2,3]\n",
    "error_mask = ['xxxx1xxxxxxxxxxx','xxxxxxxxxxxx0xxx','1xxxxxxxxxxxxxxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66b51e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet\n",
      "index_list [[0, 18, 55, 0],\n",
      " [0, 18, 95, 0],\n",
      " [0, 18, 113, 0],\n",
      " [0, 18, 155, 0],\n",
      " [0, 18, 163, 0]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_1/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_1/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_1/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_1/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_1/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_1/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_1/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_1/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "aging_active[0] True\n",
      "index_list [[0, 20, 16, 1], [0, 21, 1, 1], [0, 21, 19, 1], [0, 22, 6, 1], [0, 22, 14, 1]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_4/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_4/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_4/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_4/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_4/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_4/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_4/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_4/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[1] True\n",
      "index_list [[0, 18, 10, 5], [0, 19, 23, 5], [0, 20, 14, 5], [0, 22, 2, 5], [0, 22, 10, 5]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_5/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_5/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_5/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_5/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_5/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_5/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_5/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_5/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[2] True\n",
      "index_list [[0, 18, 10, 5], [0, 19, 23, 5], [0, 20, 14, 5], [0, 22, 2, 5], [0, 22, 10, 5]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_8/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_8/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_8/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_8/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_8/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_8/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_8/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_8/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[3] True\n",
      "index_list [[0, 6, 7, 24], [0, 9, 8, 24], [0, 11, 0, 24], [0, 1, 3, 25], [0, 1, 11, 25]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_9/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_9/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_9/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_9/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_9/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_9/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_9/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_9/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "index_list [[0, 6, 7, 24], [0, 9, 8, 24], [0, 11, 0, 24], [0, 1, 3, 25], [0, 1, 11, 25]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_12/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_12/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_12/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_12/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_12/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_12/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_12/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_12/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[5] True\n",
      "index_list [[0, 6, 7, 24], [0, 9, 8, 24], [0, 11, 0, 24], [0, 1, 3, 25], [0, 1, 11, 25]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_15/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_15/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_15/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_15/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_15/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_15/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_15/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_15/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[6] True\n",
      "index_list [[0, 6, 7, 24], [0, 9, 8, 24], [0, 11, 0, 24], [0, 1, 3, 25], [0, 1, 11, 25]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_18/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_18/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_18/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_18/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_18/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_18/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_18/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_18/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[7] True\n",
      "index_list [[0, 0, 1, 115], [0, 0, 5, 116], [0, 3, 5, 116], [0, 4, 5, 117], [0, 0, 1, 118]]\n",
      "mod_list [[49087, 0], [49087, 0], [49087, 0], [49087, 0], [65471, 16384]]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  Tensor(\"lambda_19/SelectV2:0\", shape=(5,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_19/NotEqual:0\", shape=(5,), dtype=bool)\n",
      "valores malos Tensor(\"lambda_19/GatherNd_1:0\", shape=(None,), dtype=int32)\n",
      "valores buenos tf.print Tensor(\"lambda_19/GatherNd_2:0\", shape=(None,), dtype=int32)\n",
      "newValues DESPUES de colocar 0 Tensor(\"lambda_19/SelectV2_17:0\", shape=(None,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente Tensor(\"lambda_19/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo Tensor(\"lambda_19/TensorScatterUpdate:0\", shape=(5,), dtype=int32)\n",
      "tensor luego de aplicar la inyección de errores última Tensor(\"lambda_19/Cast_1:0\", shape=(5,), dtype=float32)\n",
      "aging_active[8] True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_list []\n",
      "mod_list []\n",
      "AddCustomLayers agin 9 True\n",
      "AddCustomLayers\n",
      "aging_active[9] True\n",
      "index_list []\n",
      "mod_list []\n",
      "aging_active[10] True\n",
      "AddCustomLayers agin 10\n",
      "Dense output_shape\n",
      "AddCustomLayers False 1\n",
      "AddCustomLayers False 2\n"
     ]
    }
   ],
   "source": [
    "#activation_aging = [True]*11\n",
    "\n",
    "#activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "#Acá la creamos, notese que como no se introduciran fallos en activaciones no es necesario pasar locs ni masks\n",
    "Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                             aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                             batch_size = testBatchSize)\n",
    "Net2.load_weights(wgt_dir).expect_partial()\n",
    "#Cuantizacion de los pesos\n",
    "WeightQuantization(model = Net2, frac_bits = 11, int_bits = 4)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "#loss_sf,acc_sf =Net2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd493a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000022D57BB4760>\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x0000022D57BBE070>\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x0000022D57BB40D0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000022D57A8F670>\n",
      "<tensorflow.python.keras.layers.core.Lambda object at 0x0000022D57BB4070>\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(Net2.layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3facb439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([1952 1960 1952 1945 1938], shape=(5,), dtype=int32)\n",
      "tensor_with_error [1952 1960 1952 1945 18322]\n",
      "tensor valores_afectados tf.Tensor([False False False False  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([18322], shape=(1,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([1938], shape=(1,), dtype=int32)\n",
      "mask del for [16384]\n",
      "newValues ANTES  [0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([1952 1960 1952 1945    0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([1952 1960 1952 1945    0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [1952 1960 1952 1945 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([0.953125   0.95703125 0.953125   0.94970703 8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [0.953125 0.95703125 0.953125 0.949707031 0.946289062]\n",
      "newValues para actualizar el tensor final [0.953125 0.95703125 0.953125 0.949707031 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([47 47 47 47 47], shape=(5,), dtype=int32)\n",
      "tensor_with_error [47 47 47 47 16431]\n",
      "tensor valores_afectados tf.Tensor([False False False False  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([16431], shape=(1,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([47], shape=(1,), dtype=int32)\n",
      "mask del for [16384]\n",
      "newValues ANTES  [0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([47 47 47 47  0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([47 47 47 47  0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [47 47 47 47 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([0.02294922 0.02294922 0.02294922 0.02294922 8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [0.0229492188 0.0229492188 0.0229492188 0.0229492188 0.0229492188]\n",
      "newValues para actualizar el tensor final [0.0229492188 0.0229492188 0.0229492188 0.0229492188 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([38 38 38 38 38], shape=(5,), dtype=int32)\n",
      "tensor_with_error [38 38 38 38 16422]\n",
      "tensor valores_afectados tf.Tensor([False False False False  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([16422], shape=(1,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([38], shape=(1,), dtype=int32)\n",
      "mask del for [16384]\n",
      "newValues ANTES  [0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([38 38 38 38  0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([38 38 38 38  0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [38 38 38 38 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([0.01855469 0.01855469 0.01855469 0.01855469 8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [0.0185546875 0.0185546875 0.0185546875 0.0185546875 0.0185546875]\n",
      "newValues para actualizar el tensor final [0.0185546875 0.0185546875 0.0185546875 0.0185546875 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([33266 33266 33266 33144  1664], shape=(5,), dtype=int32)\n",
      "tensor_with_error [33202 33202 33202 33080 18048]\n",
      "tensor valores_afectados tf.Tensor([ True  True  True  True  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([33202 33202 33202 33080 18048], shape=(5,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([33266 33266 33266 33144  1664], shape=(5,), dtype=int32)\n",
      "mask del for [64 64 64 64 16384]\n",
      "newValues ANTES  [33279 33279 33279 33151 0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([33279 33279 33279 33151     0], shape=(5,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([33279 33279 33279 33151     0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([33279 33279 33279 33151     0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [33215 33215 33215 33087 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([-0.21826172 -0.21826172 -0.21826172 -0.15576172  8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [-0.243164062 -0.243164062 -0.243164062 -0.18359375 0.8125]\n",
      "newValues para actualizar el tensor final [-0.218261719 -0.218261719 -0.218261719 -0.155761719 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([196 304 586 542 501], shape=(5,), dtype=int32)\n",
      "tensor_with_error [132 304 522 542 16821]\n",
      "tensor valores_afectados tf.Tensor([ True False  True False  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([  132   522 16821], shape=(3,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([196 586 501], shape=(3,), dtype=int32)\n",
      "mask del for [64 64 16384]\n",
      "newValues ANTES  [255 639 0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([255 639   0], shape=(3,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([255 304 639 542   0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([255 304 639 542   0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [191 304 575 542 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([0.09326172 0.1484375  0.28076172 0.26464844 8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [0.095703125 0.1484375 0.286132812 0.264648438 0.244628906]\n",
      "newValues para actualizar el tensor final [0.0932617188 0.1484375 0.280761719 0.264648438 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([33428 32977  6795 34776 34776], shape=(5,), dtype=int32)\n",
      "tensor_with_error [33428 32913 6795 34712 51096]\n",
      "tensor valores_afectados tf.Tensor([False  True False  True  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([32913 34712 51096], shape=(3,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([32977 34776 34776], shape=(3,), dtype=int32)\n",
      "mask del for [64 64 16384]\n",
      "newValues ANTES  [33023 34815 32768]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([33023 34815 32768], shape=(3,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([33428 33023  6795 34815 32768], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([33428 33023  6795 34815 32768], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [33428 32959 6795 34751 49152]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([-0.32226562 -0.09326172  3.317871   -0.9682617  -8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [-0.322265625 -0.102050781 3.31787109 -0.98046875 -0.98046875]\n",
      "newValues para actualizar el tensor final [-0.322265625 -0.0932617188 3.31787109 -0.968261719 -8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([32793   278  1194  3940  5556], shape=(5,), dtype=int32)\n",
      "tensor_with_error [32793 278 1194 3876 21940]\n",
      "tensor valores_afectados tf.Tensor([False False False  True  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([ 3876 21940], shape=(2,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([3940 5556], shape=(2,), dtype=int32)\n",
      "mask del for [64 16384]\n",
      "newValues ANTES  [3967 0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([3967    0], shape=(2,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([32793   278  1194  3967     0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([32793   278  1194  3967     0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [32793 278 1194 3903 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([-0.01220703  0.13574219  0.5830078   1.9057617   8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [-0.0122070312 0.135742188 0.583007812 1.92382812 2.71289062]\n",
      "newValues para actualizar el tensor final [-0.0122070312 0.135742188 0.583007812 1.90576172 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([33932 33932   569   704   605], shape=(5,), dtype=int32)\n",
      "tensor_with_error [33932 33932 569 640 16925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor valores_afectados tf.Tensor([False False False  True  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([  640 16925], shape=(2,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([704 605], shape=(2,), dtype=int32)\n",
      "mask del for [64 16384]\n",
      "newValues ANTES  [767 0]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([767   0], shape=(2,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([33932 33932   569   767     0], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([33932 33932   569   767     0], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [33932 33932 569 703 16384]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([-0.5683594  -0.5683594   0.27783203  0.34326172  8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [-0.568359375 -0.568359375 0.277832031 0.34375 0.295410156]\n",
      "newValues para actualizar el tensor final [-0.568359375 -0.568359375 0.277832031 0.343261719 8]\n",
      "dentro de active\n",
      "dentro de apply round\n",
      "tensor entero valores afectados  tf.Tensor([  708  1924  2273  6090 34222], shape=(5,), dtype=int32)\n",
      "tensor_with_error [644 1924 2209 6026 50606]\n",
      "tensor valores_afectados tf.Tensor([ True False  True  True  True], shape=(5,), dtype=bool)\n",
      "valores malos tf.Tensor([  644  2209  6026 50606], shape=(4,), dtype=int32)\n",
      "valores buenos tf.print tf.Tensor([  708  2273  6090 34222], shape=(4,), dtype=int32)\n",
      "mask del for [64 64 64 16384]\n",
      "newValues ANTES  [767 2303 6143 32768]\n",
      "newValues DESPUES de colocar 0 tf.Tensor([  767  2303  6143 32768], shape=(4,), dtype=int32)\n",
      "tensor_act que envio para inyectar errores nuevamente tf.Tensor([  767  1924  2303  6143 32768], shape=(5,), dtype=int32)\n",
      "new_Values que llega de redondeo tf.Tensor([  767  1924  2303  6143 32768], shape=(5,), dtype=int32)\n",
      "tensor roun luego de inyectar errores entero [703 1924 2239 6079 49152]\n",
      "tensor luego de aplicar la inyección de errores última tf.Tensor([ 0.34326172  0.9394531   1.0932617   2.9682617  -8.        ], shape=(5,), dtype=float32)\n",
      "affectedValues [0.345703125 0.939453125 1.10986328 2.97363281 -0.709960938]\n",
      "newValues para actualizar el tensor final [0.343261719 0.939453125 1.09326172 2.96826172 -8]\n"
     ]
    }
   ],
   "source": [
    "#iteretor: Toma la primera imagen del dtaset\n",
    "iterator = next(iter(test_dataset))[0]\n",
    "#outputs = [layer.output for layer in Net2.layers]  # exclude Input\n",
    "#layers_fn_inp = K.function([model.input], [model.layers[4].output])\n",
    "#layers_fn = K.function([Net2.input], [Net2.layers[5].output])\n",
    "#image = next(iterator)[0]\n",
    "#out.append(model.layers[5].output)\n",
    "out=get_all_outputs(Net2,iterator)\n",
    "out_quantizacion = out[1][0]  ## segunda capa, primer elemento del batch\n",
    "out_error_and_correction = out[2][0]  ## tercera capa, primer elemento del batch                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ce59f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.21191406 -0.21191406 -0.21191406 -0.15234375  8.8125    ], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ogdtype = valores_afectados.dtype\n",
    "shift   = 2**(16-1)\n",
    "factor  = 2**11\n",
    "tensor  = tf.cast(valores_afectados*factor,dtype=tf.int32)\n",
    "tensor  = tf.where(tf.less(tensor, 0), -tensor + shift , tensor )\n",
    "tensor  = tf.bitwise.bitwise_and(tensor,faults[:,0])\n",
    "tensor  = tf.bitwise.bitwise_or(tensor,faults[:,1])\n",
    "tensor  = tf.where(tf.greater_equal(tensor,shift), shift-tensor , tensor )\n",
    "tensor  = tf.cast(tensor/factor,dtype = Ogdtype)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d75b854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  x0xxxxxxx0xxxxxx\n",
      "Valor antes:  0.953125 En binario:  0b0000011110100000\n",
      "Valor con error + aproximacion:  0.953125 En binario:  0b0000011110100000\n",
      "-------------------------\n",
      "Error:  x0xxxxxxx0xxxxxx\n",
      "Valor antes:  0.95214844 En binario:  0b0000011110011110\n",
      "Valor con error + aproximacion:  0.95214844 En binario:  0b0000011110011110\n",
      "-------------------------\n",
      "Error:  x0xxxxxxx0xxxxxx\n",
      "Valor antes:  0.94970703 En binario:  0b0000011110011001\n",
      "Valor con error + aproximacion:  0.9472656 En binario:  0b0000011110010100\n",
      "-------------------------\n",
      "Error:  x0xxxxxxx0xxxxxx\n",
      "Valor antes:  0.9472656 En binario:  0b0000011110010100\n",
      "Valor con error + aproximacion:  0.95214844 En binario:  0b0000011110011110\n",
      "-------------------------\n",
      "Error:  x1xxxxxxx0xxxxxx\n",
      "Valor antes:  0.9453125 En binario:  0b0000011110010000\n",
      "Valor con error + aproximacion:  0.9453125 En binario:  0b0000011110010000\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "Valores_antes   = [out_quantizacion[0][0][0],out_quantizacion[0][2][0],out_quantizacion[0][3][0],out_quantizacion[0][4][0],out_quantizacion[0][5][0]]\n",
    "Valores_despues = [out_error_and_correction[0][0][0],out_error_and_correction[0][2][0],out_error_and_correction[0][4][0],out_error_and_correction[0][2][0],out_error_and_correction[0][5][0]]\n",
    "\n",
    "for i in range(5):\n",
    "    print('Error: ',error_mask[i])\n",
    "    print('Valor antes: ',Valores_antes[i],'En binario: ',convert(Valores_antes[i]))\n",
    "    print('Valor con error + aproximacion: ',Valores_despues[i],'En binario: ',convert(Valores_despues[i]))\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8248bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamaño de locs 4738\n",
      "tamaño de error_mask 4738\n",
      "AlexNet\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_1/SelectV2:0\", shape=(8448,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_1/BitwiseOr:0\", shape=(8448,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_1/NotEqual:0\", shape=(8448,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_1/GatherNd:0\", shape=(8448,), dtype=float32)\n",
      "newValues Tensor(\"lambda_1/Cast_1:0\", shape=(8448,), dtype=float32)\n",
      "newValues Tensor(\"lambda_1/Cast_1:0\", shape=(8448,), dtype=float32)\n",
      " final Tensor(\"lambda_1/TensorScatterUpdate_1:0\", shape=(None, 227, 227, 3), dtype=float32)\n",
      "aging_active[0] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_4/SelectV2:0\", shape=(17552,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_4/BitwiseOr:0\", shape=(17552,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_4/NotEqual:0\", shape=(17552,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_4/GatherNd:0\", shape=(17552,), dtype=float32)\n",
      "newValues Tensor(\"lambda_4/Cast_1:0\", shape=(17552,), dtype=float32)\n",
      "newValues Tensor(\"lambda_4/Cast_1:0\", shape=(17552,), dtype=float32)\n",
      " final Tensor(\"lambda_4/TensorScatterUpdate_1:0\", shape=(None, 55, 55, 96), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[1] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_5/SelectV2:0\", shape=(1696,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_5/BitwiseOr:0\", shape=(1696,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_5/NotEqual:0\", shape=(1696,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_5/GatherNd:0\", shape=(1696,), dtype=float32)\n",
      "newValues Tensor(\"lambda_5/Cast_1:0\", shape=(1696,), dtype=float32)\n",
      "newValues Tensor(\"lambda_5/Cast_1:0\", shape=(1696,), dtype=float32)\n",
      " final Tensor(\"lambda_5/TensorScatterUpdate_1:0\", shape=(None, 27, 27, 96), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[2] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_8/SelectV2:0\", shape=(11888,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_8/BitwiseOr:0\", shape=(11888,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_8/NotEqual:0\", shape=(11888,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_8/GatherNd:0\", shape=(11888,), dtype=float32)\n",
      "newValues Tensor(\"lambda_8/Cast_1:0\", shape=(11888,), dtype=float32)\n",
      "newValues Tensor(\"lambda_8/Cast_1:0\", shape=(11888,), dtype=float32)\n",
      " final Tensor(\"lambda_8/TensorScatterUpdate_1:0\", shape=(None, 27, 27, 256), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[3] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_9/SelectV2:0\", shape=(1280,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_9/BitwiseOr:0\", shape=(1280,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_9/NotEqual:0\", shape=(1280,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_9/GatherNd:0\", shape=(1280,), dtype=float32)\n",
      "newValues Tensor(\"lambda_9/Cast_1:0\", shape=(1280,), dtype=float32)\n",
      "newValues Tensor(\"lambda_9/Cast_1:0\", shape=(1280,), dtype=float32)\n",
      " final Tensor(\"lambda_9/TensorScatterUpdate_1:0\", shape=(None, 13, 13, 256), dtype=float32)\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_12/SelectV2:0\", shape=(1600,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_12/BitwiseOr:0\", shape=(1600,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_12/NotEqual:0\", shape=(1600,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_12/GatherNd:0\", shape=(1600,), dtype=float32)\n",
      "newValues Tensor(\"lambda_12/Cast_1:0\", shape=(1600,), dtype=float32)\n",
      "newValues Tensor(\"lambda_12/Cast_1:0\", shape=(1600,), dtype=float32)\n",
      " final Tensor(\"lambda_12/TensorScatterUpdate_1:0\", shape=(None, 13, 13, 384), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[5] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_15/SelectV2:0\", shape=(1600,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_15/BitwiseOr:0\", shape=(1600,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_15/NotEqual:0\", shape=(1600,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_15/GatherNd:0\", shape=(1600,), dtype=float32)\n",
      "newValues Tensor(\"lambda_15/Cast_1:0\", shape=(1600,), dtype=float32)\n",
      "newValues Tensor(\"lambda_15/Cast_1:0\", shape=(1600,), dtype=float32)\n",
      " final Tensor(\"lambda_15/TensorScatterUpdate_1:0\", shape=(None, 13, 13, 384), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[6] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_18/SelectV2:0\", shape=(1280,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_18/BitwiseOr:0\", shape=(1280,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_18/NotEqual:0\", shape=(1280,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_18/GatherNd:0\", shape=(1280,), dtype=float32)\n",
      "newValues Tensor(\"lambda_18/Cast_1:0\", shape=(1280,), dtype=float32)\n",
      "newValues Tensor(\"lambda_18/Cast_1:0\", shape=(1280,), dtype=float32)\n",
      " final Tensor(\"lambda_18/TensorScatterUpdate_1:0\", shape=(None, 13, 13, 256), dtype=float32)\n",
      "AddCustomLayers\n",
      "aging_active[7] True\n",
      "dentro de active\n",
      "tensor dentro de RoundValues Tensor(\"lambda_19/SelectV2:0\", shape=(384,), dtype=int32)\n",
      "tensor_with_error Tensor(\"lambda_19/BitwiseOr:0\", shape=(384,), dtype=int32)\n",
      "tensor valores_afectados Tensor(\"lambda_19/NotEqual:0\", shape=(384,), dtype=bool)\n",
      "affectedValues Tensor(\"lambda_19/GatherNd:0\", shape=(384,), dtype=float32)\n",
      "newValues Tensor(\"lambda_19/Cast_1:0\", shape=(384,), dtype=float32)\n",
      "newValues Tensor(\"lambda_19/Cast_1:0\", shape=(384,), dtype=float32)\n",
      " final Tensor(\"lambda_19/TensorScatterUpdate_1:0\", shape=(None, 6, 6, 256), dtype=float32)\n",
      "aging_active[8] True\n",
      "AddCustomLayers agin 9 True\n",
      "AddCustomLayers\n",
      "aging_active[9] True\n",
      "aging_active[10] True\n",
      "AddCustomLayers agin 10\n",
      "Dense output_shape\n",
      "AddCustomLayers False 1\n",
      "AddCustomLayers False 2\n",
      "dentro de active\n",
      "tensor dentro de RoundValues tf.Tensor([1952 1960 1952 ... 1944 1490 1915], shape=(8448,), dtype=int32)\n",
      "tensor_with_error tf.Tensor([ 1952  1960  1952 ... 10168  1490  1915], shape=(8448,), dtype=int32)\n",
      "tensor valores_afectados tf.Tensor([False False False ...  True False False], shape=(8448,), dtype=bool)\n",
      "affectedValues tf.Tensor([0.953125   0.95703125 0.953125   ... 0.94921875 0.72753906 0.9350586 ], shape=(8448,), dtype=float32)\n",
      "newValues tf.Tensor([0.953125   0.95703125 0.953125   ... 4.015625   0.72753906 0.9350586 ], shape=(8448,), dtype=float32)\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to create a NewWriteableFile: Data : Acceso denegado.\r\n; Input/output error [Op:WriteFile]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtamaño de error_mask\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(error_mask))\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#print('error_mask',error_mask)\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m loss,acc   \u001b[38;5;241m=\u001b[39m \u001b[43mCheckAccuracyAndLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlexNet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwgt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m227\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m227\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mact_frac_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_int_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwgt_frac_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwgt_int_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestBatchSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maging_active\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_faults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mfaulty_addresses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_faults\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43merror_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m Accs\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#print(Accs)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Stats_original.py:122\u001b[0m, in \u001b[0;36mCheckAccuracyAndLoss\u001b[1;34m(architecture, test_dataset, wgt_dir, act_frac_size, act_int_size, wgt_frac_size, wgt_int_size, input_shape, output_shape, faulty_addresses, masked_faults, aging_active, batch_size, verbose, weights_faults)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m \tqNet\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 122\u001b[0m \t(loss,acc) \u001b[38;5;241m=\u001b[39m \u001b[43mqNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \toutputs \u001b[38;5;241m=\u001b[39m (loss,acc)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Cleaning Memory\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1489\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1488\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1489\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1490\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1491\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1323\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_function\u001b[39m(iterator):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;124;03m\"\"\"Runs an evaluation execution with one step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1314\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1311\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m   1313\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1314\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1316\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1281\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1284\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1285\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2831\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2833\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3607\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:597\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1307\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1307\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `test_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1266\u001b[0m, in \u001b[0;36mModel.test_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1263\u001b[0m data \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mexpand_1d(data)\n\u001b[0;32m   1264\u001b[0m x, y, sample_weight \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[1;32m-> 1266\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;66;03m# Updates stateful loss metrics.\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(\n\u001b[0;32m   1269\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:420\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    403\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:556\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    553\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 556\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, nest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:919\u001b[0m, in \u001b[0;36mLambda.call\u001b[1;34m(self, inputs, mask, training)\u001b[0m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m var\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backprop\u001b[38;5;241m.\u001b[39mGradientTape(watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tape,\\\n\u001b[0;32m    918\u001b[0m     variable_scope\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[1;32m--> 919\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Nets.py:105\u001b[0m, in \u001b[0;36mGetNeuralNetworkModel.<locals>.Round\u001b[1;34m(tensor, index_list, mod_list, active)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m#print('newValues antes de actualizar al final',newValues)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m one_string \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstrings\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (affectedValues))\n\u001b[1;32m--> 105\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewValues\u001b[39m\u001b[38;5;124m'\u001b[39m,newValues)\n\u001b[0;32m    108\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtensor_scatter_nd_update(tensor, index_list, newValues)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:2264\u001b[0m, in \u001b[0;36mwrite_file\u001b[1;34m(filename, contents, name)\u001b[0m\n\u001b[0;32m   2262\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrite_file_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m   2267\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:2297\u001b[0m, in \u001b[0;36mwrite_file_eager_fallback\u001b[1;34m(filename, contents, name, ctx)\u001b[0m\n\u001b[0;32m   2295\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [filename, contents]\n\u001b[0;32m   2296\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2297\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWriteFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2298\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2299\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to create a NewWriteableFile: Data : Acceso denegado.\r\n; Input/output error [Op:WriteFile]"
     ]
    }
   ],
   "source": [
    "tfds.load('colorectal_histology')\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'AlexNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 16\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)\n",
    "#\n",
    "#\n",
    "Accs = []\n",
    "# Accs_w = []\n",
    "# Accs_a_w = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ruta_bin = 'Data/Fault Characterization/VC707/RawData'\n",
    "#ruta_bin = 'Data/Fault Characterization/KC705_B/RowData/'\n",
    "#directorio = pathlib.Path(ruta_bin)\n",
    "\n",
    "#ficheros = [fichero.name for fichero in directorio.iterdir()]\n",
    "#ficheros.sort()\n",
    "\n",
    "# for i, j in enumerate(ficheros):\n",
    "#     directorio= os.path.join(ruta_bin, j)\n",
    "#     buffer= (analize_file(directorio, buffer_size))\n",
    "#     error_mask, locs = (buffer_vectores(buffer))\n",
    "#     print(directorio)\n",
    "locs = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/locs_054')\n",
    "error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/error_mask_054')\n",
    "# error_mask=load_obj('Data/Fault Characterization/error_mask_10/vc_707/error_mask_054')\n",
    "# locs  = load_obj('Data/Fault Characterization/error_mask_10/vc_707/locs_054')\n",
    "# error_mask=load_obj('Data/Fault Characterization/error_mask_0x_10/vc_707/error_mask_054')\n",
    "# locs  = load_obj('Data/Fault Characterization/error_mask_0x_10/vc_707/locs_054')\n",
    "print('tamaño de locs',len(locs))\n",
    "print('tamaño de error_mask',len(error_mask))\n",
    "#print('error_mask',error_mask)\n",
    "\n",
    "\n",
    "\n",
    "loss,acc   = CheckAccuracyAndLoss('AlexNet', test_dataset, wgt_dir, output_shape=8, input_shape = (227,227,3),\n",
    "                                            act_frac_size = 11, act_int_size = 4, wgt_frac_size = 11, wgt_int_size = 4,\n",
    "                                            batch_size=testBatchSize, verbose = 0, aging_active = True, weights_faults = False,\n",
    "                                            faulty_addresses = locs, masked_faults = error_mask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Accs.append(acc)\n",
    "#print(Accs)\n",
    "print('AlexNet',acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [x for x,y in test_dataset]\n",
    "#salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "outputs1 = get_all_outputs(Net1,X[0])\n",
    "#salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "outputs2 = get_all_outputs(Net2,X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d923ec",
   "metadata": {},
   "source": [
    "### Definiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dba9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de bits para activaciones (a) y pesos (w)\n",
    "word_size  = 16\n",
    "afrac_size = 11  \n",
    "aint_size  = 4\n",
    "wfrac_size = 11\n",
    "wint_size  = 4\n",
    "# Tamaño del buffer de pesos == al tamaño de la capa con mayor numero de pesos (885120 pesos de 16 bits cada uno)\n",
    "#wbuffer_size = 885120*word_size\n",
    "# Tamaño del buffer de activaciones == al tamaño de la capa con mayor numero de activaciones (290400 pesos de 16 bits cada uno)\n",
    "#abuffer_size = (1024*1024)*word_size\n",
    "# Directorio de los pesos\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'AlexNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4de90",
   "metadata": {},
   "source": [
    "   ### Generación de una muestra de fallos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a884e2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4738\n",
      "mostrando las 5 primeras direcciones con fallos\n",
      "direcciones: [4141, 4181, 4199, 4241, 4249, 4309, 4410, 4425, 4473, 4525, 4527, 4593, 4661, 4685, 4737, 4789, 4899, 4903, 5001, 5009, 5107, 6836, 7830, 7900, 14395, 14481, 14523, 17254, 18015, 18039, 18073, 18193, 18199, 18343, 18355, 18365, 19243, 23681, 23719, 23863, 28631, 28702, 28788, 28894, 28956, 28958, 29020, 29022, 29150, 29152, 30522, 30526, 30534, 30576, 30586, 30995, 32461, 32683, 34226, 34352, 34400, 34436, 34476, 34602, 34604, 34666, 34716, 38517, 38545, 38583, 38833, 39903, 41111, 41291, 41299, 41449, 41805, 41983, 42869, 43076, 43580, 43658, 43810, 43854, 50849, 50899, 54967, 55913, 55995, 57613, 57679, 57913, 59338, 60952, 64022, 64062, 64280, 64342, 64360, 64428]\n",
      "mascara de fallos: ['x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x0xxxxxxx0xxxxxx', 'x1xxxxxxx0xxxxxx', 'x0xxxxxxx1xxxxxx', 'xxxxxx1xxxxxxx1x', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx1xxxxxx', 'x0xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x0xxxxxxx1xxxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx1xxxxxx', 'x0xxxxxxx1xxxxxx', 'x0xxxxxxx0xxxxxx', '0xxxxxxx0xxxxxxx', '0xxxxxxx1xxxxxxx', 'xxxxx10xxxxxx00x', 'x1xxxxxxx0xxxxxx', 'xxx0xxxxxxx1xxxx', 'xxx1xxxxxxx1xxxx', 'xxx0xxxxxxx0xxxx', 'xxxx1xxxxxxx0xxx', 'x0xxxxxxx1xxxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x0xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'xx1xxxxxxx0xxxxx', 'xxxx1xxxxxxx0xxx', 'xxxx1xxxxxxx0xxx', 'xxxx0xxxxxxx1xxx', '0xxxxxxx1xxxxxxx', 'xx0xxxxxxx1xxxxx', 'xx1xxxxxxx1xxxxx', 'xx0xxxxxxx0xxxxx', 'xx1xxxxxxx0xxxxx', 'xx1xxxxxxx0xxxxx', 'xx1xxxxxxx1xxxxx', 'xx0xxxxxxx0xxxxx', 'xx0xxxxxxx1xxxxx', 'xx1xxxxxxx1xxxxx', 'x1xxxxxxx0xxxxxx', 'xxxxxx1xxxxxxx1x', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x0xxxxxxx1xxxxxx', 'xxxx1xxxxxxx0xxx', 'xxx0xxxxxxx1xxxx', 'x0xxxxxxx1xxxxxx', 'xx1xxxxxxx1xxxxx', 'xx0xxxxxxx1xxxxx', 'xx1xxxxxxx1xxxxx', 'xxx0xxxxxxx1xxxx', 'xx0xxxxxxx1xxxxx', 'xx0xxxxxxx0xxxxx', 'xx0xxxxxxx1xxxxx', 'xx1xxxxxxx0xxxxx', 'xx1xxxxxxx0xxxxx', 'xxxx1xxxxxxx1xxx', 'xxxx1xxxxxxx1xxx', 'xxxx0xxxxxxx1xxx', 'xxxx0xxxxxxx0xxx', 'xxxx0xxxxxxx1xxx', 'xxxxxxx0xxxxxxx0', 'xxxxxxx1xxxxxxx1', 'xxxxxxx1xxxxxxx0', 'xxxxxxx0xxxxxxx1', 'xxxxxxx0xxxxxxx1', 'xxxxxxx1xxxxxxx1', 'xxxxxxx0xxxxxxx1', 'xxxx1xxxxxxx0xxx', 'xxxx1xxxxxxx1xxx', 'xxxxx0xxxxxxx0xx', 'xxx1xxxxxxx0xxxx', 'xxxxx0xxxxxxx0xx', 'xxxxxx1xxxxxxx0x', 'xx0xxxxxxx1xxxxx', 'xxxxx0xxxxxxx0xx', 'xxx1xxxxxxx0xxxx', 'xxx0xxxxxxx1xxxx', 'xxxxxx1xxxxxxx0x', 'xxxxxx1xxxxxxx0x', 'xxxxxx1xxxxxxx0x', 'xxxxxxx0xxxxxxx1', 'xx1xxxxxxx1xxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx0xxxxxx', 'x1xxxxxxx1xxxxxx', 'x1xxxxxxx0xxxxxx', 'x0xxxxxxx1xxxxxx', 'x1xxxxxxx1xxxxxx']\n",
      "4738\n"
     ]
    }
   ],
   "source": [
    "# Decidir si cargar errores de un archivo locs y error_mask o generarlos aleatoriamente\n",
    "Cargar_errores = True\n",
    "\n",
    "#print(load_file('Data/Fault Characterization/wgt/Accs_w_707_55'))\n",
    "\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/error_mask_054')\n",
    "    #locs  = load_obj('Data/Fault Characterization/error_mask y locs_buffer_pesos_vc-707/locs_0_54_buffer_pesos')\n",
    "    #error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_pesos_vc-707/error_mask_0_54_buffer_pesos')\n",
    "else:\n",
    "    \n",
    "    \n",
    "    locs = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/locs_0_54')\n",
    "    numero_bits_con_fallo = len(locs)\n",
    "    bits_con_fallo = np.random.randint(0,2,numero_bits_con_fallo)\n",
    "    mbuffer = np.array(['0']*(abuffer_size-numero_bits_con_fallo))\n",
    "    mbuffer = np.concatenate([mbuffer,bits_con_fallo])\n",
    "    #Convertirlo en vectores de 16 elementos\n",
    "    mbuffer = np.reshape(mbuffer,(-1,word_size))\n",
    "    mbuffer = [\"\".join(i) for i in mbuffer]\n",
    "    error_mask=mbuffer[0:numero_bits_con_fallo]\n",
    "    #more_posiction_errors=len(error_mask)-len(locs)\n",
    "\n",
    "#print(more_posiction_errors)\n",
    "print(len(locs)) \n",
    "print('mostrando las 5 primeras direcciones con fallos')\n",
    "print('direcciones:',locs[0:100])\n",
    "print('mascara de fallos:',error_mask[0:100])\n",
    "print(len(error_mask))\n",
    "#print(more_posiction_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903b555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.242446001280832\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "shape=(227,227,3)\n",
    "address=64022\n",
    "actMap = address//(shape[0]*shape[1])\n",
    "actMapd = address/(shape[0]*shape[1])\n",
    "print(actMapd)\n",
    "print(actMap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3d2b2",
   "metadata": {},
   "source": [
    "## Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9c9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c889d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/error_mask_054')\n",
    "locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/locs_054')\n",
    "#error_mask=error_mask[0:9]\n",
    "#locs=locs[0:9]\n",
    "\n",
    "#locs=locs[100:109]\n",
    "print(len(error_mask))\n",
    "print(len(locs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308e2cc",
   "metadata": {},
   "source": [
    "### Crear la red sin fallos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ba450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "activation_aging = [False]*11\n",
    "\n",
    "\n",
    "#Acá la creamos, notese que como no se introduciran fallos en activaciones no es necesario pasar locs ni masks\n",
    "Net1 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, aging_active=activation_aging,\n",
    "                             word_size=word_size, frac_size=afrac_size, batch_size = testBatchSize)\n",
    "Net1.load_weights(wgt_dir).expect_partial()\n",
    "#Net1_procces = Net1.get_weights()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "#WeightQuantization(model = Net1, frac_bits = wfrac_size, int_bits = wint_size)\n",
    "Net1.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "#Net1_procces = Net1.get_weights()\n",
    "#loss_sf,acc_sf =Net1.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b0042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n",
      "750/750 [==============================] - 74s 98ms/step - loss: 2.6147 - accuracy: 0.4493\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_aging = [True]*11\n",
    "\n",
    "#activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "#Acá la creamos, notese que como no se introduciran fallos en activaciones no es necesario pasar locs ni masks\n",
    "Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                             aging_active=activation_aging, word_size=word_size, frac_size=afrac_size, \n",
    "                             batch_size = testBatchSize)\n",
    "Net2.load_weights(wgt_dir).expect_partial()\n",
    "#Cuantizacion de los pesos\n",
    "#WeightQuantization(model = Net2, frac_bits = wfrac_size, int_bits = wint_size)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "#loss_sf,acc_sf =Net2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8deee6",
   "metadata": {},
   "source": [
    "# Crear red con fallos en todas las capas a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0544dc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n"
     ]
    }
   ],
   "source": [
    "neighbor_exp=True\n",
    "activation_aging = [True]*11\n",
    "\n",
    "#activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "#Acá la creamos, notese que como no se introduciran fallos en activaciones no es necesario pasar locs ni masks\n",
    "Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                             aging_active=activation_aging, word_size=word_size, frac_size=afrac_size, \n",
    "                             batch_size = testBatchSize)\n",
    "Net2.load_weights(wgt_dir).expect_partial()\n",
    "#Cuantizacion de los pesos\n",
    "#WeightQuantization(model = Net2, frac_bits = wfrac_size, int_bits = wint_size)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "#loss_sf,acc_sf =Net2.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21621c10",
   "metadata": {},
   "source": [
    "## Función para guardar en dataframe to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c5a7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def same_elements(outputs1,outputs2,ciclo,acc_list):\n",
    "    \n",
    "    \n",
    "    write_layer=[2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "    #FZNET\n",
    "    #write_layer = [2,6,10,14,18,22,26,30,32,36,39,43]\n",
    "\n",
    "\n",
    "             \n",
    "             \n",
    "    \n",
    "    for index in range(0,len(outputs2)):\n",
    "        if index == write_layer[ciclo] and Net2.layers[index].__class__.__name__=='Lambda':\n",
    "            #for i, layer in enumerate(write_layer):\n",
    "            print('Capa',index,Net2.layers[index].__class__.__name__)\n",
    "            a=outputs1[index]== outputs2[index]\n",
    "            size_output=a.size\n",
    "            output_true=np.sum(a)\n",
    "            numero.append(index)\n",
    "            print('numero', numero)\n",
    "            capa.append(Net2.layers[index].__class__.__name__)\n",
    "            print('capa', capa)\n",
    "            #list_output_true.append(output_true)\n",
    "            list_size_output.append(size_output)\n",
    "            amount_dif=size_output-output_true\n",
    "            print(amount_dif)\n",
    "            list_amount_dif.append(amount_dif)\n",
    "            ratio=((amount_dif*100)/size_output)\n",
    "            list_ratio.append(ratio)\n",
    "            non_zero = (np.count_nonzero(outputs2[index]))\n",
    "            total_zero= size_output-non_zero\n",
    "            ratio_zero=((total_zero*100)/size_output)\n",
    "            list_ratio_zero.append(ratio_zero)\n",
    "            list_total_zero.append(total_zero)\n",
    "    return(numero,capa,list_size_output,list_amount_dif,list_ratio,list_total_zero,list_ratio_zero)        \n",
    "    #df_numero=pd.DataFrame(numero)\n",
    "    #df_capa=pd.DataFrame(capa)\n",
    "    #print('df_capa', df_capa)\n",
    "    #df_acc=pd.DataFrame(acc_list)\n",
    "    #df_list_size_output=pd.DataFrame(list_size_output)\n",
    "    #df_list_output_diff=pd.DataFrame(list_amount_dif)\n",
    "    #df_list_ratio=pd.DataFrame(list_ratio)\n",
    "    #df_list_elem_zero=pd.DataFrame(list_total_zero)\n",
    "    #df_list_ratio_zero=pd.DataFrame(list_ratio_zero)\n",
    "    #    \n",
    "    #buf_same_elemen = pd.concat([df_numero,df_capa,df_list_size_output,df_list_output_diff,df_list_ratio,df_acc, df_list_elem_zero, df_list_ratio_zero], axis=1, join='outer')\n",
    "    #buf_same_elemen.columns = ['Num','Capa','T_actv', 'dif_elem', '%','Acc', 'Act_0', '%']\n",
    "    #buf_same_elemen.to_excel(writer, sheet_name='ratio_'+ str(architecture), index=False)\n",
    "                \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14422bf",
   "metadata": {},
   "source": [
    "## Función me guarda el contenido d etodas las capas en cada iteración en pestañas diferentes seggún la condición del ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53adced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same(outputs1,outputs2,ciclo):\n",
    "    \n",
    "    list_size_output=[]\n",
    "    list_output_true=[]\n",
    "    list_amount_dif=[]\n",
    "    list_ratio=[]\n",
    "    list_ratio_zero=[]\n",
    "    list_total_zero=[]\n",
    "    numero=[]\n",
    "    capa=[]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    for index in range(0,len(outputs2)):\n",
    "        \n",
    "        #print('Capa',index,Net2.layers[index].__class__.__name__)\n",
    "        a=outputs1[index]== outputs2[index]\n",
    "        size_output=a.size\n",
    "        print('size_output', size_output)\n",
    "        output_true=np.sum(a)\n",
    "        print('output_true',output_true)\n",
    "        numero.append(index)\n",
    "        capa.append(Net2.layers[index].__class__.__name__)\n",
    "        list_output_true.append(output_true)\n",
    "        list_size_output.append(size_output)\n",
    "        print(list_size_output)\n",
    "        amount_dif=size_output-output_true\n",
    "        list_amount_dif.append(amount_dif)\n",
    "        ratio=((amount_dif*100)/size_output)\n",
    "        list_ratio.append(ratio)\n",
    "        non_zero = (np.count_nonzero(outputs2[index]))\n",
    "        total_zero= size_output-non_zero\n",
    "        ratio_zero=((total_zero*100)/size_output)\n",
    "        list_ratio_zero.append(ratio_zero)\n",
    "        list_total_zero.append(total_zero)\n",
    "\n",
    "        df_numero=pd.DataFrame(numero)\n",
    "        df_capa=pd.DataFrame(capa)\n",
    "        df_list_size_output=pd.DataFrame(list_size_output)\n",
    "        df_list_output_diff=pd.DataFrame(list_amount_dif)\n",
    "        df_list_ratio=pd.DataFrame(list_ratio)\n",
    "        df_list_elem_zero=pd.DataFrame(list_total_zero)\n",
    "        df_list_ratio_zero=pd.DataFrame(list_ratio_zero)\n",
    "        \n",
    "        buf_same_elemen = pd.concat([df_numero,df_capa,df_list_size_output,df_list_output_diff, df_list_ratio, df_list_elem_zero, df_list_ratio_zero], axis=1, join='outer')\n",
    "        buf_same_elemen.columns = ['num','capa','Total_elements_layer', 'diff_elements', 'Ratio', 'amount_zero', 'Ratio']\n",
    "        buf_same_elemen.to_excel(writer, sheet_name='ratio_'+ str(ciclo), index=False)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "742d1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciclo 0\n",
      "[ True False False False False False False False False False False]\n",
      "Redondeo\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m         outputs2 \u001b[38;5;241m=\u001b[39m get_all_outputs(Net2,X[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m#print(outputs1)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;66;03m#print(outputs2)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;66;03m#print('list_ciclo',list_ciclo)\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;66;03m#same_elements(outputs1,outputs2,list_ciclo,acc_list)\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m         \u001b[43msame_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutputs2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mciclo\u001b[49m\u001b[43m,\u001b[49m\u001b[43macc_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m## De esta forma es cuando quiero guardar solo las capas que escriben en el buffer\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ciclo\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(activation_aging)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\funciones.py:73\u001b[0m, in \u001b[0;36msame_elements\u001b[1;34m(outputs1, outputs2, ciclo, Net2)\u001b[0m\n\u001b[0;32m     67\u001b[0m list_ratio\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(outputs2)):\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapa\u001b[39m\u001b[38;5;124m'\u001b[39m,index,\u001b[43mNet2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m[index]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     74\u001b[0m     a\u001b[38;5;241m=\u001b[39moutputs1[index]\u001b[38;5;241m==\u001b[39m outputs2[index]\n\u001b[0;32m     75\u001b[0m     size_output\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "neighbor_exp=True\n",
    "activation_aging = np.array([False]*11)\n",
    "acc_list=[]\n",
    "list_ciclo=[]\n",
    "list_size_output=[]\n",
    "list_size_output=[]\n",
    "list_output_true=[]\n",
    "list_amount_dif=[]\n",
    "list_ratio=[]\n",
    "list_ratio_zero=[]\n",
    "list_total_zero=[]\n",
    "numero=[]\n",
    "capa=[]\n",
    "\n",
    "with pd.ExcelWriter('AlexNet/ratio_pruebas_error_mask_borrar.xlsx') as writer:\n",
    "#from openpyxl import Workbook\n",
    "#from openpyxl import load_workbook\n",
    "#wb=Workbook()\n",
    "#wb.save('AlexNet/ratio_element_diff_pruebas.xlsx')\n",
    "\n",
    "\n",
    "    for i, valor in enumerate(activation_aging):\n",
    "        ciclo=i\n",
    "        print('ciclo',ciclo)\n",
    "        activation_aging[i]=True \n",
    "        activation_aging[i-1]=False    \n",
    "        print (activation_aging)\n",
    "    #activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "    #activation_aging= False\n",
    "        Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=activation_aging, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "        Net2.load_weights(wgt_dir).expect_partial()\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "        #loss,acc  = Net2.evaluate(test_dataset)\n",
    "        #acc_list.append(acc)\n",
    "        #list_ciclo.append(i)\n",
    "        \n",
    "        X = [x for x,y in test_dataset]\n",
    "        #salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "        outputs1= get_all_outputs(Net1,X[0])\n",
    "        #salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "        outputs2 = get_all_outputs(Net2,X[0])\n",
    "        #print(outputs1)\n",
    "        #print(outputs2)\n",
    "        #print('list_ciclo',list_ciclo)\n",
    "        #same_elements(outputs1,outputs2,list_ciclo,acc_list)\n",
    "        same_elements(outputs1,outputs2,ciclo,acc_list)\n",
    "## De esta forma es cuando quiero guardar solo las capas que escriben en el buffer\n",
    "    if ciclo==len(activation_aging)-1:\n",
    "        last_layer=ciclo+1\n",
    "        same_elements(outputs1, outputs2, last_layer, 0)\n",
    "    df_numero=pd.DataFrame(numero)\n",
    "    df_capa=pd.DataFrame(capa)\n",
    "    df_acc=pd.DataFrame(acc_list)\n",
    "    df_list_size_output=pd.DataFrame(list_size_output)\n",
    "    df_list_output_diff=pd.DataFrame(list_amount_dif)\n",
    "    df_list_ratio=pd.DataFrame(list_ratio)\n",
    "    df_list_elem_zero=pd.DataFrame(list_total_zero)\n",
    "    df_list_ratio_zero=pd.DataFrame(list_ratio_zero)\n",
    "        \n",
    "    buf_same_elemen = pd.concat([df_numero,df_capa,df_list_size_output,df_list_output_diff,df_list_ratio,df_acc, df_list_elem_zero, df_list_ratio_zero], axis=1, join='outer')\n",
    "    buf_same_elemen.columns = ['Num','Capa','T_actv', 'dif_elem', '%','Acc', 'Act_0', '%']\n",
    "    #buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\n",
    "    #buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\n",
    "    #writer=pd.ExcelWriter('AlexNet/ratio.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    buf_same_elemen.to_excel(writer,sheet_name='datos1',startcol = 2, index=False)\n",
    "    writer.save()\n",
    "    \n",
    "    #buf_same_elemen.to_excel(writer, writer.worksheets[1].title, startcol = 3,  index = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "print('Ejecución  completada: ', datetime.now().strftime(\"%H:%M:%S\"))   \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "acc_list\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210edfbd",
   "metadata": {},
   "source": [
    "## prueba lueho borro el de arriba si sale bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5de6078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciclo 0\n",
      "[ True False False False False False False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 70s 93ms/step - loss: 0.7251 - accuracy: 0.7320\n",
      "Capa 2 Lambda\n",
      "numero [2]\n",
      "capa ['Lambda']\n",
      "570\n",
      "ciclo 1\n",
      "[False  True False False False False False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 49s 65ms/step - loss: 1.9566 - accuracy: 0.6187\n",
      "Capa 8 Lambda\n",
      "numero [2, 8]\n",
      "capa ['Lambda', 'Lambda']\n",
      "1193\n",
      "ciclo 2\n",
      "[False False  True False False False False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.5324 - accuracy: 0.7453\n",
      "Capa 10 Lambda\n",
      "numero [2, 8, 10]\n",
      "capa ['Lambda', 'Lambda', 'Lambda']\n",
      "103\n",
      "ciclo 3\n",
      "[False False False  True False False False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 50s 66ms/step - loss: 0.3126 - accuracy: 0.8893\n",
      "Capa 16 Lambda\n",
      "numero [2, 8, 10, 16]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "790\n",
      "ciclo 4\n",
      "[False False False False  True False False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 53s 70ms/step - loss: 0.3141 - accuracy: 0.8867\n",
      "Capa 18 Lambda\n",
      "numero [2, 8, 10, 16, 18]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "82\n",
      "ciclo 5\n",
      "[False False False False False  True False False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 51s 67ms/step - loss: 0.3090 - accuracy: 0.8947\n",
      "Capa 24 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "102\n",
      "ciclo 6\n",
      "[False False False False False False  True False False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 63s 84ms/step - loss: 0.3116 - accuracy: 0.8960\n",
      "Capa 30 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "113\n",
      "ciclo 7\n",
      "[False False False False False False False  True False False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 55s 73ms/step - loss: 0.3166 - accuracy: 0.8853\n",
      "Capa 36 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30, 36]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "90\n",
      "ciclo 8\n",
      "[False False False False False False False False  True False False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 50s 66ms/step - loss: 0.3196 - accuracy: 0.8853\n",
      "Capa 38 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30, 36, 38]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "27\n",
      "ciclo 9\n",
      "[False False False False False False False False False  True False]\n",
      "Redondeo\n",
      "750/750 [==============================] - 46s 61ms/step - loss: 0.3179 - accuracy: 0.8827\n",
      "Capa 44 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30, 36, 38, 44]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "0\n",
      "ciclo 10\n",
      "[False False False False False False False False False False  True]\n",
      "Redondeo\n",
      "750/750 [==============================] - 45s 60ms/step - loss: 0.3179 - accuracy: 0.8827\n",
      "Capa 49 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30, 36, 38, 44, 49]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "0\n",
      "Capa 53 Lambda\n",
      "numero [2, 8, 10, 16, 18, 24, 30, 36, 38, 44, 49, 53]\n",
      "capa ['Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda', 'Lambda']\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 8 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m df_list_ratio_zero\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(list_ratio_zero)\n\u001b[0;32m     96\u001b[0m buf_same_elemen \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_numero,df_capa,df_list_size_output,df_list_output_diff,df_list_ratio,df_acc, df_list_elem_zero, df_list_ratio_zero], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m buf_same_elemen\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapa\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_actv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdif_elem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAct_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m#buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m#writer=pd.ExcelWriter('AlexNet/ratio.xlsx', engine='xlsxwriter')\u001b[39;00m\n\u001b[0;32m    102\u001b[0m buf_same_elemen\u001b[38;5;241m.\u001b[39mto_excel(writer,sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatos1\u001b[39m\u001b[38;5;124m'\u001b[39m,startcol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 7 elements, new values have 8 elements"
     ]
    }
   ],
   "source": [
    "#Cargar_errores = True\n",
    "#\n",
    "#\n",
    "#if Cargar_errores:\n",
    "#    locs  = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/locs_0_54')\n",
    "#    error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_act_vc-707/error_mask_0_54')\n",
    "#else:\n",
    "#    numero_bits_con_fallo = 1000\n",
    "#    bits_con_fallo = np.random.randint(0,2,numero_bits_con_fallo)\n",
    "#    #crear una mascara (m) del buffer de pesos donde x: bit sin fallo, 0: bit con fallo en 0, 1: bit con fallo en 1.\n",
    "#    #si quieres introducir fallos en activaciones en lugar de los pesos, simplemente cambia wbuffer_size por abuffer_size.\n",
    "#    mbuffer = np.array(['x']*(abuffer_size-numero_bits_con_fallo))\n",
    "#    mbuffer = np.concatenate([mbuffer,bits_con_fallo])\n",
    "#    #distribuir los errores aleatoriamente en la mascara del buffer\n",
    "#    np.random.shuffle(mbuffer)\n",
    "#    #organizar la mascara del buffer por direcciones\n",
    "#    mbuffer = np.reshape(mbuffer,(-1,word_size))\n",
    "#    mbuffer = [\"\".join(i) for i in mbuffer]\n",
    "#    #filtrar dejando solo las direcciones con error\n",
    "#    locs  = [x for x,y in enumerate(mbuffer) if y.count('x') < 16]\n",
    "#    masks = [y for x,y in enumerate(mbuffer) if y.count('x') < 16] \n",
    "#print('mostrando las 5 primeras direcciones con fallos')\n",
    "#print('direcciones:',locs[0:5])\n",
    "#print('mascara de fallos:',error_mask[0:5])\n",
    "#print(len(error_mask))\n",
    "\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "neighbor_exp=True\n",
    "activation_aging = np.array([False]*11)\n",
    "acc_list=[]\n",
    "list_ciclo=[]\n",
    "list_size_output=[]\n",
    "list_size_output=[]\n",
    "list_output_true=[]\n",
    "list_amount_dif=[]\n",
    "list_ratio=[]\n",
    "list_ratio_zero=[]\n",
    "list_total_zero=[]\n",
    "numero=[]\n",
    "capa=[]\n",
    "\n",
    "with pd.ExcelWriter('AlexNet/ratio_pruebas_error_mask_borrar.xlsx') as writer:\n",
    "#from openpyxl import Workbook\n",
    "#from openpyxl import load_workbook\n",
    "#wb=Workbook()\n",
    "#wb.save('AlexNet/ratio_element_diff_pruebas.xlsx')\n",
    "\n",
    "\n",
    "    for i, valor in enumerate(activation_aging):\n",
    "        ciclo=i\n",
    "        print('ciclo',ciclo)\n",
    "        activation_aging[i]=True \n",
    "        activation_aging[i-1]=False    \n",
    "        print (activation_aging)\n",
    "    #activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "    #activation_aging= False\n",
    "        Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=activation_aging, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "        Net2.load_weights(wgt_dir).expect_partial()\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "        loss,acc  = Net2.evaluate(test_dataset)\n",
    "        #acc_list.append(acc)\n",
    "        #list_ciclo.append(i)\n",
    "        \n",
    "        X = [x for x,y in test_dataset]\n",
    "        #salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "        outputs1= get_all_outputs(Net1,X[0])\n",
    "        #salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "        outputs2 = get_all_outputs(Net2,X[0])\n",
    "        #print(outputs1)\n",
    "        #print(outputs2)\n",
    "        #print('list_ciclo',list_ciclo)\n",
    "        #same_elements(outputs1,outputs2,list_ciclo,acc_list)\n",
    "        same_elements(outputs1,outputs2,ciclo,acc_list)\n",
    "## De esta forma es cuando quiero guardar solo las capas que escriben en el buffer\n",
    "    if ciclo==len(activation_aging)-1:\n",
    "        last_layer=ciclo+1\n",
    "        same_elements(outputs1, outputs2, last_layer, 0)\n",
    "    df_numero=pd.DataFrame(numero)\n",
    "    df_capa=pd.DataFrame(capa)\n",
    "    df_acc=pd.DataFrame(acc_list)\n",
    "    df_list_size_output=pd.DataFrame(list_size_output)\n",
    "    df_list_output_diff=pd.DataFrame(list_amount_dif)\n",
    "    df_list_ratio=pd.DataFrame(list_ratio)\n",
    "    df_list_elem_zero=pd.DataFrame(list_total_zero)\n",
    "    df_list_ratio_zero=pd.DataFrame(list_ratio_zero)\n",
    "        \n",
    "    buf_same_elemen = pd.concat([df_numero,df_capa,df_list_size_output,df_list_output_diff,df_list_ratio,df_acc, df_list_elem_zero, df_list_ratio_zero], axis=1, join='outer')\n",
    "    buf_same_elemen.columns = ['Num','Capa','T_actv', 'dif_elem', '%','Acc', 'Act_0', '%']\n",
    "    #buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\n",
    "    #buf_same_elemen.to_excel(writer, sheet_name='ratio', index=False)\n",
    "    #writer=pd.ExcelWriter('AlexNet/ratio.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    buf_same_elemen.to_excel(writer,sheet_name='datos1',startcol = 2, index=False)\n",
    "    writer.save()\n",
    "    \n",
    "    #buf_same_elemen.to_excel(writer, writer.worksheets[1].title, startcol = 3,  index = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "print('Ejecución  completada: ', datetime.now().strftime(\"%H:%M:%S\"))   \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "acc_list\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd977dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "wb=Workbook()\n",
    "wb.save('AlexNet/ratio_element_diff_pruebas.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f954968",
   "metadata": {},
   "source": [
    "### Crear la red con fallos en activaciones en ciclo de vectores true and false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c3fa897",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'AlexNet_sinageing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m acc_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m list_ciclo\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAlexNet_sinageing/ratio_element_diff.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, valor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(activation_aging):\n\u001b[0;32m     11\u001b[0m         ciclo\u001b[38;5;241m=\u001b[39mi\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:191\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1103\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1104\u001b[0m )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheets: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\common.py:694\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 694\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\pandas\\io\\common.py:568\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    566\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'AlexNet_sinageing'"
     ]
    }
   ],
   "source": [
    "activation_aging = np.array([False]*11)\n",
    "acc_list=[]\n",
    "list_ciclo=[]\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('AlexNet_sinageing/ratio_element_diff.xlsx') as writer:\n",
    "    \n",
    "\n",
    "\n",
    "    for i, valor in enumerate(activation_aging):\n",
    "        ciclo=i\n",
    "        activation_aging[i]=True \n",
    "        activation_aging[i-1]=False    \n",
    "        print (activation_aging)\n",
    "    #activation_aging = [False,False,False,False,True,False,False,False,False,False,False]\n",
    "    #activation_aging= False\n",
    "        Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=activation_aging, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "        Net2.load_weights(wgt_dir).expect_partial()\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "        loss,acc  = Net2.evaluate(test_dataset)\n",
    "        acc_list.append(acc)\n",
    "        print(acc_list)\n",
    "        #list_ciclo.append(i)\n",
    "        \n",
    "        X = [x for x,y in test_dataset]\n",
    "        #salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "        outputs1= get_all_outputs(Net1,X[0])\n",
    "        #salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "        outputs2 = get_all_outputs(Net2,X[0])\n",
    "        #print(outputs1)\n",
    "        #print(outputs2)\n",
    "        #print('list_ciclo',list_ciclo)\n",
    "        #same_elements(outputs1,outputs2,list_ciclo,acc_list)\n",
    "        same_elements(outputs1,outputs2,ciclo)\n",
    "writer.close        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "print('Ejecución  completada: ', datetime.now().strftime(\"%H:%M:%S\"))   \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b19b6406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "Capa 2 Lambda\n",
      "0\n",
      "Cantidad de elementos en 0: 0 de un total de: 154587 ratio: 0.0 %\n",
      "yes\n",
      "Capa 8 Lambda\n",
      "9064\n",
      "Cantidad de elementos en 0: 9064 de un total de: 290400 ratio: 3.121212121212121 %\n",
      "yes\n",
      "Capa 10 Lambda\n",
      "2153\n",
      "Cantidad de elementos en 0: 2153 de un total de: 69984 ratio: 3.0764174668495654 %\n",
      "yes\n",
      "Capa 16 Lambda\n",
      "21\n",
      "Cantidad de elementos en 0: 21 de un total de: 186624 ratio: 0.011252572016460906 %\n",
      "yes\n",
      "Capa 18 Lambda\n",
      "2\n",
      "Cantidad de elementos en 0: 2 de un total de: 43264 ratio: 0.004622781065088758 %\n",
      "yes\n",
      "Capa 24 Lambda\n",
      "3\n",
      "Cantidad de elementos en 0: 3 de un total de: 64896 ratio: 0.004622781065088758 %\n",
      "yes\n",
      "Capa 30 Lambda\n",
      "4\n",
      "Cantidad de elementos en 0: 4 de un total de: 64896 ratio: 0.00616370808678501 %\n",
      "yes\n",
      "Capa 36 Lambda\n",
      "3\n",
      "Cantidad de elementos en 0: 3 de un total de: 43264 ratio: 0.006934171597633136 %\n",
      "yes\n",
      "Capa 38 Lambda\n",
      "3\n",
      "Cantidad de elementos en 0: 3 de un total de: 9216 ratio: 0.032552083333333336 %\n",
      "yes\n",
      "Capa 44 Lambda\n",
      "3778\n",
      "Cantidad de elementos en 0: 3778 de un total de: 4096 ratio: 92.236328125 %\n",
      "yes\n",
      "Capa 49 Lambda\n",
      "3448\n",
      "Cantidad de elementos en 0: 3448 de un total de: 4096 ratio: 84.1796875 %\n",
      "yes\n",
      "Capa 53 Lambda\n",
      "5\n",
      "Cantidad de elementos en 0: 5 de un total de: 8 ratio: 62.5 %\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from numpy import array\n",
    "write_layer=[2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "for index in range(0,len(outputs2)):\n",
    "    #if Net2.layers[index].__class__.__name__== 'Lambda' and write_layer.index(i):\n",
    "    if index in write_layer and Net2.layers[index].__class__.__name__== 'Lambda':\n",
    "        print('yes')      \n",
    "        print('Capa',index,Net2.layers[index].__class__.__name__)\n",
    "        a=(np.count_nonzero(outputs2[index]))\n",
    "        b=(outputs2[index].size)\n",
    "        print(b-a)\n",
    "        c= b-a\n",
    "        x= (c*100)/b\n",
    "        print('Cantidad de elementos en 0:', c , 'de un total de:', b , 'ratio:', x, '%')\n",
    "             \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf75890",
   "metadata": {},
   "source": [
    "## Analizar Accurancy inyectando errores en la última Capa\n",
    "### Lo haré con la máscara de error del buffer de pesos para el voltaje 0.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0bfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mostrando las 5 primeras direcciones con fallos\n",
      "direcciones: [343, 583, 601, 631, 653, 671, 809, 841, 843, 875, 899, 913, 937, 941, 953, 969, 1312, 1422, 2079, 2179]\n",
      "mascara de fallos: ['xxxx0xxxxxxx0xxx', 'x0xxxxxxx0xxxxxx', '00xxxxxx00xxxxxx', 'xxxxxx1xxxxxxx0x', '0xxxxxxx1xxxxxxx', 'xxxxxx1xxxxxxx1x', 'xxxx1xxxxxxx1xxx', 'xxxxxx1xxxxxxx1x', 'x0xxxx0xx1xxxx1x', 'xxxxxx0xxxxxxx1x', 'xxxx1xxxxxxx0xxx', 'xxxxxx1xxxxxxx1x', 'xxxxxxx1xxxxxxx0', 'x1xxxxxxx1xxxxxx', 'xxxxxx1xxxxxxx1x', 'xxxxxx1xxxxxxx1x', 'xxxxxx0xxxxxxx1x', 'xxxxxx0xxxxxxx0x', 'xxxx0xxxxxxx0xxx', 'xxxx0xxxxxxx1xxx']\n",
      "6265\n",
      "6265\n"
     ]
    }
   ],
   "source": [
    "Cargar_errores = True\n",
    "\n",
    "\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/error_mask y locs_buffer_pesos_vc-707/locs_0_54_buffer_pesos')\n",
    "    error_mask = load_obj('Data/Fault Characterization/error_mask y locs_buffer_pesos_vc-707/error_mask_0_54_buffer_pesos')\n",
    "print('mostrando las 5 primeras direcciones con fallos')\n",
    "print('direcciones:',locs[0:20])\n",
    "print('mascara de fallos:',error_mask[0:20])\n",
    "print(len(error_mask))\n",
    "print(len(locs))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4e1cb",
   "metadata": {},
   "source": [
    "### inyectando errres en toda las capas este es lo que se optiene accuracy: 0.3613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4dc82eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n",
      "65471\n"
     ]
    }
   ],
   "source": [
    "mask='x1xxxxxxx0xxxxxx'\n",
    "error_1  = int(\"\".join(mask.replace('x','0')),2)\n",
    "error_0  = int(\"\".join(mask.replace('x','1')),2)\n",
    "print(error_1)\n",
    "print(error_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca7c2d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "49086\n"
     ]
    }
   ],
   "source": [
    "if static_1_error !=0:\n",
    "    static_1_error=static_1_error-1\n",
    "if  static_0_Error!=0:\n",
    "    static_0_Error=static_0_Error-1   \n",
    "print(static_1_error)\n",
    "print(static_0_Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec353cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "-1=32769\n",
    "-72=32840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d4a6376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32769"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(-1)+(2**(16-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f04a97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32769"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(-1)+(2**(16-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cf6cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2056"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(2,11)+8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "29f7fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import bitwise_ops\n",
    "dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64,\n",
    "              tf.uint8, tf.uint16, tf.uint32, tf.uint64]\n",
    "\n",
    "for dtype in dtype_list:\n",
    "    lhs = tf.constant([0, 5, 3, 14], dtype=dtype)\n",
    "    rhs = tf.constant([5, 0, 7, 11], dtype=dtype)\n",
    "    #exp = tf.constant([0, 0, 3, 10], dtype=tf.float32)\n",
    "\n",
    "    res = bitwise_ops.bitwise_and(lhs, rhs)\n",
    "    tf.assert_equal(tf.cast(res, tf.float32), exp) # TRUE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4ca2b92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=uint64, numpy=array([ 0,  0,  3, 10], dtype=uint64)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9df010e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38, 38)\n",
      "[[32639     0]\n",
      " [49087     0]\n",
      " [49151    64]]\n"
     ]
    }
   ],
   "source": [
    "tensor=tf.placeholder=(38,38,38)\n",
    "a=[(32639,0),(49087,0),(49151,64)]\n",
    "faults = np.array(a)\n",
    "print(tensor)\n",
    "print(faults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "05d4d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([38 38 38], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor  = tf.bitwise.bitwise_and(tensor,faults[:,0])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88a789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_np = np.random.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dda0fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list_np=([2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ccf3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_vecino  [4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "index_vecino=[x+1 for x in index_list_np[1:]]\n",
    "print('index_vecino ',index_vecino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d57c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tf.disable_v2_behavior()\n",
    "tensor = tf.constant([[11,12,13,14],[14,15,16,15],[17,18,19,16]])\n",
    "#tensor.eval(ses=tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ec3742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[11, 12, 13, 14],\n",
       "       [14, 15, 16, 15],\n",
       "       [17, 18, 19, 16]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f15a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array=tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "244354b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 12, 13, 14],\n",
       "       [14, 15, 16, 15],\n",
       "       [17, 18, 19, 16]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f23a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_vecino  [13, 16, 19]\n"
     ]
    }
   ],
   "source": [
    "index_vecino=[x[1]+1 for x in numpy_array]\n",
    "print('index_vecino ',index_vecino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9737673",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(numpy_array):\n\u001b[1;32m----> 2\u001b[0m     index_vecino\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m numpy_array]\n",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(numpy_array):\n\u001b[1;32m----> 2\u001b[0m     index_vecino\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x[:\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m numpy_array]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (4,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(numpy_array):\n",
    "    index_vecino=[x+1 for x[:1] in numpy_array]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d88c20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(index_vecino))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb0f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_first",
   "language": "python",
   "name": "env_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
