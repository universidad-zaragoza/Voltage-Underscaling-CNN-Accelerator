{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3830bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds\n",
    "#import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8d49c",
   "metadata": {},
   "source": [
    "## Función resultados entres entradas y salidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa85f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnlyzExp(net,Layer ):\n",
    "    layers=Layer\n",
    "\n",
    "    diff_inp_output=[]\n",
    "    razon=[]\n",
    "    capa=[]\n",
    "    numero=[]\n",
    "    sum_tensor_cociente = []\n",
    "#with pd.ExcelWriter('Analizando_fichero_detalle/diferencias_entre_resultados/Alexnet_mask_0.xlsx') as writer:\n",
    "    \n",
    "    for i,j in enumerate(write_layer):\n",
    "            \n",
    "            \n",
    "            print('Capa',j,net.layers[j].__class__.__name__)\n",
    "            capa.append(net.layers[j].__class__.__name__)\n",
    "            numero.append(j)\n",
    "            #X = [x for x,y in test_dataset]\n",
    "            image = next(iter(test_dataset))[0]\n",
    "            #salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "            out= get_all_outputs(net,image)\n",
    "            #salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "            out_quantizacion = out[j-1]\n",
    "            out_error_and_correction = out[j]\n",
    "            tensor_aux= tf.math.abs(tf.math.subtract(out_quantizacion,out_error_and_correction ))\n",
    "            diff_inp_out=np.sum(tf.math.abs(tf.math.subtract(out_quantizacion,out_error_and_correction )))\n",
    "            input_sin_ceros=tf.math.abs(tf.where(tf.equal(out_quantizacion,0),tf.ones_like(out_quantizacion),out_quantizacion))    \n",
    "            tensor_cociente=tf.math.divide(tensor_aux,input_sin_ceros)\n",
    "            tensor_cociente  = tf.where(tf.less(tensor_cociente, 1), 1/tensor_cociente , tensor_cociente )\n",
    "            tensor_cociente_final = tf.math.reduce_sum(tf.where(tf.math.is_inf(tensor_cociente), 0 , tensor_cociente ))\n",
    "            tensor_cociente_final = np.sum(tf.where(tf.math.is_inf(tensor_cociente), 0 , tensor_cociente ))\n",
    "            print('tensor_cociente final',tensor_cociente_final)\n",
    "            diff_inp_output.append(diff_inp_out)\n",
    "            sum_tensor_cociente.append(tensor_cociente_final)\n",
    "            total=np.sum(sum_tensor_cociente)\n",
    "            #print(total)\n",
    "            print(sum_tensor_cociente)\n",
    "            \n",
    "    df_numero=pd.DataFrame(numero)\n",
    "    df_capa = pd.DataFrame(capa)   \n",
    "    df_inp_output=pd.DataFrame(diff_inp_output)\n",
    "    df_razon=pd.DataFrame(sum_tensor_cociente)\n",
    "    #print('df_razon',df_razon)\n",
    "       \n",
    "    buf_cociente = pd.concat([df_numero,df_capa,df_inp_output,df_razon], axis=1, join='outer')\n",
    "    #print('buf_cociente',buf_cociente)\n",
    "    buf_cociente.columns = ['numero','Capa','df_inp_output','df_razon']\n",
    "    print(buf_cociente)\n",
    "    return buf_cociente\n",
    "    #with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/Alexnet_mask_orig.xlsx') as writer:\n",
    "    #    buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)\n",
    "    #      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7b8d6",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba11c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,test_dataset = GetDatasets('colorectal_histology',(80,5,15),(227,227), 8, trainBatchSize, testBatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe32abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_size  = 16\n",
    "afrac_size = 11  \n",
    "aint_size  = 4\n",
    "wfrac_size = 11\n",
    "wint_size  = 4\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'AlexNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e60a48",
   "metadata": {},
   "source": [
    "## Cambiar dirección"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1f794",
   "metadata": {},
   "source": [
    "### Mácara Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2805059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "Cargar_errores = True\n",
    "\n",
    "\n",
    "\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/error_mask_054')\n",
    "    print(len(locs))\n",
    "    print(len(error_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57379a",
   "metadata": {},
   "source": [
    "### Máscara volteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507ab4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x']\n"
     ]
    }
   ],
   "source": [
    "Bese_Volt =True\n",
    "\n",
    "if Bese_Volt:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e3ea6",
   "metadata": {},
   "source": [
    "### Máscara en 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc53c170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000']\n"
     ]
    }
   ],
   "source": [
    "Mask_0 =True\n",
    "\n",
    "if Mask_0:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a414572",
   "metadata": {},
   "source": [
    " ## Creo la red con el experimento original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499709d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac83ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento Base\n",
      "Base\n",
      "750/750 [==============================] - 56s 75ms/step - loss: 0.3870 - accuracy: 0.8387\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "NetOriginal = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                             aging_active=True, word_size=word_size, frac_size=afrac_size, batch_size = testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "# Cuantizacion de los pesos\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "NetOriginal.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "NetOriginal.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = NetOriginal, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =NetOriginal.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa07cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 1054.0\n",
      "[1054.0]\n",
      "Capa 8 Lambda\n",
      "tensor_cociente final 2145.0\n",
      "[1054.0, 2145.0]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 200.0\n",
      "[1054.0, 2145.0, 200.0]\n",
      "Capa 16 Lambda\n",
      "tensor_cociente final 1483.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0]\n",
      "Capa 18 Lambda\n",
      "tensor_cociente final 157.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0]\n",
      "Capa 24 Lambda\n",
      "tensor_cociente final 200.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 200.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 159.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0, 159.0]\n",
      "Capa 38 Lambda\n",
      "tensor_cociente final 48.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0, 159.0, 48.0]\n",
      "Capa 44 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0, 159.0, 48.0, 0.0]\n",
      "Capa 49 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0, 159.0, 48.0, 0.0, 0.0]\n",
      "Capa 53 Lambda\n",
      "tensor_cociente final 6669.5684\n",
      "[1054.0, 2145.0, 200.0, 1483.0, 157.0, 200.0, 200.0, 159.0, 48.0, 0.0, 0.0, 6669.5684]\n",
      "    numero    Capa  df_inp_output     df_razon\n",
      "0        2  Lambda    1004.447754  1054.000000\n",
      "1        8  Lambda     377.326660  2145.000000\n",
      "2       10  Lambda      36.981934   200.000000\n",
      "3       16  Lambda     734.049805  1483.000000\n",
      "4       18  Lambda     106.046387   157.000000\n",
      "5       24  Lambda     132.578125   200.000000\n",
      "6       30  Lambda     129.648438   200.000000\n",
      "7       36  Lambda     117.108398   159.000000\n",
      "8       38  Lambda      36.889160    48.000000\n",
      "9       44  Lambda       0.000000     0.000000\n",
      "10      49  Lambda       0.000000     0.000000\n",
      "11      53  Lambda       0.000662  6669.568359\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "buf_cociente=AnlyzExp(NetOriginal,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/Alexnet_mask_0.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4ed31",
   "metadata": {},
   "source": [
    "## Creo la red con el experimento de redondeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a8baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n",
      "Redondeo\n",
      "750/750 [==============================] - 75s 100ms/step - loss: 0.3123 - accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "from Nets import GetNeuralNetworkModel\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "\n",
    "\n",
    "\n",
    "Net2 = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "Net2.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "Net2.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = Net2, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =Net2.evaluate(test_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9276e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 398252.53\n",
      "[398252.53]\n",
      "Capa 8 Lambda\n",
      "tensor_cociente final 150864.5\n",
      "[398252.53, 150864.5]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 13897.649\n",
      "[398252.53, 150864.5, 13897.649]\n",
      "Capa 16 Lambda\n",
      "tensor_cociente final 251854.75\n",
      "[398252.53, 150864.5, 13897.649, 251854.75]\n",
      "Capa 18 Lambda\n",
      "tensor_cociente final 54656.582\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582]\n",
      "Capa 24 Lambda\n",
      "tensor_cociente final 58800.367\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 76679.73\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 61009.82\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73, 61009.82]\n",
      "Capa 38 Lambda\n",
      "tensor_cociente final 20341.4\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73, 61009.82, 20341.4]\n",
      "Capa 44 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73, 61009.82, 20341.4, 0.0]\n",
      "Capa 49 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73, 61009.82, 20341.4, 0.0, 0.0]\n",
      "Capa 53 Lambda\n",
      "tensor_cociente final 20245.748\n",
      "[398252.53, 150864.5, 13897.649, 251854.75, 54656.582, 58800.367, 76679.73, 61009.82, 20341.4, 0.0, 0.0, 20245.748]\n",
      "    numero    Capa  df_inp_output       df_razon\n",
      "0        2  Lambda       2.912598  398252.531250\n",
      "1        8  Lambda      10.961426  150864.500000\n",
      "2       10  Lambda       1.011230   13897.649414\n",
      "3       16  Lambda       4.681641  251854.750000\n",
      "4       18  Lambda       0.555176   54656.582031\n",
      "5       24  Lambda       0.646484   58800.367188\n",
      "6       30  Lambda       0.825195   76679.726562\n",
      "7       36  Lambda       0.526367   61009.820312\n",
      "8       38  Lambda       0.254395   20341.400391\n",
      "9       44  Lambda       0.000000       0.000000\n",
      "10      49  Lambda       0.000000       0.000000\n",
      "11      53  Lambda       0.000488   20245.748047\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "buf_cociente=AnlyzExp(Net2,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/Alexnet_redond_volt.xlsx') as  writer:\n",
    "    buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f31af2",
   "metadata": {},
   "source": [
    "## Creo la red con el experimento de Vecino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538cd35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vecinos\n"
     ]
    }
   ],
   "source": [
    "from NetsVecino import GetNeuralNetworkModel\n",
    "from StatsVecino import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "\n",
    "\n",
    "NetVecinos = GetNeuralNetworkModel('AlexNet', (227,227,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                             aging_active=True, word_size=word_size, frac_size=afrac_size, batch_size = testBatchSize)\n",
    "\n",
    "#Cuantizacion de los pesos\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "NetVecinos.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "NetVecinos.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = NetVecinos, frac_bits = afrac_size, int_bits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bba9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_layer=[2,8,10,16,18,24,30,36,38,44,49,53]\n",
    "#buf_cociente=AnlyzExp(NetVecinos,write_layer)\n",
    "#with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/Alexnet_vecinos.xlsx') as writer:\n",
    "#        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887fa59",
   "metadata": {},
   "source": [
    "# Squeeznet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0002044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# Numero de bits para activaciones (a) y pesos (w)\n",
    "word_size  = 16\n",
    "afrac_size = 9\n",
    "aint_size  = 6\n",
    "wfrac_size = 15\n",
    "wint_size  = 0\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SqueezeNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46d03a",
   "metadata": {},
   "source": [
    "# Modificar dirección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f24754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "Cargar_errores = True\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/error_mask_054')\n",
    "    print(len(locs))\n",
    "    print(len(error_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18368bde",
   "metadata": {},
   "source": [
    "### Máscara volteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be485d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x']\n"
     ]
    }
   ],
   "source": [
    "Bese_Volt =True\n",
    "\n",
    "if Bese_Volt:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f976364",
   "metadata": {},
   "source": [
    "### Mask_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26105f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000']\n"
     ]
    }
   ],
   "source": [
    "Mask_0 =True\n",
    "\n",
    "if Mask_0:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5f2d5",
   "metadata": {},
   "source": [
    "## Red  original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0f9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento Base\n",
      "750/750 [==============================] - 79s 106ms/step - loss: 2.4122 - accuracy: 0.7813\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "NetSqueezeOriginal = GetNeuralNetworkModel('SqueezeNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "NetSqueezeOriginal.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "NetSqueezeOriginal.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = NetSqueezeOriginal, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =NetSqueezeOriginal.evaluate(test_dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "427e2f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 1054.0\n",
      "[1054.0]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 4786.0\n",
      "[1054.0, 4786.0]\n",
      "Capa 8 Lambda\n",
      "tensor_cociente final 903.0\n",
      "[1054.0, 4786.0, 903.0]\n",
      "Capa 12 Lambda\n",
      "tensor_cociente final 106.0\n",
      "[1054.0, 4786.0, 903.0, 106.0]\n",
      "Capa 19 Lambda\n",
      "tensor_cociente final 2068.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0]\n",
      "Capa 23 Lambda\n",
      "tensor_cociente final 140.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 1932.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 520.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0]\n",
      "Capa 41 Lambda\n",
      "tensor_cociente final 2916.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0]\n",
      "Capa 43 Lambda\n",
      "tensor_cociente final 843.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0]\n",
      "Capa 47 Lambda\n",
      "tensor_cociente final 45.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0]\n",
      "Capa 54 Lambda\n",
      "tensor_cociente final 630.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0]\n",
      "Capa 58 Lambda\n",
      "tensor_cociente final 84.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0]\n",
      "Capa 65 Lambda\n",
      "tensor_cociente final 1244.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0]\n",
      "Capa 69 Lambda\n",
      "tensor_cociente final 101.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0]\n",
      "Capa 76 Lambda\n",
      "tensor_cociente final 1405.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0]\n",
      "Capa 80 Lambda\n",
      "tensor_cociente final 103.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0]\n",
      "Capa 87 Lambda\n",
      "tensor_cociente final 1125.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0]\n",
      "Capa 89 Lambda\n",
      "tensor_cociente final 301.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0, 301.0]\n",
      "Capa 93 Lambda\n",
      "tensor_cociente final 24.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0, 301.0, 24.0]\n",
      "Capa 100 Lambda\n",
      "tensor_cociente final 338.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0, 301.0, 24.0, 338.0]\n",
      "Capa 103 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0, 301.0, 24.0, 338.0, 0.0]\n",
      "Capa 107 Lambda\n",
      "tensor_cociente final 1271.591\n",
      "[1054.0, 4786.0, 903.0, 106.0, 2068.0, 140.0, 1932.0, 520.0, 2916.0, 843.0, 45.0, 630.0, 84.0, 1244.0, 101.0, 1405.0, 103.0, 1125.0, 301.0, 24.0, 338.0, 0.0, 1271.591]\n",
      "    numero    Capa  df_inp_output     df_razon\n",
      "0        2  Lambda    1003.707031  1054.000000\n",
      "1        6  Lambda    2301.171875  4786.000000\n",
      "2        8  Lambda     289.599609   903.000000\n",
      "3       12  Lambda      59.556641   106.000000\n",
      "4       19  Lambda     718.990234  2068.000000\n",
      "5       23  Lambda      51.746094   140.000000\n",
      "6       30  Lambda     515.652344  1932.000000\n",
      "7       34  Lambda     176.816406   520.000000\n",
      "8       41  Lambda     544.427734  2916.000000\n",
      "9       43  Lambda     208.753906   843.000000\n",
      "10      47  Lambda       8.767578    45.000000\n",
      "11      54  Lambda      64.570312   630.000000\n",
      "12      58  Lambda       8.515625    84.000000\n",
      "13      65  Lambda     155.259766  1244.000000\n",
      "14      69  Lambda      37.941406   101.000000\n",
      "15      76  Lambda     377.423828  1405.000000\n",
      "16      80  Lambda      76.302734   103.000000\n",
      "17      87  Lambda    1551.998047  1125.000000\n",
      "18      89  Lambda     528.882812   301.000000\n",
      "19      93  Lambda      43.255859    24.000000\n",
      "20     100  Lambda     906.574219   338.000000\n",
      "21     103  Lambda       0.000000     0.000000\n",
      "22     107  Lambda       0.001651  1271.590942\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,8,12,     19,23,     30,34,     41,43,47,     54,58,     65,69,     76,80 ,    87,89,93,    100,103,107]\n",
    "buf_cociente=AnlyzExp(NetSqueezeOriginal,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/SqueezeNet_mask_0.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66a9c7",
   "metadata": {},
   "source": [
    "## Red con el experimento de redondeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38396c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n",
      "750/750 [==============================] - 136s 181ms/step - loss: 2.5533 - accuracy: 0.7453\n"
     ]
    }
   ],
   "source": [
    "from Nets import GetNeuralNetworkModel\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "NetSqueezeRound = GetNeuralNetworkModel('SqueezeNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "NetSqueezeRound.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "NetSqueezeRound.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = NetSqueezeRound, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =NetSqueezeRound.evaluate(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795f0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 94727.39\n",
      "[94727.39]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 520280.97\n",
      "[94727.39, 520280.97]\n",
      "Capa 8 Lambda\n",
      "tensor_cociente final 82350.984\n",
      "[94727.39, 520280.97, 82350.984]\n",
      "Capa 12 Lambda\n",
      "tensor_cociente final 8868.195\n",
      "[94727.39, 520280.97, 82350.984, 8868.195]\n",
      "Capa 19 Lambda\n",
      "tensor_cociente final 139600.31\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31]\n",
      "Capa 23 Lambda\n",
      "tensor_cociente final 6443.947\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 119846.27\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 26514.137\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137]\n",
      "Capa 41 Lambda\n",
      "tensor_cociente final 348072.03\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03]\n",
      "Capa 43 Lambda\n",
      "tensor_cociente final 55022.88\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88]\n",
      "Capa 47 Lambda\n",
      "tensor_cociente final 3458.44\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44]\n",
      "Capa 54 Lambda\n",
      "tensor_cociente final 49736.965\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965]\n",
      "Capa 58 Lambda\n",
      "tensor_cociente final 4017.8765\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765]\n",
      "Capa 65 Lambda\n",
      "tensor_cociente final 65921.64\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64]\n",
      "Capa 69 Lambda\n",
      "tensor_cociente final 5272.442\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442]\n",
      "Capa 76 Lambda\n",
      "tensor_cociente final 83487.68\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68]\n",
      "Capa 80 Lambda\n",
      "tensor_cociente final 14529.28\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28]\n",
      "Capa 87 Lambda\n",
      "tensor_cociente final 219596.2\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2]\n",
      "Capa 89 Lambda\n",
      "tensor_cociente final 49981.17\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2, 49981.17]\n",
      "Capa 93 Lambda\n",
      "tensor_cociente final 9784.567\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2, 49981.17, 9784.567]\n",
      "Capa 100 Lambda\n",
      "tensor_cociente final 99910.37\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2, 49981.17, 9784.567, 99910.37]\n",
      "Capa 103 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2, 49981.17, 9784.567, 99910.37, 0.0]\n",
      "Capa 107 Lambda\n",
      "tensor_cociente final 3616.3325\n",
      "[94727.39, 520280.97, 82350.984, 8868.195, 139600.31, 6443.947, 119846.27, 26514.137, 348072.03, 55022.88, 3458.44, 49736.965, 4017.8765, 65921.64, 5272.442, 83487.68, 14529.28, 219596.2, 49981.17, 9784.567, 99910.37, 0.0, 3616.3325]\n",
      "    numero    Capa  df_inp_output       df_razon\n",
      "0        2  Lambda      17.894531   94727.390625\n",
      "1        6  Lambda     323.408203  520280.968750\n",
      "2        8  Lambda      55.603516   82350.984375\n",
      "3       12  Lambda       4.712891    8868.195312\n",
      "4       19  Lambda      83.957031  139600.312500\n",
      "5       23  Lambda       1.679688    6443.946777\n",
      "6       30  Lambda      78.636719  119846.273438\n",
      "7       34  Lambda      11.285156   26514.136719\n",
      "8       41  Lambda     293.851562  348072.031250\n",
      "9       43  Lambda      36.089844   55022.878906\n",
      "10      47  Lambda       1.701172    3458.439941\n",
      "11      54  Lambda      37.818359   49736.964844\n",
      "12      58  Lambda       3.138672    4017.876465\n",
      "13      65  Lambda      53.203125   65921.640625\n",
      "14      69  Lambda       2.269531    5272.441895\n",
      "15      76  Lambda      49.960938   83487.679688\n",
      "16      80  Lambda       3.501953   14529.280273\n",
      "17      87  Lambda      94.781250  219596.203125\n",
      "18      89  Lambda      14.656250   49981.171875\n",
      "19      93  Lambda       1.673828    9784.567383\n",
      "20     100  Lambda      14.244141   99910.367188\n",
      "21     103  Lambda       0.000000       0.000000\n",
      "22     107  Lambda       0.000554    3616.332520\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,8,12,     19,23,     30,34,     41,43,47,     54,58,     65,69,     76,80 ,    87,89,93,    100,103,107]\n",
    "buf_cociente=AnlyzExp(NetSqueezeRound,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/SqueezeNet_redond_volt.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658e23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnlyzExp(net,Layer ):\n",
    "    layers=Layer\n",
    "\n",
    "    diff_inp_output=[]\n",
    "    razon=[]\n",
    "    capa=[]\n",
    "    numero=[]\n",
    "    sum_tensor_cociente = []\n",
    "#with pd.ExcelWriter('Analizando_fichero_detalle/diferencias_entre_resultados/Alexnet_mask_0.xlsx') as writer:\n",
    "    \n",
    "    for i,j in enumerate(write_layer):\n",
    "            \n",
    "            \n",
    "            print('Capa',j,net.layers[j].__class__.__name__)\n",
    "            capa.append(net.layers[j].__class__.__name__)\n",
    "            numero.append(j)\n",
    "            #X = [x for x,y in test_dataset]\n",
    "            image = next(iter(test_dataset))[0]\n",
    "            #salidas del modelo sin fallas para la primer imagen del dataset de prueba\n",
    "            out= get_all_outputs(net,image)\n",
    "            #salidas del modelo con fallas para la primer imagen del dataset de prueba\n",
    "            out_quantizacion = out[j-1]\n",
    "            out_error_and_correction = out[j]\n",
    "            tensor_aux= tf.math.abs(tf.math.subtract(out_quantizacion,out_error_and_correction ))\n",
    "            diff_inp_out=np.sum(tf.math.abs(tf.math.subtract(out_quantizacion,out_error_and_correction )))\n",
    "            input_sin_ceros=tf.math.abs(tf.where(tf.equal(out_quantizacion,0),tf.ones_like(out_quantizacion),out_quantizacion))    \n",
    "            tensor_cociente=tf.math.divide(tensor_aux,input_sin_ceros)\n",
    "            tensor_cociente  = tf.where(tf.less(tensor_cociente, 1), 1/tensor_cociente , tensor_cociente )\n",
    "            tensor_cociente_final = tf.math.reduce_sum(tf.where(tf.math.is_inf(tensor_cociente), 0 , tensor_cociente ))\n",
    "            tensor_cociente_final = np.sum(tf.where(tf.math.is_inf(tensor_cociente), 0 , tensor_cociente ))\n",
    "            print('tensor_cociente final',tensor_cociente_final)\n",
    "            diff_inp_output.append(diff_inp_out)\n",
    "            sum_tensor_cociente.append(tensor_cociente_final)\n",
    "            total=np.sum(sum_tensor_cociente)\n",
    "            #print(total)\n",
    "            print(sum_tensor_cociente)\n",
    "            \n",
    "    df_numero=pd.DataFrame(numero)\n",
    "    df_capa = pd.DataFrame(capa)   \n",
    "    df_inp_output=pd.DataFrame(diff_inp_output)\n",
    "    df_razon=pd.DataFrame(sum_tensor_cociente)\n",
    "    #print('df_razon',df_razon)\n",
    "       \n",
    "    buf_cociente = pd.concat([df_numero,df_capa,df_inp_output,df_razon], axis=1, join='outer')\n",
    "    #print('buf_cociente',buf_cociente)\n",
    "    buf_cociente.columns = ['numero','Capa','df_inp_output','df_razon']\n",
    "    print(buf_cociente)\n",
    "    return buf_cociente\n",
    "    #with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/Alexnet_mask_orig.xlsx') as writer:\n",
    "    #    buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)\n",
    "    #      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fdd4e6",
   "metadata": {},
   "source": [
    "## MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac438f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# Numero de bits para activaciones (a) y pesos (w)\n",
    "word_size  = 16\n",
    "afrac_size = 11\n",
    "aint_size  = 4\n",
    "wfrac_size = 14\n",
    "wint_size  = 1\n",
    "\n",
    "# Tamaño del buffer de activaciones == al tamaño de la capa con mayor numero de activaciones (290400 pesos de 16 bits cada uno)\n",
    "abuffer_size = 16777216\n",
    "# Directorio de los pesos\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'MobileNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "\n",
    "Cargar_errores = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "layer=[2,9,15,21,28,34,40,46,53,59,65,71,78,84,90,96,102,108,114,120,126,132,138,144,151,157,163,169,173,179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870457fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx0x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx1xxxxxx', 'xxxxxxxxxxxxxx1x', 'xxxxxxxxx0xxxxxx', 'xxxxxxxxxxxxxx0x']\n"
     ]
    }
   ],
   "source": [
    "Bese_Volt =True\n",
    "\n",
    "if Bese_Volt:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/mask_volteada/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122573f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000', '0000000000000000']\n"
     ]
    }
   ],
   "source": [
    "Mask_0 =True\n",
    "\n",
    "if Mask_0:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/error_mask_0/vc_707/error_mask_054')\n",
    "locs[0:20]  \n",
    "print(error_mask[0:20]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f4e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento Base\n",
      "750/750 [==============================] - 121s 161ms/step - loss: 2.8904 - accuracy: 0.4347\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "MobileNetOriginal = GetNeuralNetworkModel('MobileNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "MobileNetOriginal.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "MobileNetOriginal.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = MobileNetOriginal, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =MobileNetOriginal.evaluate(test_dataset)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a38886c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 1054.0\n",
      "[1054.0]\n",
      "Capa 9 Lambda\n",
      "tensor_cociente final 2487.0\n",
      "[1054.0, 2487.0]\n",
      "Capa 15 Lambda\n",
      "tensor_cociente final 1696.0\n",
      "[1054.0, 2487.0, 1696.0]\n",
      "Capa 21 Lambda\n",
      "tensor_cociente final 4093.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0]\n",
      "Capa 28 Lambda\n",
      "tensor_cociente final 777.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 1622.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0]\n",
      "Capa 40 Lambda\n",
      "tensor_cociente final 1837.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0]\n",
      "Capa 46 Lambda\n",
      "tensor_cociente final 1498.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0]\n",
      "Capa 53 Lambda\n",
      "tensor_cociente final 334.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0]\n",
      "Capa 59 Lambda\n",
      "tensor_cociente final 690.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0]\n",
      "Capa 65 Lambda\n",
      "tensor_cociente final 507.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0]\n",
      "Capa 71 Lambda\n",
      "tensor_cociente final 1001.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0]\n",
      "Capa 78 Lambda\n",
      "tensor_cociente final 95.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0]\n",
      "Capa 84 Lambda\n",
      "tensor_cociente final 342.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0]\n",
      "Capa 90 Lambda\n",
      "tensor_cociente final 332.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0]\n",
      "Capa 96 Lambda\n",
      "tensor_cociente final 423.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0]\n",
      "Capa 102 Lambda\n",
      "tensor_cociente final 255.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0]\n",
      "Capa 108 Lambda\n",
      "tensor_cociente final 252.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0]\n",
      "Capa 114 Lambda\n",
      "tensor_cociente final 200.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0]\n",
      "Capa 120 Lambda\n",
      "tensor_cociente final 338.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0]\n",
      "Capa 126 Lambda\n",
      "tensor_cociente final 352.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0]\n",
      "Capa 132 Lambda\n",
      "tensor_cociente final 274.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0]\n",
      "Capa 138 Lambda\n",
      "tensor_cociente final 325.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0]\n",
      "Capa 144 Lambda\n",
      "tensor_cociente final 346.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0]\n",
      "Capa 151 Lambda\n",
      "tensor_cociente final 30.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0]\n",
      "Capa 157 Lambda\n",
      "tensor_cociente final 96.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0, 96.0]\n",
      "Capa 163 Lambda\n",
      "tensor_cociente final 85.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0, 96.0, 85.0]\n",
      "Capa 169 Lambda\n",
      "tensor_cociente final 63.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0, 96.0, 85.0, 63.0]\n",
      "Capa 173 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0, 96.0, 85.0, 63.0, 0.0]\n",
      "Capa 179 Lambda\n",
      "tensor_cociente final 15155.202\n",
      "[1054.0, 2487.0, 1696.0, 4093.0, 777.0, 1622.0, 1837.0, 1498.0, 334.0, 690.0, 507.0, 1001.0, 95.0, 342.0, 332.0, 423.0, 255.0, 252.0, 200.0, 338.0, 352.0, 274.0, 325.0, 346.0, 30.0, 96.0, 85.0, 63.0, 0.0, 15155.202]\n",
      "    numero    Capa  df_inp_output      df_razon\n",
      "0        2  Lambda    1003.718262   1054.000000\n",
      "1        9  Lambda    2644.320801   2487.000000\n",
      "2       15  Lambda    1709.628418   1696.000000\n",
      "3       21  Lambda    5392.589844   4093.000000\n",
      "4       28  Lambda     694.454590    777.000000\n",
      "5       34  Lambda    2062.341797   1622.000000\n",
      "6       40  Lambda    1289.645020   1837.000000\n",
      "7       46  Lambda    2204.666016   1498.000000\n",
      "8       53  Lambda     329.016113    334.000000\n",
      "9       59  Lambda     924.080566    690.000000\n",
      "10      65  Lambda     495.787598    507.000000\n",
      "11      71  Lambda    1873.022461   1001.000000\n",
      "12      78  Lambda     132.543457     95.000000\n",
      "13      84  Lambda     589.004883    342.000000\n",
      "14      90  Lambda     284.194824    332.000000\n",
      "15      96  Lambda     829.624512    423.000000\n",
      "16     102  Lambda     239.416992    255.000000\n",
      "17     108  Lambda     428.230469    252.000000\n",
      "18     114  Lambda     204.923340    200.000000\n",
      "19     120  Lambda     561.334473    338.000000\n",
      "20     126  Lambda     251.918945    352.000000\n",
      "21     132  Lambda     425.021484    274.000000\n",
      "22     138  Lambda     196.165039    325.000000\n",
      "23     144  Lambda     551.122559    346.000000\n",
      "24     151  Lambda      25.628906     30.000000\n",
      "25     157  Lambda     128.600586     96.000000\n",
      "26     163  Lambda      51.557617     85.000000\n",
      "27     169  Lambda      76.114746     63.000000\n",
      "28     173  Lambda       0.000000      0.000000\n",
      "29     179  Lambda       0.000645  15155.202148\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,9,15,21,28,34,40,46,53,59,65,71,78,84,90,96,102,108,114,120,126,132,138,144,151,157,163,169,173,179]\n",
    "buf_cociente=AnlyzExp(MobileNetOriginal,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/MobileNet_mask_0.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66eecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n",
      "750/750 [==============================] - 219s 292ms/step - loss: 0.3685 - accuracy: 0.8707\n"
     ]
    }
   ],
   "source": [
    "from Nets import GetNeuralNetworkModel\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "MobileNetRound = GetNeuralNetworkModel('MobileNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "MobileNetRound.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "MobileNetRound.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = MobileNetRound, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =MobileNetRound.evaluate(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e251a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 398495.8\n",
      "[398495.8]\n",
      "Capa 9 Lambda\n",
      "tensor_cociente final 1099181.9\n",
      "[398495.8, 1099181.9]\n",
      "Capa 15 Lambda\n",
      "tensor_cociente final 832428.2\n",
      "[398495.8, 1099181.9, 832428.2]\n",
      "Capa 21 Lambda\n",
      "tensor_cociente final 2433053.8\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8]\n",
      "Capa 28 Lambda\n",
      "tensor_cociente final 299521.2\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 761243.8\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8]\n",
      "Capa 40 Lambda\n",
      "tensor_cociente final 648331.1\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1]\n",
      "Capa 46 Lambda\n",
      "tensor_cociente final 694540.6\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6]\n",
      "Capa 53 Lambda\n",
      "tensor_cociente final 98651.18\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18]\n",
      "Capa 59 Lambda\n",
      "tensor_cociente final 339045.72\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72]\n",
      "Capa 65 Lambda\n",
      "tensor_cociente final 270813.12\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12]\n",
      "Capa 71 Lambda\n",
      "tensor_cociente final 302841.62\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62]\n",
      "Capa 78 Lambda\n",
      "tensor_cociente final 39086.016\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016]\n",
      "Capa 84 Lambda\n",
      "tensor_cociente final 141758.23\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23]\n",
      "Capa 90 Lambda\n",
      "tensor_cociente final 122772.06\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06]\n",
      "Capa 96 Lambda\n",
      "tensor_cociente final 118226.5\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5]\n",
      "Capa 102 Lambda\n",
      "tensor_cociente final 110982.05\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05]\n",
      "Capa 108 Lambda\n",
      "tensor_cociente final 111785.04\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04]\n",
      "Capa 114 Lambda\n",
      "tensor_cociente final 94986.91\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91]\n",
      "Capa 120 Lambda\n",
      "tensor_cociente final 152412.2\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2]\n",
      "Capa 126 Lambda\n",
      "tensor_cociente final 139834.61\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61]\n",
      "Capa 132 Lambda\n",
      "tensor_cociente final 124171.016\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016]\n",
      "Capa 138 Lambda\n",
      "tensor_cociente final 104793.98\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98]\n",
      "Capa 144 Lambda\n",
      "tensor_cociente final 152148.92\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92]\n",
      "Capa 151 Lambda\n",
      "tensor_cociente final 16632.16\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16]\n",
      "Capa 157 Lambda\n",
      "tensor_cociente final 35989.293\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16, 35989.293]\n",
      "Capa 163 Lambda\n",
      "tensor_cociente final 36023.355\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16, 35989.293, 36023.355]\n",
      "Capa 169 Lambda\n",
      "tensor_cociente final 44265.055\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16, 35989.293, 36023.355, 44265.055]\n",
      "Capa 173 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16, 35989.293, 36023.355, 44265.055, 0.0]\n",
      "Capa 179 Lambda\n",
      "tensor_cociente final 46329.64\n",
      "[398495.8, 1099181.9, 832428.2, 2433053.8, 299521.2, 761243.8, 648331.1, 694540.6, 98651.18, 339045.72, 270813.12, 302841.62, 39086.016, 141758.23, 122772.06, 118226.5, 110982.05, 111785.04, 94986.91, 152412.2, 139834.61, 124171.016, 104793.98, 152148.92, 16632.16, 35989.293, 36023.355, 44265.055, 0.0, 46329.64]\n",
      "    numero    Capa  df_inp_output      df_razon\n",
      "0        2  Lambda       2.979492  3.984958e+05\n",
      "1        9  Lambda      19.145508  1.099182e+06\n",
      "2       15  Lambda      22.683594  8.324282e+05\n",
      "3       21  Lambda      70.062500  2.433054e+06\n",
      "4       28  Lambda       8.302246  2.995212e+05\n",
      "5       34  Lambda      21.472168  7.612438e+05\n",
      "6       40  Lambda      21.445312  6.483311e+05\n",
      "7       46  Lambda      20.241699  6.945406e+05\n",
      "8       53  Lambda       3.435059  9.865118e+04\n",
      "9       59  Lambda       9.202148  3.390457e+05\n",
      "10      65  Lambda       8.398438  2.708131e+05\n",
      "11      71  Lambda       9.353516  3.028416e+05\n",
      "12      78  Lambda       0.852539  3.908602e+04\n",
      "13      84  Lambda       3.445801  1.417582e+05\n",
      "14      90  Lambda       3.052734  1.227721e+05\n",
      "15      96  Lambda       3.654785  1.182265e+05\n",
      "16     102  Lambda       3.669434  1.109820e+05\n",
      "17     108  Lambda       3.819336  1.117850e+05\n",
      "18     114  Lambda       3.501953  9.498691e+04\n",
      "19     120  Lambda       3.402832  1.524122e+05\n",
      "20     126  Lambda       3.141602  1.398346e+05\n",
      "21     132  Lambda       3.369629  1.241710e+05\n",
      "22     138  Lambda       3.457031  1.047940e+05\n",
      "23     144  Lambda       3.569336  1.521489e+05\n",
      "24     151  Lambda       0.487305  1.663216e+04\n",
      "25     157  Lambda       1.062988  3.598929e+04\n",
      "26     163  Lambda       1.078125  3.602336e+04\n",
      "27     169  Lambda       1.197266  4.426505e+04\n",
      "28     173  Lambda       0.000000  0.000000e+00\n",
      "29     179  Lambda       0.000043  4.632964e+04\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,9,15,21,28,34,40,46,53,59,65,71,78,84,90,96,102,108,114,120,126,132,138,144,151,157,163,169,173,179]\n",
    "buf_cociente=AnlyzExp(MobileNetRound,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/MobileNet_redond_volt.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f18e7",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc09098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "word_size  = 16\n",
    "afrac_size = 12\n",
    "aint_size  = 3\n",
    "wfrac_size = 15\n",
    "wint_size  = 0\n",
    "\n",
    "# Tamaño del buffer de activaciones == al tamaño de la capa con mayor numero de activaciones (290400 pesos de 16 bits cada uno)\n",
    "abuffer_size = 16777216\n",
    "# Directorio de los pesos\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'VGG16')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42637047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento Base\n",
      "750/750 [==============================] - 482s 642ms/step - loss: 1.1234 - accuracy: 0.6360\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "VGG16Original = GetNeuralNetworkModel('VGG16', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "VGG16Original.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "VGG16Original.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = VGG16Original, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =VGG16Original.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361d33ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 1054.0\n",
      "[1054.0]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 5423.0\n",
      "[1054.0, 5423.0]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 4314.0\n",
      "[1054.0, 5423.0, 4314.0]\n",
      "Capa 12 Lambda\n",
      "tensor_cociente final 3855.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0]\n",
      "Capa 16 Lambda\n",
      "tensor_cociente final 2701.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0]\n",
      "Capa 20 Lambda\n",
      "tensor_cociente final 2379.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0]\n",
      "Capa 22 Lambda\n",
      "tensor_cociente final 1540.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0]\n",
      "Capa 26 Lambda\n",
      "tensor_cociente final 2368.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 1834.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 1471.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 167.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0]\n",
      "Capa 40 Lambda\n",
      "tensor_cociente final 690.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0]\n",
      "Capa 44 Lambda\n",
      "tensor_cociente final 1033.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0]\n",
      "Capa 48 Lambda\n",
      "tensor_cociente final 483.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0]\n",
      "Capa 50 Lambda\n",
      "tensor_cociente final 79.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0]\n",
      "Capa 54 Lambda\n",
      "tensor_cociente final 138.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0]\n",
      "Capa 58 Lambda\n",
      "tensor_cociente final 139.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0]\n",
      "Capa 62 Lambda\n",
      "tensor_cociente final 109.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0, 109.0]\n",
      "Capa 64 Lambda\n",
      "tensor_cociente final 24.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0, 109.0, 24.0]\n",
      "Capa 69 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0, 109.0, 24.0, 0.0]\n",
      "Capa 73 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0, 109.0, 24.0, 0.0, 0.0]\n",
      "Capa 77 Lambda\n",
      "tensor_cociente final 11840.971\n",
      "[1054.0, 5423.0, 4314.0, 3855.0, 2701.0, 2379.0, 1540.0, 2368.0, 1834.0, 1471.0, 167.0, 690.0, 1033.0, 483.0, 79.0, 138.0, 139.0, 109.0, 24.0, 0.0, 0.0, 11840.971]\n",
      "    numero    Capa  df_inp_output      df_razon\n",
      "0        2  Lambda    1003.556641   1054.000000\n",
      "1        6  Lambda     739.914795   5423.000000\n",
      "2       10  Lambda     459.370117   4314.000000\n",
      "3       12  Lambda     309.769531   3855.000000\n",
      "4       16  Lambda     133.872314   2701.000000\n",
      "5       20  Lambda      97.455566   2379.000000\n",
      "6       22  Lambda      40.117188   1540.000000\n",
      "7       26  Lambda      54.816406   2368.000000\n",
      "8       30  Lambda      40.591797   1834.000000\n",
      "9       34  Lambda      23.216064   1471.000000\n",
      "10      36  Lambda       3.135010    167.000000\n",
      "11      40  Lambda       6.586670    690.000000\n",
      "12      44  Lambda      20.065918   1033.000000\n",
      "13      48  Lambda       7.006836    483.000000\n",
      "14      50  Lambda       1.419434     79.000000\n",
      "15      54  Lambda       2.029297    138.000000\n",
      "16      58  Lambda       3.538086    139.000000\n",
      "17      62  Lambda       3.368164    109.000000\n",
      "18      64  Lambda       1.008789     24.000000\n",
      "19      69  Lambda       0.000000      0.000000\n",
      "20      73  Lambda       0.000000      0.000000\n",
      "21      77  Lambda       0.000586  11840.970703\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,10,12,16,20,22,26,30,34,36,40,44,48,50,54,58,62,64,69,73,77]\n",
    "buf_cociente=AnlyzExp(VGG16Original,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/VGG16_mask_0.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7fa211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n"
     ]
    }
   ],
   "source": [
    "from Nets import GetNeuralNetworkModel\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "VGG16Round = GetNeuralNetworkModel('VGG16', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "VGG16Round.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "VGG16Round.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = VGG16Round, frac_bits = afrac_size, int_bits = aint_size)\n",
    "#loss,acc =VGG16Round.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e92e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 755968.25\n",
      "[755968.25]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 2554692.2\n",
      "[755968.25, 2554692.2]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 2648391.0\n",
      "[755968.25, 2554692.2, 2648391.0]\n",
      "Capa 12 Lambda\n",
      "tensor_cociente final 1887625.0\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0]\n",
      "Capa 16 Lambda\n",
      "tensor_cociente final 3399579.5\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5]\n",
      "Capa 20 Lambda\n",
      "tensor_cociente final 3597531.2\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2]\n",
      "Capa 22 Lambda\n",
      "tensor_cociente final 855786.75\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75]\n",
      "Capa 26 Lambda\n",
      "tensor_cociente final 2644984.5\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 2865987.8\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8]\n",
      "Capa 34 Lambda\n",
      "tensor_cociente final 2934713.2\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 490387.3\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3]\n",
      "Capa 40 Lambda\n",
      "tensor_cociente final 1131194.9\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9]\n",
      "Capa 44 Lambda\n",
      "tensor_cociente final 1107370.5\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5]\n",
      "Capa 48 Lambda\n",
      "tensor_cociente final 1162991.8\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8]\n",
      "Capa 50 Lambda\n",
      "tensor_cociente final 223403.39\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39]\n",
      "Capa 54 Lambda\n",
      "tensor_cociente final 181206.02\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02]\n",
      "Capa 58 Lambda\n",
      "tensor_cociente final 191456.05\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05]\n",
      "Capa 62 Lambda\n",
      "tensor_cociente final 211838.03\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05, 211838.03]\n",
      "Capa 64 Lambda\n",
      "tensor_cociente final 26962.055\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05, 211838.03, 26962.055]\n",
      "Capa 69 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05, 211838.03, 26962.055, 0.0]\n",
      "Capa 73 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05, 211838.03, 26962.055, 0.0, 0.0]\n",
      "Capa 77 Lambda\n",
      "tensor_cociente final 19522.738\n",
      "[755968.25, 2554692.2, 2648391.0, 1887625.0, 3399579.5, 3597531.2, 855786.75, 2644984.5, 2865987.8, 2934713.2, 490387.3, 1131194.9, 1107370.5, 1162991.8, 223403.39, 181206.02, 191456.05, 211838.03, 26962.055, 0.0, 0.0, 19522.738]\n",
      "    numero    Capa  df_inp_output      df_razon\n",
      "0        2  Lambda       1.839355  7.559682e+05\n",
      "1        6  Lambda      37.734619  2.554692e+06\n",
      "2       10  Lambda      40.146973  2.648391e+06\n",
      "3       12  Lambda      32.832275  1.887625e+06\n",
      "4       16  Lambda      43.864258  3.399580e+06\n",
      "5       20  Lambda      44.083984  3.597531e+06\n",
      "6       22  Lambda      11.424072  8.557868e+05\n",
      "7       26  Lambda      37.399170  2.644984e+06\n",
      "8       30  Lambda      38.322510  2.865988e+06\n",
      "9       34  Lambda      39.238037  2.934713e+06\n",
      "10      36  Lambda       5.343750  4.903873e+05\n",
      "11      40  Lambda      12.876709  1.131195e+06\n",
      "12      44  Lambda      11.935547  1.107370e+06\n",
      "13      48  Lambda      12.984863  1.162992e+06\n",
      "14      50  Lambda       2.164551  2.234034e+05\n",
      "15      54  Lambda       1.993896  1.812060e+05\n",
      "16      58  Lambda       2.010498  1.914560e+05\n",
      "17      62  Lambda       2.152832  2.118380e+05\n",
      "18      64  Lambda       0.281250  2.696205e+04\n",
      "19      69  Lambda       0.000000  0.000000e+00\n",
      "20      73  Lambda       0.000000  0.000000e+00\n",
      "21      77  Lambda       0.000462  1.952274e+04\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,10,12,16,20,22,26,30,34,36,40,44,48,50,54,58,62,64,69,73,77]\n",
    "buf_cociente=AnlyzExp(VGG16Round,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/VGG16_redond_volt.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3257eb8",
   "metadata": {},
   "source": [
    "## ZFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7e52cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from funciones import compilNet, same_elements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import ExcelWriter\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_size  = 16\n",
    "afrac_size = 11\n",
    "aint_size  = 4\n",
    "wfrac_size = 14\n",
    "wint_size  = 1\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'ZFNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5e6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 87s 116ms/step - loss: 12.4162 - accuracy: 0.1173\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "ZFNetOriginal = GetNeuralNetworkModel('ZFNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "ZFNetOriginal.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "ZFNetOriginal.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = ZFNetOriginal, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =ZFNetOriginal.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67905e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 122488.336\n",
      "[122488.336]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 499913.88\n",
      "[122488.336, 499913.88]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 144222.84\n",
      "[122488.336, 499913.88, 144222.84]\n",
      "Capa 14 Lambda\n",
      "tensor_cociente final 115019.72\n",
      "[122488.336, 499913.88, 144222.84, 115019.72]\n",
      "Capa 18 Lambda\n",
      "tensor_cociente final 15944.09\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09]\n",
      "Capa 22 Lambda\n",
      "tensor_cociente final 17239.438\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438]\n",
      "Capa 26 Lambda\n",
      "tensor_cociente final 13178.362\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 12283.836\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362, 12283.836]\n",
      "Capa 32 Lambda\n",
      "tensor_cociente final 2774.239\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362, 12283.836, 2774.239]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362, 12283.836, 2774.239, 0.0]\n",
      "Capa 39 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362, 12283.836, 2774.239, 0.0, 0.0]\n",
      "Capa 43 Lambda\n",
      "tensor_cociente final 12385.99\n",
      "[122488.336, 499913.88, 144222.84, 115019.72, 15944.09, 17239.438, 13178.362, 12283.836, 2774.239, 0.0, 0.0, 12385.99]\n",
      "    numero    Capa  df_inp_output       df_razon\n",
      "0        2  Lambda     582.543457  122488.335938\n",
      "1        6  Lambda    5886.127441  499913.875000\n",
      "2       10  Lambda    1779.643555  144222.843750\n",
      "3       14  Lambda     929.754883  115019.718750\n",
      "4       18  Lambda     201.146484   15944.089844\n",
      "5       22  Lambda     235.140625   17239.437500\n",
      "6       26  Lambda     234.544434   13178.362305\n",
      "7       30  Lambda     198.915527   12283.835938\n",
      "8       32  Lambda      80.534180    2774.239014\n",
      "9       36  Lambda       0.000000       0.000000\n",
      "10      39  Lambda       0.000000       0.000000\n",
      "11      43  Lambda       0.000185   12385.990234\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,10,14,18,22,26,30,32,36,39,43]\n",
    "buf_cociente=AnlyzExp(ZFNetOriginal,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/ZFNet_mask_orig.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc69dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redondeo\n",
      "750/750 [==============================] - 122s 162ms/step - loss: 12.4162 - accuracy: 0.1173\n"
     ]
    }
   ],
   "source": [
    "from Nets import GetNeuralNetworkModel\n",
    "from Stats_original import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "ZFNetRound = GetNeuralNetworkModel('ZFNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "ZFNetRound.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "ZFNetRound.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = ZFNetRound, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =ZFNetRound.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82be5450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 193054.28\n",
      "[193054.28]\n",
      "Capa 6 Lambda\n",
      "tensor_cociente final 529806.9\n",
      "[193054.28, 529806.9]\n",
      "Capa 10 Lambda\n",
      "tensor_cociente final 128657.555\n",
      "[193054.28, 529806.9, 128657.555]\n",
      "Capa 14 Lambda\n",
      "tensor_cociente final 133133.42\n",
      "[193054.28, 529806.9, 128657.555, 133133.42]\n",
      "Capa 18 Lambda\n",
      "tensor_cociente final 10003.197\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197]\n",
      "Capa 22 Lambda\n",
      "tensor_cociente final 22091.963\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963]\n",
      "Capa 26 Lambda\n",
      "tensor_cociente final 16392.47\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47]\n",
      "Capa 30 Lambda\n",
      "tensor_cociente final 12100.453\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47, 12100.453]\n",
      "Capa 32 Lambda\n",
      "tensor_cociente final 2758.854\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47, 12100.453, 2758.854]\n",
      "Capa 36 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47, 12100.453, 2758.854, 0.0]\n",
      "Capa 39 Lambda\n",
      "tensor_cociente final 0.0\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47, 12100.453, 2758.854, 0.0, 0.0]\n",
      "Capa 43 Lambda\n",
      "tensor_cociente final 6611.688\n",
      "[193054.28, 529806.9, 128657.555, 133133.42, 10003.197, 22091.963, 16392.47, 12100.453, 2758.854, 0.0, 0.0, 6611.688]\n",
      "    numero    Capa  df_inp_output       df_razon\n",
      "0        2  Lambda     407.210938  193054.281250\n",
      "1        6  Lambda    5726.552734  529806.875000\n",
      "2       10  Lambda    1692.420898  128657.554688\n",
      "3       14  Lambda     868.745117  133133.421875\n",
      "4       18  Lambda     175.460449   10003.197266\n",
      "5       22  Lambda     227.306152   22091.962891\n",
      "6       26  Lambda     230.030762   16392.470703\n",
      "7       30  Lambda     198.821289   12100.453125\n",
      "8       32  Lambda      80.348145    2758.854004\n",
      "9       36  Lambda       0.000000       0.000000\n",
      "10      39  Lambda       0.000000       0.000000\n",
      "11      43  Lambda       0.000332    6611.687988\n"
     ]
    }
   ],
   "source": [
    "write_layer=[2,6,10,14,18,22,26,30,32,36,39,43]\n",
    "buf_cociente=AnlyzExp(ZFNetRound,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/ZFNet_mask_redond.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb20ca",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d22a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from Training import GetDatasets\n",
    "from Simulation import get_all_outputs\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from funciones import compilNet, same_elements\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainBatchSize = testBatchSize = 1\n",
    "_, _, test_dataset = GetDatasets('colorectal_histology', (80, 5, 15), (224, 224), 8, trainBatchSize, testBatchSize)\n",
    "\n",
    "\n",
    "\n",
    "word_size  = 16\n",
    "afrac_size = 12\n",
    "aint_size  = 3\n",
    "wfrac_size = 13\n",
    "wint_size  = 2\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'DenseNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Colorectal Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e9b07c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9439\n",
      "9439\n"
     ]
    }
   ],
   "source": [
    "Cargar_errores = True\n",
    "if Cargar_errores:\n",
    "    locs  = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/locs_054')\n",
    "    error_mask = load_obj('Data/Fault Characterization/variante_mask_vc_707/vc_707/error_mask_054')\n",
    "    print(len(locs))\n",
    "    print(len(error_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5369dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 452s 603ms/step - loss: 0.7139 - accuracy: 0.6600\n"
     ]
    }
   ],
   "source": [
    "from Nets_original import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, IntroduceFaultsInWeights, GenerateFaultsList\n",
    "DenseNetOriginal = GetNeuralNetworkModel('DenseNet', (224,224,3), 8, faulty_addresses=locs, masked_faults=error_mask,\n",
    "                                 aging_active=True, word_size=word_size, frac_size=afrac_size, \n",
    "                                 batch_size = testBatchSize)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "DenseNetOriginal.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "DenseNetOriginal.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = DenseNetOriginal, frac_bits = afrac_size, int_bits = aint_size)\n",
    "loss,acc =DenseNetOriginal.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9594c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa 2 Lambda\n",
      "tensor_cociente final 249138.75\n",
      "[249138.75]\n",
      "Capa 9 Lambda\n",
      "tensor_cociente final 2083457.5\n",
      "[249138.75, 2083457.5]\n",
      "Capa 11 MaxPooling2D\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1,114,114,64] vs. [1,56,56,64] [Op:Sub]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m write_layer\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m21\u001b[39m,(\u001b[38;5;241m23\u001b[39m,\u001b[38;5;241m11\u001b[39m),\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m34\u001b[39m,(\u001b[38;5;241m36\u001b[39m,\u001b[38;5;241m24\u001b[39m),\u001b[38;5;241m41\u001b[39m,\u001b[38;5;241m47\u001b[39m,(\u001b[38;5;241m49\u001b[39m,\u001b[38;5;241m37\u001b[39m),\u001b[38;5;241m54\u001b[39m,\u001b[38;5;241m60\u001b[39m,(\u001b[38;5;241m62\u001b[39m,\u001b[38;5;241m50\u001b[39m),\u001b[38;5;241m67\u001b[39m,\u001b[38;5;241m73\u001b[39m,(\u001b[38;5;241m75\u001b[39m,\u001b[38;5;241m63\u001b[39m),\u001b[38;5;241m80\u001b[39m,\u001b[38;5;241m86\u001b[39m,(\u001b[38;5;241m88\u001b[39m,\u001b[38;5;241m76\u001b[39m),\u001b[38;5;241m93\u001b[39m,\u001b[38;5;241m96\u001b[39m,\u001b[38;5;241m98\u001b[39m,\u001b[38;5;241m102\u001b[39m,\u001b[38;5;241m108\u001b[39m,(\u001b[38;5;241m110\u001b[39m,\u001b[38;5;241m98\u001b[39m),\n\u001b[0;32m      2\u001b[0m      \u001b[38;5;241m115\u001b[39m,\u001b[38;5;241m121\u001b[39m,(\u001b[38;5;241m123\u001b[39m,\u001b[38;5;241m111\u001b[39m),\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m134\u001b[39m,(\u001b[38;5;241m136\u001b[39m,\u001b[38;5;241m124\u001b[39m),\u001b[38;5;241m141\u001b[39m,\u001b[38;5;241m147\u001b[39m,(\u001b[38;5;241m149\u001b[39m,\u001b[38;5;241m137\u001b[39m),\u001b[38;5;241m154\u001b[39m,\u001b[38;5;241m160\u001b[39m,(\u001b[38;5;241m162\u001b[39m,\u001b[38;5;241m150\u001b[39m),\u001b[38;5;241m167\u001b[39m,\u001b[38;5;241m173\u001b[39m,(\u001b[38;5;241m175\u001b[39m,\u001b[38;5;241m163\u001b[39m),\u001b[38;5;241m180\u001b[39m,\u001b[38;5;241m186\u001b[39m,(\u001b[38;5;241m188\u001b[39m,\u001b[38;5;241m176\u001b[39m),\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;241m193\u001b[39m,\u001b[38;5;241m199\u001b[39m,(\u001b[38;5;241m201\u001b[39m,\u001b[38;5;241m189\u001b[39m),\u001b[38;5;241m206\u001b[39m,\u001b[38;5;241m212\u001b[39m,(\u001b[38;5;241m214\u001b[39m,\u001b[38;5;241m202\u001b[39m),\u001b[38;5;241m219\u001b[39m,\u001b[38;5;241m225\u001b[39m,(\u001b[38;5;241m227\u001b[39m,\u001b[38;5;241m215\u001b[39m),\u001b[38;5;241m232\u001b[39m,\u001b[38;5;241m238\u001b[39m,(\u001b[38;5;241m240\u001b[39m,\u001b[38;5;241m228\u001b[39m),\u001b[38;5;241m245\u001b[39m,\u001b[38;5;241m251\u001b[39m,(\u001b[38;5;241m253\u001b[39m,\u001b[38;5;241m241\u001b[39m),\u001b[38;5;241m258\u001b[39m,\u001b[38;5;241m261\u001b[39m,\u001b[38;5;241m263\u001b[39m,\u001b[38;5;241m267\u001b[39m,\u001b[38;5;241m273\u001b[39m,(\u001b[38;5;241m275\u001b[39m,\u001b[38;5;241m263\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m      \u001b[38;5;241m679\u001b[39m,\u001b[38;5;241m685\u001b[39m,(\u001b[38;5;241m687\u001b[39m,\u001b[38;5;241m675\u001b[39m),\u001b[38;5;241m692\u001b[39m,\u001b[38;5;241m698\u001b[39m,(\u001b[38;5;241m700\u001b[39m,\u001b[38;5;241m688\u001b[39m),\u001b[38;5;241m705\u001b[39m,\u001b[38;5;241m711\u001b[39m,(\u001b[38;5;241m713\u001b[39m,\u001b[38;5;241m701\u001b[39m),\u001b[38;5;241m718\u001b[39m,\u001b[38;5;241m724\u001b[39m,(\u001b[38;5;241m726\u001b[39m,\u001b[38;5;241m714\u001b[39m),\u001b[38;5;241m731\u001b[39m,\u001b[38;5;241m737\u001b[39m,(\u001b[38;5;241m739\u001b[39m,\u001b[38;5;241m727\u001b[39m),\u001b[38;5;241m744\u001b[39m,\u001b[38;5;241m750\u001b[39m,(\u001b[38;5;241m752\u001b[39m,\u001b[38;5;241m740\u001b[39m),\n\u001b[0;32m     10\u001b[0m      \u001b[38;5;241m757\u001b[39m,\u001b[38;5;241m763\u001b[39m,(\u001b[38;5;241m765\u001b[39m,\u001b[38;5;241m753\u001b[39m),\u001b[38;5;241m770\u001b[39m,\u001b[38;5;241m776\u001b[39m,(\u001b[38;5;241m778\u001b[39m,\u001b[38;5;241m766\u001b[39m),\u001b[38;5;241m783\u001b[39m,\u001b[38;5;241m789\u001b[39m,(\u001b[38;5;241m791\u001b[39m,\u001b[38;5;241m779\u001b[39m),\u001b[38;5;241m796\u001b[39m,\u001b[38;5;241m799\u001b[39m,\u001b[38;5;241m803\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m buf_cociente\u001b[38;5;241m=\u001b[39m\u001b[43mAnlyzExp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDenseNetOriginal\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwrite_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnalizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/DenseNet_mask_orig.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     13\u001b[0m         buf_cociente\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuf_diff_inp_out\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mAnlyzExp\u001b[1;34m(net, Layer)\u001b[0m\n\u001b[0;32m     22\u001b[0m out_quantizacion \u001b[38;5;241m=\u001b[39m out[j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     23\u001b[0m out_error_and_correction \u001b[38;5;241m=\u001b[39m out[j]\n\u001b[1;32m---> 24\u001b[0m tensor_aux\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mabs(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_quantizacion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_error_and_correction\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     25\u001b[0m diff_inp_out\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mabs(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39msubtract(out_quantizacion,out_error_and_correction )))\n\u001b[0;32m     26\u001b[0m input_sin_ceros\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mabs(tf\u001b[38;5;241m.\u001b[39mwhere(tf\u001b[38;5;241m.\u001b[39mequal(out_quantizacion,\u001b[38;5;241m0\u001b[39m),tf\u001b[38;5;241m.\u001b[39mones_like(out_quantizacion),out_quantizacion))    \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:548\u001b[0m, in \u001b[0;36msubtract\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.subtract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtract\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubtract\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 548\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:10551\u001b[0m, in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  10549\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  10550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m> 10551\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10552\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m  10553\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6897\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6896\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6897\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1,114,114,64] vs. [1,56,56,64] [Op:Sub]"
     ]
    }
   ],
   "source": [
    "write_layer=[2,9,11,15,21,(23,11),28,34,(36,24),41,47,(49,37),54,60,(62,50),67,73,(75,63),80,86,(88,76),93,96,98,102,108,(110,98),\n",
    "     115,121,(123,111),128,134,(136,124),141,147,(149,137),154,160,(162,150),167,173,(175,163),180,186,(188,176),\n",
    "     193,199,(201,189),206,212,(214,202),219,225,(227,215),232,238,(240,228),245,251,(253,241),258,261,263,267,273,(275,263),\n",
    "     280,286,(288,276),293,299,(301,289),306,312,(314,302),319,325,(327,315),332,338,(340,328),345,351,(353,341),\n",
    "     358,364,(366,353),371,377,(379,367),384,390,(392,380),397,403,(405,393),410,416,(418,406),423,429,(431,419),\n",
    "     436,442,(444,432),449,455,(457,445),462,468,(470,458),475,481,(483,471),488,494,(496,484),501,507,(509,497),\n",
    "     514,520,(522,510),527,533,(535,523),540,546,(548,536),553,559,(561,549),566,572,(574,562),579,582,584,588,594,(596,584),\n",
    "     601,607,(609,597),614,620,(622,610),627,633,(635,623),640,646,(648,636),653,659,(661,649),666,672,(674,662),\n",
    "     679,685,(687,675),692,698,(700,688),705,711,(713,701),718,724,(726,714),731,737,(739,727),744,750,(752,740),\n",
    "     757,763,(765,753),770,776,(778,766),783,789,(791,779),796,799,803]\n",
    "buf_cociente=AnlyzExp(DenseNetOriginal,write_layer)\n",
    "with pd.ExcelWriter('Analizando_fichero_detalle/Alterado_fichero/diferencias_entre_resultados/DenseNet_mask_orig.xlsx') as writer:\n",
    "        buf_cociente.to_excel(writer, sheet_name='buf_diff_inp_out', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4e7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_first",
   "language": "python",
   "name": "env_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
