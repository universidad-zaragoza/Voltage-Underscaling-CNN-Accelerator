{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from Heatmap_plot import Heatmap\n",
    "from Training import GetIMBDDataset\n",
    "from Nets_original  import GetNeuralNetworkModel\n",
    "from Stats import WeightQuantization, ActivationStats, CheckAccuracyAndLoss, QuantizationEffect, GetReadAndWrites\n",
    "from Simulation import buffer_simulation, save_obj, load_obj\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = test_batch_size = 1\n",
    "train_set,valid_set,test_set  = GetIMBDDataset(train_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b) Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aging_active False\n"
     ]
    }
   ],
   "source": [
    "activation_aging = [False]*4\n",
    "\n",
    "SentimentalNet = GetNeuralNetworkModel('SentimentalNet',(500),1,quantization = False,aging_active = activation_aging)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "metrics = ['accuracy']\n",
    "# Compile Model\n",
    "SentimentalNet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 38s 2ms/step - loss: 0.6931 - accuracy: 0.5077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6930970549583435, 0.5076666474342346]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentimentalNet.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 251       \n",
      "_________________________________________________________________\n",
      "lambda_8 (Lambda)            (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda) (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_9 (Lambda)            (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SentimentalNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d) Save/Load Weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2189a865f10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "wgt_dir = os.path.join(cwd, 'Data')\n",
    "wgt_dir = os.path.join(wgt_dir, 'Trained Weights')\n",
    "wgt_dir = os.path.join(wgt_dir, 'SentimentalNet')\n",
    "wgt_dir = os.path.join(wgt_dir, 'IMBD Reviews Dataset')\n",
    "wgt_dir = os.path.join(wgt_dir,'Weights')\n",
    "SentimentalNet.load_weights(wgt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  e) Activation Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value (MMU): -0.00054240436\n",
      "mean value (Buffer): 0.008347793\n",
      "maximum (MMU): 9.246262\n",
      "minimum (MMU): -10.349268\n",
      "maximum (Buffer): 1.5768503\n",
      "minimum (Buffer): -0.16261402\n",
      "saturation ratio (MMU): 3.7118110444012754e-05\n",
      "saturation ratio (Buffer): 0.0\n"
     ]
    }
   ],
   "source": [
    "    ActivationStats(SentimentalNet,test_set,14,1,499)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  f) Write/Read Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indices  = [1,4,8,12,16]\n",
    "#Data     = GetReadAndWrites(SentimentalNet,Indices,16000,150,CNN_gating=False)\n",
    "#stats    = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "#Baseline_Acceses   = pd.DataFrame(stats).reset_index(drop=False)\n",
    "#Data     = GetReadAndWrites(SentimentalNet,Indices,1024*1024,150,CNN_gating=True)\n",
    "#stats    = {'Lecturas': Data['Reads'],'Escrituras': Data['Writes']}\n",
    "#CNN_gating_Acceses = pd.DataFrame(stats).reset_index(drop=False)\n",
    "##save_obj(Baseline_Acceses,'Data/Acceses/SentimentalNet/Baseline')\n",
    "#save_obj(CNN_gating_Acceses,'Data/Acceses/SentimentalNet/CNN_gating_Fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Quantization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Starting Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aging_active False\n",
      "15000/15000 [==============================] - 24s 2ms/step - loss: 5.9819e-08 - accuracy: 0.8868\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracyAndLoss('SentimentalNet', test_set, wgt_dir, act_frac_size = 15, act_int_size = 0, wgt_frac_size = 15, wgt_int_size = 0, \n",
    "                    input_shape = (500), output_shape = 1, batch_size = test_batch_size, aging_active = activation_aging);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b) Number of bits analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estoy aquí en el efecto d ecuantización\n",
      "Activation fraction part\n",
      "aging_active False\n",
      "0  bits results:  acc:  0.498199999332428 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.498199999332428 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.498199999332428 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.8353333473205566 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.8749333620071411 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.8824666738510132 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.8881999850273132 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.8851333260536194 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.8861333131790161 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.8866000175476074 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.88673335313797 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.8866666555404663 loss:  nan\n",
      "Weights fraction part\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  bits results:  acc:  0.498199999332428 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.498199999332428 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.498199999332428 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.6887999773025513 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.8673333525657654 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.883733332157135 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.8862000107765198 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.8866666555404663 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.884933352470398 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.8864666819572449 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.8868666887283325 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.8868666887283325 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.88673335313797 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.8866000175476074 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "Activation integer part\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:350: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights fraction part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  bits results:  acc:  0.8867999911308289 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.8867999911308289 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.8867999911308289 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.8867999911308289 loss:  5.981922868159018e-08\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "Weights integer part\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:356: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Activation integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  bits results:  acc:  0.8867999911308289 loss:  nan\n",
      "aging_active False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  bits results:  acc:  0.8867999911308289 loss:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py:362: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame({'Experiment':['Weights integer part'],'bits':[bit],'acc':[acc],'loss':[loss]}))\n"
     ]
    }
   ],
   "source": [
    "df = QuantizationEffect('SentimentalNet',test_set,wgt_dir,(500),1,test_batch_size)\n",
    "#save_obj(df,'Data/Quantization/SentimentalNet/IMDB Reviews Dataset/Quantization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; f) Used Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_3932\\4008800163.py\", line 1, in <cell line: 1>\n",
      "    CheckAccuracyAndLoss('SentimentalNet', test_set, wgt_dir, act_frac_size = 14, act_int_size = 1, wgt_frac_size = 15, wgt_int_size = 0,\n",
      "  File \"C:\\Users\\usuario\\Desktop\\CNN_Gating\\Stats.py\", line 110, in CheckAccuracyAndLoss\n",
      "    qNet = GetNeuralNetworkModel(architecture,input_shape,output_shape,faulty_addresses,masked_faults,aging_active=aging_active,\n",
      "  File \"C:\\Users\\usuario\\Desktop\\CNN_Gating\\Nets_original.py\", line 514, in GetNeuralNetworkModel\n",
      "    print('aging_active',aging_active[0])\n",
      "TypeError: 'bool' object is not subscriptable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracyAndLoss('SentimentalNet', test_set, wgt_dir, act_frac_size = 14, act_int_size = 1, wgt_frac_size = 15, wgt_int_size = 0, \n",
    "                    input_shape = (500), output_shape = 1, batch_size = test_batch_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Buffer Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\usuario\\anaconda3\\envs\\env_first\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aging_active False\n",
      "buffer sections:  [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000]\n",
      "Simulation Started, time: 15:17:12 cycles:  0 offset:  0\n"
     ]
    },
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m LI \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m16\u001b[39m]\n\u001b[0;32m     13\u001b[0m AI \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m19\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m \u001b[43mbuffer_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQSentimentalNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtestSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteger_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfractional_bits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_from\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbit_invertion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit_shifting\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCNN_gating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Stats/SentimentalNet/IMDB Reviews Dataset/Baseline/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlayer_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLI\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_indixes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAI\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:504\u001b[0m, in \u001b[0;36mbuffer_simulation\u001b[1;34m(network, dataset, samples, integer_bits, fractional_bits, bit_invertion, bit_shifting, write_mode, CNN_gating, buffer_size, start_from, results_dir, layer_indexes, activation_indixes, save_results, network_type)\u001b[0m\n\u001b[0;32m    499\u001b[0m \tactivacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m activacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,activacions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msize))\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# una variable [] donde guardaré los ciclos de cada iteración sin sumar\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# una variable [arreglo] donde guardaré el nombre de las capas de cada iteración sin sumar\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# cycles_capa.append(cycles)\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m cycles \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43msimulate_one_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivacions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcycles\u001b[39m\u001b[38;5;124m'\u001b[39m,cycles)\n\u001b[0;32m    507\u001b[0m buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLowCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m cycles \u001b[38;5;241m-\u001b[39m  buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHighCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m-\u001b[39m  buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOffCyclesCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:420\u001b[0m, in \u001b[0;36msimulate_one_image\u001b[1;34m(network_type, layers, activations, config, buffer, first_buffer)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index,layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layers):\n\u001b[0;32m    419\u001b[0m \ttmp \u001b[38;5;241m=\u001b[39m cycles\n\u001b[1;32m--> 420\u001b[0m \tcycles_temp\u001b[38;5;241m=\u001b[39m\u001b[43mhandle_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \tlayer_list\u001b[38;5;241m.\u001b[39mappend(layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    422\u001b[0m \tcycles_by_layer\u001b[38;5;241m.\u001b[39mappend(cycles_temp)\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:412\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.handle_layer\u001b[1;34m(buffer, layer, layer_outputs, out_buffer_id)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    411\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--now processing CPULayer\u001b[39m\u001b[38;5;124m'\u001b[39m, layer\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m--> 412\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msim_CPULayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_buffer_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:339\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.sim_CPULayer\u001b[1;34m(buffer, layer, layer_outputs, write_buffer_id)\u001b[0m\n\u001b[0;32m    337\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(layer_outputs\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39macts_per_cycle))\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m \tcycles \u001b[38;5;241m=\u001b[39m \u001b[43mwrite_Loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----elapsed layer simulation time: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m t0)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    341\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m cycles\n",
      "File \u001b[1;32m~\\Desktop\\CNN_Gating\\Simulation.py:193\u001b[0m, in \u001b[0;36msimulate_one_image.<locals>.write_Loop\u001b[1;34m(buffer, layer, activations, manual_offset, params)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m#Update stats after the initial delay\u001b[39;00m\n\u001b[0;32m    192\u001b[0m cycles \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial Delay\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 193\u001b[0m \u001b[43mupdate_high_cycle_count\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblockspergrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreadsperblock\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhigh_cycles_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInitial Delay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m#Acceleration of GPU Memory Transfer using small representation\u001b[39;00m\n\u001b[0;32m    195\u001b[0m tmp_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:821\u001b[0m, in \u001b[0;36m_KernelConfiguration.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgriddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblockdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msharedmem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:964\u001b[0m, in \u001b[0;36mDispatcher.call\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    962\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 964\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m kernel\u001b[38;5;241m.\u001b[39mlaunch(args, griddim, blockdim, stream, sharedmem)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:972\u001b[0m, in \u001b[0;36mDispatcher._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kws\n\u001b[0;32m    971\u001b[0m argtypes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeof_pyval(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 972\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:1102\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert(c_sig, kernel, cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads[argtypes] \u001b[38;5;241m=\u001b[39m kernel\n\u001b[1;32m-> 1102\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigs\u001b[38;5;241m.\u001b[39mappend(sig)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:590\u001b[0m, in \u001b[0;36m_Kernel.bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m    Force binding to current CUDA context\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\compiler.py:433\u001b[0m, in \u001b[0;36mCachedCUFunction.get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 433\u001b[0m     cuctx \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     device \u001b[38;5;241m=\u001b[39m cuctx\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    435\u001b[0m     cufunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;241m.\u001b[39mget(device\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:212\u001b[0m, in \u001b[0;36mget_context\u001b[1;34m(devnum)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(devnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m    return the CUDA context.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    136\u001b[0m attached_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_attached_context()\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attached_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_context_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:151\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mThis version does not read the cache.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mget_active_context() \u001b[38;5;28;01mas\u001b[39;00m ac:\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ac:\n\u001b[0;32m    153\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activate_context_for(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:393\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# Not cached. Query the driver API.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m drvapi\u001b[38;5;241m.\u001b[39mcu_context(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxGetCurrent\u001b[49m(byref(hctx))\n\u001b[0;32m    394\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m hctx \u001b[38;5;28;01mif\u001b[39;00m hctx\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_first\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:283\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CudaSupportError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at driver init: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    284\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# Find function in driver library\u001b[39;00m\n\u001b[0;32m    287\u001b[0m libfn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_api(fname)\n",
      "\u001b[1;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,testSet = GetIMBDDataset(train_batch_size=1, test_batch_size=1)\n",
    "activation_aging = [False]*4\n",
    "\n",
    "QSentimentalNet  = GetNeuralNetworkModel('SentimentalNet',(500),1,quantization = True, aging_active = activation_aging,word_size = 16, frac_size = 15)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "QSentimentalNet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "QSentimentalNet.load_weights(wgt_dir).expect_partial()\n",
    "WeightQuantization(model = QSentimentalNet, frac_bits = 15, int_bits = 0)\n",
    "\n",
    "\n",
    "LI = [1,4,8,12,16]\n",
    "AI = [3,7,10,15,19]\n",
    "buffer_simulation(QSentimentalNet,testSet, integer_bits = 0, fractional_bits = 15, samples = 150, start_from = 0,\n",
    "                 bit_invertion = False, bit_shifting = False, CNN_gating = False, write_mode ='default',\n",
    "                 results_dir = 'Data/Stats/SentimentalNet/IMDB Reviews Dataset/Baseline/',buffer_size = 2*16000,\n",
    "                 layer_indexes = LI , activation_indixes = AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CNN-Gated, case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "c:\\users\\nicol\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "c:\\users\\nicol\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer sections:  [0, 131072, 262144, 393216, 524288, 655360, 786432, 917504, 1048576]\n",
      "Simulation Started, time: 12:53:19 cycles:  0 offset:  0\n",
      "procesed images: 0  time: 12:53:24 cycles:  13106 offset:  393216\n",
      "procesed images: 1  time: 12:53:26 cycles:  26212 offset:  655360\n",
      "procesed images: 2  time: 12:53:29 cycles:  39318 offset:  1048576\n",
      "procesed images: 3  time: 12:53:31 cycles:  52424 offset:  262144\n",
      "procesed images: 4  time: 12:53:34 cycles:  65530 offset:  655360\n",
      "procesed images: 5  time: 12:53:35 cycles:  78636 offset:  917504\n",
      "procesed images: 6  time: 12:53:38 cycles:  91742 offset:  262144\n",
      "procesed images: 7  time: 12:53:40 cycles:  104848 offset:  524288\n",
      "procesed images: 8  time: 12:53:43 cycles:  117954 offset:  917504\n",
      "procesed images: 9  time: 12:53:45 cycles:  131060 offset:  131072\n",
      "procesed images: 10  time: 12:53:48 cycles:  144166 offset:  524288\n",
      "procesed images: 11  time: 12:53:49 cycles:  157272 offset:  786432\n",
      "procesed images: 12  time: 12:53:53 cycles:  170378 offset:  131072\n",
      "procesed images: 13  time: 12:53:54 cycles:  183484 offset:  393216\n",
      "procesed images: 14  time: 12:53:57 cycles:  196590 offset:  786432\n",
      "procesed images: 15  time: 12:53:59 cycles:  209696 offset:  1048576\n",
      "procesed images: 16  time: 12:54:02 cycles:  222802 offset:  393216\n",
      "procesed images: 17  time: 12:54:04 cycles:  235908 offset:  655360\n",
      "procesed images: 18  time: 12:54:07 cycles:  249014 offset:  1048576\n",
      "procesed images: 19  time: 12:54:09 cycles:  262120 offset:  262144\n",
      "procesed images: 20  time: 12:54:12 cycles:  275226 offset:  655360\n",
      "procesed images: 21  time: 12:54:13 cycles:  288332 offset:  917504\n",
      "procesed images: 22  time: 12:54:16 cycles:  301438 offset:  262144\n",
      "procesed images: 23  time: 12:54:18 cycles:  314544 offset:  524288\n",
      "procesed images: 24  time: 12:54:21 cycles:  327650 offset:  917504\n",
      "procesed images: 25  time: 12:54:23 cycles:  340756 offset:  131072\n",
      "procesed images: 26  time: 12:54:26 cycles:  353862 offset:  524288\n",
      "procesed images: 27  time: 12:54:28 cycles:  366968 offset:  786432\n",
      "procesed images: 28  time: 12:54:31 cycles:  380074 offset:  131072\n",
      "procesed images: 29  time: 12:54:33 cycles:  393180 offset:  393216\n",
      "procesed images: 30  time: 12:54:36 cycles:  406286 offset:  786432\n",
      "procesed images: 31  time: 12:54:38 cycles:  419392 offset:  1048576\n",
      "procesed images: 32  time: 12:54:41 cycles:  432498 offset:  393216\n",
      "procesed images: 33  time: 12:54:42 cycles:  445604 offset:  655360\n",
      "procesed images: 34  time: 12:54:45 cycles:  458710 offset:  1048576\n",
      "procesed images: 35  time: 12:54:47 cycles:  471816 offset:  262144\n",
      "procesed images: 36  time: 12:54:50 cycles:  484922 offset:  655360\n",
      "procesed images: 37  time: 12:54:52 cycles:  498028 offset:  917504\n",
      "procesed images: 38  time: 12:54:55 cycles:  511134 offset:  262144\n",
      "procesed images: 39  time: 12:54:57 cycles:  524240 offset:  524288\n",
      "procesed images: 40  time: 12:55:00 cycles:  537346 offset:  917504\n",
      "procesed images: 41  time: 12:55:01 cycles:  550452 offset:  131072\n",
      "procesed images: 42  time: 12:55:05 cycles:  563558 offset:  524288\n",
      "procesed images: 43  time: 12:55:06 cycles:  576664 offset:  786432\n",
      "procesed images: 44  time: 12:55:09 cycles:  589770 offset:  131072\n",
      "procesed images: 45  time: 12:55:11 cycles:  602876 offset:  393216\n",
      "procesed images: 46  time: 12:55:14 cycles:  615982 offset:  786432\n",
      "procesed images: 47  time: 12:55:16 cycles:  629088 offset:  1048576\n",
      "procesed images: 48  time: 12:55:19 cycles:  642194 offset:  393216\n",
      "procesed images: 49  time: 12:55:21 cycles:  655300 offset:  655360\n",
      "procesed images: 50  time: 12:55:24 cycles:  668406 offset:  1048576\n",
      "procesed images: 51  time: 12:55:26 cycles:  681512 offset:  262144\n",
      "procesed images: 52  time: 12:55:29 cycles:  694618 offset:  655360\n",
      "procesed images: 53  time: 12:55:31 cycles:  707724 offset:  917504\n",
      "procesed images: 54  time: 12:55:34 cycles:  720830 offset:  262144\n",
      "procesed images: 55  time: 12:55:35 cycles:  733936 offset:  524288\n",
      "procesed images: 56  time: 12:55:39 cycles:  747042 offset:  917504\n",
      "procesed images: 57  time: 12:55:41 cycles:  760148 offset:  131072\n",
      "procesed images: 58  time: 12:55:44 cycles:  773254 offset:  524288\n",
      "procesed images: 59  time: 12:55:45 cycles:  786360 offset:  786432\n",
      "procesed images: 60  time: 12:55:48 cycles:  799466 offset:  131072\n",
      "procesed images: 61  time: 12:55:50 cycles:  812572 offset:  393216\n",
      "procesed images: 62  time: 12:55:53 cycles:  825678 offset:  786432\n",
      "procesed images: 63  time: 12:55:55 cycles:  838784 offset:  1048576\n",
      "procesed images: 64  time: 12:55:59 cycles:  851890 offset:  393216\n",
      "procesed images: 65  time: 12:56:00 cycles:  864996 offset:  655360\n",
      "procesed images: 66  time: 12:56:03 cycles:  878102 offset:  1048576\n",
      "procesed images: 67  time: 12:56:05 cycles:  891208 offset:  262144\n",
      "procesed images: 68  time: 12:56:08 cycles:  904314 offset:  655360\n",
      "procesed images: 69  time: 12:56:10 cycles:  917420 offset:  917504\n",
      "procesed images: 70  time: 12:56:14 cycles:  930526 offset:  262144\n",
      "procesed images: 71  time: 12:56:15 cycles:  943632 offset:  524288\n",
      "procesed images: 72  time: 12:56:19 cycles:  956738 offset:  917504\n",
      "procesed images: 73  time: 12:56:20 cycles:  969844 offset:  131072\n",
      "procesed images: 74  time: 12:56:23 cycles:  982950 offset:  524288\n",
      "procesed images: 75  time: 12:56:26 cycles:  996056 offset:  786432\n",
      "procesed images: 76  time: 12:56:29 cycles:  1009162 offset:  131072\n",
      "procesed images: 77  time: 12:56:31 cycles:  1022268 offset:  393216\n",
      "procesed images: 78  time: 12:56:34 cycles:  1035374 offset:  786432\n",
      "procesed images: 79  time: 12:56:36 cycles:  1048480 offset:  1048576\n",
      "procesed images: 80  time: 12:56:39 cycles:  1061586 offset:  393216\n",
      "procesed images: 81  time: 12:56:41 cycles:  1074692 offset:  655360\n",
      "procesed images: 82  time: 12:56:44 cycles:  1087798 offset:  1048576\n",
      "procesed images: 83  time: 12:56:46 cycles:  1100904 offset:  262144\n",
      "procesed images: 84  time: 12:56:49 cycles:  1114010 offset:  655360\n",
      "procesed images: 85  time: 12:56:51 cycles:  1127116 offset:  917504\n",
      "procesed images: 86  time: 12:56:54 cycles:  1140222 offset:  262144\n",
      "procesed images: 87  time: 12:56:56 cycles:  1153328 offset:  524288\n",
      "procesed images: 88  time: 12:56:59 cycles:  1166434 offset:  917504\n",
      "procesed images: 89  time: 12:57:00 cycles:  1179540 offset:  131072\n",
      "procesed images: 90  time: 12:57:04 cycles:  1192646 offset:  524288\n",
      "procesed images: 91  time: 12:57:05 cycles:  1205752 offset:  786432\n",
      "procesed images: 92  time: 12:57:08 cycles:  1218858 offset:  131072\n",
      "procesed images: 93  time: 12:57:10 cycles:  1231964 offset:  393216\n",
      "procesed images: 94  time: 12:57:13 cycles:  1245070 offset:  786432\n",
      "procesed images: 95  time: 12:57:15 cycles:  1258176 offset:  1048576\n",
      "procesed images: 96  time: 12:57:18 cycles:  1271282 offset:  393216\n",
      "procesed images: 97  time: 12:57:20 cycles:  1284388 offset:  655360\n",
      "procesed images: 98  time: 12:57:23 cycles:  1297494 offset:  1048576\n",
      "procesed images: 99  time: 12:57:24 cycles:  1310600 offset:  262144\n",
      "procesed images: 100  time: 12:57:28 cycles:  1323706 offset:  655360\n",
      "procesed images: 101  time: 12:57:30 cycles:  1336812 offset:  917504\n",
      "procesed images: 102  time: 12:57:33 cycles:  1349918 offset:  262144\n",
      "procesed images: 103  time: 12:57:35 cycles:  1363024 offset:  524288\n",
      "procesed images: 104  time: 12:57:38 cycles:  1376130 offset:  917504\n",
      "procesed images: 105  time: 12:57:40 cycles:  1389236 offset:  131072\n",
      "procesed images: 106  time: 12:57:43 cycles:  1402342 offset:  524288\n",
      "procesed images: 107  time: 12:57:45 cycles:  1415448 offset:  786432\n",
      "procesed images: 108  time: 12:57:48 cycles:  1428554 offset:  131072\n",
      "procesed images: 109  time: 12:57:50 cycles:  1441660 offset:  393216\n",
      "procesed images: 110  time: 12:57:53 cycles:  1454766 offset:  786432\n",
      "procesed images: 111  time: 12:57:55 cycles:  1467872 offset:  1048576\n",
      "procesed images: 112  time: 12:57:58 cycles:  1480978 offset:  393216\n",
      "procesed images: 113  time: 12:58:00 cycles:  1494084 offset:  655360\n",
      "procesed images: 114  time: 12:58:03 cycles:  1507190 offset:  1048576\n",
      "procesed images: 115  time: 12:58:04 cycles:  1520296 offset:  262144\n",
      "procesed images: 116  time: 12:58:08 cycles:  1533402 offset:  655360\n",
      "procesed images: 117  time: 12:58:09 cycles:  1546508 offset:  917504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesed images: 118  time: 12:58:12 cycles:  1559614 offset:  262144\n",
      "procesed images: 119  time: 12:58:14 cycles:  1572720 offset:  524288\n",
      "procesed images: 120  time: 12:58:17 cycles:  1585826 offset:  917504\n",
      "procesed images: 121  time: 12:58:19 cycles:  1598932 offset:  131072\n",
      "procesed images: 122  time: 12:58:22 cycles:  1612038 offset:  524288\n",
      "procesed images: 123  time: 12:58:24 cycles:  1625144 offset:  786432\n",
      "procesed images: 124  time: 12:58:27 cycles:  1638250 offset:  131072\n",
      "procesed images: 125  time: 12:58:29 cycles:  1651356 offset:  393216\n",
      "procesed images: 126  time: 12:58:32 cycles:  1664462 offset:  786432\n",
      "procesed images: 127  time: 12:58:34 cycles:  1677568 offset:  1048576\n",
      "procesed images: 128  time: 12:58:37 cycles:  1690674 offset:  393216\n",
      "procesed images: 129  time: 12:58:39 cycles:  1703780 offset:  655360\n",
      "procesed images: 130  time: 12:58:42 cycles:  1716886 offset:  1048576\n",
      "procesed images: 131  time: 12:58:44 cycles:  1729992 offset:  262144\n",
      "procesed images: 132  time: 12:58:47 cycles:  1743098 offset:  655360\n",
      "procesed images: 133  time: 12:58:49 cycles:  1756204 offset:  917504\n",
      "procesed images: 134  time: 12:58:52 cycles:  1769310 offset:  262144\n",
      "procesed images: 135  time: 12:58:54 cycles:  1782416 offset:  524288\n",
      "procesed images: 136  time: 12:58:57 cycles:  1795522 offset:  917504\n",
      "procesed images: 137  time: 12:58:58 cycles:  1808628 offset:  131072\n",
      "procesed images: 138  time: 12:59:02 cycles:  1821734 offset:  524288\n",
      "procesed images: 139  time: 12:59:03 cycles:  1834840 offset:  786432\n",
      "procesed images: 140  time: 12:59:06 cycles:  1847946 offset:  131072\n",
      "procesed images: 141  time: 12:59:08 cycles:  1861052 offset:  393216\n",
      "procesed images: 142  time: 12:59:11 cycles:  1874158 offset:  786432\n",
      "procesed images: 143  time: 12:59:13 cycles:  1887264 offset:  1048576\n",
      "procesed images: 144  time: 12:59:16 cycles:  1900370 offset:  393216\n",
      "procesed images: 145  time: 12:59:18 cycles:  1913476 offset:  655360\n",
      "procesed images: 146  time: 12:59:21 cycles:  1926582 offset:  1048576\n",
      "procesed images: 147  time: 12:59:22 cycles:  1939688 offset:  262144\n",
      "procesed images: 148  time: 12:59:25 cycles:  1952794 offset:  655360\n",
      "procesed images: 149  time: 12:59:27 cycles:  1965900 offset:  917504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Number of Addresses': 1048576,\n",
       "  'Data': array([2, 2, 2, ..., 2, 2, 2], dtype=int8),\n",
       "  'HighCyclesCount': array([ 82694,  34413,  33215, ...,  97722, 111114, 144354], dtype=uint32),\n",
       "  'OffCyclesCount': array([1727008, 1727008, 1727008, ..., 1735500, 1735500, 1735500],\n",
       "        dtype=uint32),\n",
       "  'LowCyclesCount': array([156198, 204479, 205677, ..., 132678, 119286,  86046], dtype=uint32),\n",
       "  'Flips': array([25, 22, 17, ...,  0,  0,  0], dtype=uint32),\n",
       "  'offset': 917504},\n",
       " 1965900)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,testSet = GetIMBDDataset(train_batch_size=1, test_batch_size=1)\n",
    "\n",
    "QSentimentalNet  = GetNeuralNetworkModel('SentimentalNet',(500),1,quantization = True, aging=False,wordSize = 16, fracSize = 15)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "QSentimentalNet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "QSentimentalNet.load_weights(wgtDir).expect_partial()\n",
    "WeightQuantization(model = QSentimentalNet, fracBits = 15, intBits = 0)\n",
    "\n",
    "\n",
    "LI = [1,4,8,12,16]\n",
    "AI = [3,7,10,15,19]\n",
    "buffer_simulation(QSentimentalNet,testSet, integer_bits = 0, fractional_bits = 15, samples = 150, start_from = 0,\n",
    "                 bit_invertion = False, bit_shifting = False, CNN_gating = True, write_mode ='default',\n",
    "                 results_dir = 'Data/Stats/SentimentalNet/IMDB Reviews Dataset/CNN-Gated/Full Buffer',buffer_size = 2*1024*1024,\n",
    "                 layer_indexes = LI , activation_indixes = AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CNN-Gated, case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer sections:  [0, 2000, 4000, 6000, 8000, 10000, 12000, 14000, 16000]\n",
      "Simulation Started, time: 13:00:41 cycles:  0 offset:  0\n",
      "procesed images: 0  time: 13:00:44 cycles:  13106 offset:  10000\n",
      "procesed images: 1  time: 13:00:45 cycles:  26212 offset:  12000\n",
      "procesed images: 2  time: 13:00:47 cycles:  39318 offset:  6000\n",
      "procesed images: 3  time: 13:00:48 cycles:  52424 offset:  8000\n",
      "procesed images: 4  time: 13:00:50 cycles:  65530 offset:  2000\n",
      "procesed images: 5  time: 13:00:50 cycles:  78636 offset:  4000\n",
      "procesed images: 6  time: 13:00:52 cycles:  91742 offset:  14000\n",
      "procesed images: 7  time: 13:00:53 cycles:  104848 offset:  16000\n",
      "procesed images: 8  time: 13:00:55 cycles:  117954 offset:  10000\n",
      "procesed images: 9  time: 13:00:56 cycles:  131060 offset:  12000\n",
      "procesed images: 10  time: 13:00:58 cycles:  144166 offset:  6000\n",
      "procesed images: 11  time: 13:00:58 cycles:  157272 offset:  8000\n",
      "procesed images: 12  time: 13:01:00 cycles:  170378 offset:  2000\n",
      "procesed images: 13  time: 13:01:01 cycles:  183484 offset:  4000\n",
      "procesed images: 14  time: 13:01:03 cycles:  196590 offset:  14000\n",
      "procesed images: 15  time: 13:01:04 cycles:  209696 offset:  16000\n",
      "procesed images: 16  time: 13:01:06 cycles:  222802 offset:  10000\n",
      "procesed images: 17  time: 13:01:07 cycles:  235908 offset:  12000\n",
      "procesed images: 18  time: 13:01:09 cycles:  249014 offset:  6000\n",
      "procesed images: 19  time: 13:01:09 cycles:  262120 offset:  8000\n",
      "procesed images: 20  time: 13:01:11 cycles:  275226 offset:  2000\n",
      "procesed images: 21  time: 13:01:12 cycles:  288332 offset:  4000\n",
      "procesed images: 22  time: 13:01:14 cycles:  301438 offset:  14000\n",
      "procesed images: 23  time: 13:01:15 cycles:  314544 offset:  16000\n",
      "procesed images: 24  time: 13:01:17 cycles:  327650 offset:  10000\n",
      "procesed images: 25  time: 13:01:18 cycles:  340756 offset:  12000\n",
      "procesed images: 26  time: 13:01:20 cycles:  353862 offset:  6000\n",
      "procesed images: 27  time: 13:01:20 cycles:  366968 offset:  8000\n",
      "procesed images: 28  time: 13:01:22 cycles:  380074 offset:  2000\n",
      "procesed images: 29  time: 13:01:23 cycles:  393180 offset:  4000\n",
      "procesed images: 30  time: 13:01:25 cycles:  406286 offset:  14000\n",
      "procesed images: 31  time: 13:01:26 cycles:  419392 offset:  16000\n",
      "procesed images: 32  time: 13:01:28 cycles:  432498 offset:  10000\n",
      "procesed images: 33  time: 13:01:28 cycles:  445604 offset:  12000\n",
      "procesed images: 34  time: 13:01:30 cycles:  458710 offset:  6000\n",
      "procesed images: 35  time: 13:01:31 cycles:  471816 offset:  8000\n",
      "procesed images: 36  time: 13:01:33 cycles:  484922 offset:  2000\n",
      "procesed images: 37  time: 13:01:34 cycles:  498028 offset:  4000\n",
      "procesed images: 38  time: 13:01:36 cycles:  511134 offset:  14000\n",
      "procesed images: 39  time: 13:01:37 cycles:  524240 offset:  16000\n",
      "procesed images: 40  time: 13:01:39 cycles:  537346 offset:  10000\n",
      "procesed images: 41  time: 13:01:39 cycles:  550452 offset:  12000\n",
      "procesed images: 42  time: 13:01:41 cycles:  563558 offset:  6000\n",
      "procesed images: 43  time: 13:01:42 cycles:  576664 offset:  8000\n",
      "procesed images: 44  time: 13:01:44 cycles:  589770 offset:  2000\n",
      "procesed images: 45  time: 13:01:45 cycles:  602876 offset:  4000\n",
      "procesed images: 46  time: 13:01:47 cycles:  615982 offset:  14000\n",
      "procesed images: 47  time: 13:01:47 cycles:  629088 offset:  16000\n",
      "procesed images: 48  time: 13:01:49 cycles:  642194 offset:  10000\n",
      "procesed images: 49  time: 13:01:50 cycles:  655300 offset:  12000\n",
      "procesed images: 50  time: 13:01:52 cycles:  668406 offset:  6000\n",
      "procesed images: 51  time: 13:01:53 cycles:  681512 offset:  8000\n",
      "procesed images: 52  time: 13:01:55 cycles:  694618 offset:  2000\n",
      "procesed images: 53  time: 13:01:55 cycles:  707724 offset:  4000\n",
      "procesed images: 54  time: 13:01:57 cycles:  720830 offset:  14000\n",
      "procesed images: 55  time: 13:01:58 cycles:  733936 offset:  16000\n",
      "procesed images: 56  time: 13:02:00 cycles:  747042 offset:  10000\n",
      "procesed images: 57  time: 13:02:01 cycles:  760148 offset:  12000\n",
      "procesed images: 58  time: 13:02:03 cycles:  773254 offset:  6000\n",
      "procesed images: 59  time: 13:02:04 cycles:  786360 offset:  8000\n",
      "procesed images: 60  time: 13:02:06 cycles:  799466 offset:  2000\n",
      "procesed images: 61  time: 13:02:06 cycles:  812572 offset:  4000\n",
      "procesed images: 62  time: 13:02:08 cycles:  825678 offset:  14000\n",
      "procesed images: 63  time: 13:02:09 cycles:  838784 offset:  16000\n",
      "procesed images: 64  time: 13:02:11 cycles:  851890 offset:  10000\n",
      "procesed images: 65  time: 13:02:12 cycles:  864996 offset:  12000\n",
      "procesed images: 66  time: 13:02:14 cycles:  878102 offset:  6000\n",
      "procesed images: 67  time: 13:02:14 cycles:  891208 offset:  8000\n",
      "procesed images: 68  time: 13:02:16 cycles:  904314 offset:  2000\n",
      "procesed images: 69  time: 13:02:17 cycles:  917420 offset:  4000\n",
      "procesed images: 70  time: 13:02:19 cycles:  930526 offset:  14000\n",
      "procesed images: 71  time: 13:02:20 cycles:  943632 offset:  16000\n",
      "procesed images: 72  time: 13:02:22 cycles:  956738 offset:  10000\n",
      "procesed images: 73  time: 13:02:23 cycles:  969844 offset:  12000\n",
      "procesed images: 74  time: 13:02:25 cycles:  982950 offset:  6000\n",
      "procesed images: 75  time: 13:02:25 cycles:  996056 offset:  8000\n",
      "procesed images: 76  time: 13:02:27 cycles:  1009162 offset:  2000\n",
      "procesed images: 77  time: 13:02:28 cycles:  1022268 offset:  4000\n",
      "procesed images: 78  time: 13:02:30 cycles:  1035374 offset:  14000\n",
      "procesed images: 79  time: 13:02:31 cycles:  1048480 offset:  16000\n",
      "procesed images: 80  time: 13:02:33 cycles:  1061586 offset:  10000\n",
      "procesed images: 81  time: 13:02:33 cycles:  1074692 offset:  12000\n",
      "procesed images: 82  time: 13:02:35 cycles:  1087798 offset:  6000\n",
      "procesed images: 83  time: 13:02:36 cycles:  1100904 offset:  8000\n",
      "procesed images: 84  time: 13:02:38 cycles:  1114010 offset:  2000\n",
      "procesed images: 85  time: 13:02:39 cycles:  1127116 offset:  4000\n",
      "procesed images: 86  time: 13:02:41 cycles:  1140222 offset:  14000\n",
      "procesed images: 87  time: 13:02:41 cycles:  1153328 offset:  16000\n",
      "procesed images: 88  time: 13:02:43 cycles:  1166434 offset:  10000\n",
      "procesed images: 89  time: 13:02:44 cycles:  1179540 offset:  12000\n",
      "procesed images: 90  time: 13:02:46 cycles:  1192646 offset:  6000\n",
      "procesed images: 91  time: 13:02:47 cycles:  1205752 offset:  8000\n",
      "procesed images: 92  time: 13:02:49 cycles:  1218858 offset:  2000\n",
      "procesed images: 93  time: 13:02:49 cycles:  1231964 offset:  4000\n",
      "procesed images: 94  time: 13:02:51 cycles:  1245070 offset:  14000\n",
      "procesed images: 95  time: 13:02:52 cycles:  1258176 offset:  16000\n",
      "procesed images: 96  time: 13:02:54 cycles:  1271282 offset:  10000\n",
      "procesed images: 97  time: 13:02:55 cycles:  1284388 offset:  12000\n",
      "procesed images: 98  time: 13:02:57 cycles:  1297494 offset:  6000\n",
      "procesed images: 99  time: 13:02:58 cycles:  1310600 offset:  8000\n",
      "procesed images: 100  time: 13:03:00 cycles:  1323706 offset:  2000\n",
      "procesed images: 101  time: 13:03:00 cycles:  1336812 offset:  4000\n",
      "procesed images: 102  time: 13:03:02 cycles:  1349918 offset:  14000\n",
      "procesed images: 103  time: 13:03:03 cycles:  1363024 offset:  16000\n",
      "procesed images: 104  time: 13:03:05 cycles:  1376130 offset:  10000\n",
      "procesed images: 105  time: 13:03:06 cycles:  1389236 offset:  12000\n",
      "procesed images: 106  time: 13:03:08 cycles:  1402342 offset:  6000\n",
      "procesed images: 107  time: 13:03:08 cycles:  1415448 offset:  8000\n",
      "procesed images: 108  time: 13:03:10 cycles:  1428554 offset:  2000\n",
      "procesed images: 109  time: 13:03:11 cycles:  1441660 offset:  4000\n",
      "procesed images: 110  time: 13:03:13 cycles:  1454766 offset:  14000\n",
      "procesed images: 111  time: 13:03:14 cycles:  1467872 offset:  16000\n",
      "procesed images: 112  time: 13:03:16 cycles:  1480978 offset:  10000\n",
      "procesed images: 113  time: 13:03:16 cycles:  1494084 offset:  12000\n",
      "procesed images: 114  time: 13:03:18 cycles:  1507190 offset:  6000\n",
      "procesed images: 115  time: 13:03:19 cycles:  1520296 offset:  8000\n",
      "procesed images: 116  time: 13:03:21 cycles:  1533402 offset:  2000\n",
      "procesed images: 117  time: 13:03:22 cycles:  1546508 offset:  4000\n",
      "procesed images: 118  time: 13:03:24 cycles:  1559614 offset:  14000\n",
      "procesed images: 119  time: 13:03:25 cycles:  1572720 offset:  16000\n",
      "procesed images: 120  time: 13:03:27 cycles:  1585826 offset:  10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesed images: 121  time: 13:03:27 cycles:  1598932 offset:  12000\n",
      "procesed images: 122  time: 13:03:29 cycles:  1612038 offset:  6000\n",
      "procesed images: 123  time: 13:03:30 cycles:  1625144 offset:  8000\n",
      "procesed images: 124  time: 13:03:32 cycles:  1638250 offset:  2000\n",
      "procesed images: 125  time: 13:03:33 cycles:  1651356 offset:  4000\n",
      "procesed images: 126  time: 13:03:35 cycles:  1664462 offset:  14000\n",
      "procesed images: 127  time: 13:03:35 cycles:  1677568 offset:  16000\n",
      "procesed images: 128  time: 13:03:37 cycles:  1690674 offset:  10000\n",
      "procesed images: 129  time: 13:03:38 cycles:  1703780 offset:  12000\n",
      "procesed images: 130  time: 13:03:40 cycles:  1716886 offset:  6000\n",
      "procesed images: 131  time: 13:03:41 cycles:  1729992 offset:  8000\n",
      "procesed images: 132  time: 13:03:43 cycles:  1743098 offset:  2000\n",
      "procesed images: 133  time: 13:03:44 cycles:  1756204 offset:  4000\n",
      "procesed images: 134  time: 13:03:46 cycles:  1769310 offset:  14000\n",
      "procesed images: 135  time: 13:03:46 cycles:  1782416 offset:  16000\n",
      "procesed images: 136  time: 13:03:48 cycles:  1795522 offset:  10000\n",
      "procesed images: 137  time: 13:03:49 cycles:  1808628 offset:  12000\n",
      "procesed images: 138  time: 13:03:51 cycles:  1821734 offset:  6000\n",
      "procesed images: 139  time: 13:03:52 cycles:  1834840 offset:  8000\n",
      "procesed images: 140  time: 13:03:54 cycles:  1847946 offset:  2000\n",
      "procesed images: 141  time: 13:03:54 cycles:  1861052 offset:  4000\n",
      "procesed images: 142  time: 13:03:56 cycles:  1874158 offset:  14000\n",
      "procesed images: 143  time: 13:03:57 cycles:  1887264 offset:  16000\n",
      "procesed images: 144  time: 13:03:59 cycles:  1900370 offset:  10000\n",
      "procesed images: 145  time: 13:04:00 cycles:  1913476 offset:  12000\n",
      "procesed images: 146  time: 13:04:02 cycles:  1926582 offset:  6000\n",
      "procesed images: 147  time: 13:04:03 cycles:  1939688 offset:  8000\n",
      "procesed images: 148  time: 13:04:05 cycles:  1952794 offset:  2000\n",
      "procesed images: 149  time: 13:04:05 cycles:  1965900 offset:  4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'Number of Addresses': 16000,\n",
       "  'Data': array([2, 2, 2, ..., 2, 2, 2], dtype=int8),\n",
       "  'HighCyclesCount': array([304464,  42996,  47890, ..., 244240, 197748, 394506], dtype=uint32),\n",
       "  'OffCyclesCount': array([989076, 989076, 989076, ..., 845292, 845292, 845292], dtype=uint32),\n",
       "  'LowCyclesCount': array([672360, 933828, 928934, ..., 876368, 922860, 726102], dtype=uint32),\n",
       "  'Flips': array([126,  89,  94, ...,  98, 105, 125], dtype=uint32),\n",
       "  'offset': 4000},\n",
       " 1965900)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainBatchSize = testBatchSize = 1\n",
    "_,_,testSet = GetIMBDDataset(train_batch_size=1, test_batch_size=1)\n",
    "\n",
    "QSentimentalNet  = GetNeuralNetworkModel('SentimentalNet',(500),1,quantization = True, aging=False,wordSize = 16, fracSize = 15)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "QSentimentalNet.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "QSentimentalNet.load_weights(wgtDir).expect_partial()\n",
    "WeightQuantization(model = QSentimentalNet, fracBits = 15, intBits = 0)\n",
    "\n",
    "\n",
    "LI = [1,4,8,12,16]\n",
    "AI = [3,7,10,15,19]\n",
    "buffer_simulation(QSentimentalNet,testSet, integer_bits = 0, fractional_bits = 15, samples = 150, start_from = 0,\n",
    "                 bit_invertion = False, bit_shifting = False, CNN_gating = True, write_mode ='default',\n",
    "                 results_dir = 'Data/Stats/SentimentalNet/IMDB Reviews Dataset/CNN-Gated/', buffer_size = 2*16000,\n",
    "                 layer_indexes = LI , activation_indixes = AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Error Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet,validSet,testSet = GetIMBDDataset(32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Measuring effect of errors by buffer,section,number of faults and bit localization of the fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from copy import deepcopy\n",
    "from Quantization_and_Errors import Check_Accuracy_and_Loss\n",
    "from Simulation import save_obj, load_obj\n",
    "from datetime import datetime\n",
    "\n",
    "Start_from_zero = False\n",
    "\n",
    "if Start_from_zero:\n",
    "    Accs     = {0.0001:[],0.0005:[],0.001:[],0.005:[],0.01:[]}\n",
    "    Loss     = {0.0001:[],0.0005:[],0.001:[],0.005:[],0.01:[]}\n",
    "else:\n",
    "    Accs     = load_obj('Data/Errors/SentimentalNet/IMDB Reviews Dataset/Accs')\n",
    "    Loss     = load_obj('Data/Errors/SentimentalNet/IMDB Reviews Dataset/Loss')\n",
    "    \n",
    "cell_modifications = list(itertools.product(['1', 'x','0'], repeat=16))\n",
    "possible_errors_under_8000 = [\"\".join(i) for i in cell_modifications]\n",
    "cell_modifications = list(itertools.product(['1', 'x','0'], repeat=5))\n",
    "possible_errors_above_8000 = ['x'+\"\".join(i)+'xxxxxxxxxx' for i in cell_modifications]\n",
    "\n",
    "\n",
    "Num_of_samples = 200\n",
    "for Enumber in Accs:\n",
    "    for index in range(0,Num_of_samples):\n",
    "        if index < Num_of_samples//2:\n",
    "            mask = [True,False,True,False]\n",
    "        else:\n",
    "            mask = [False,True,False,True]\n",
    "        number_of_errors = np.ceil(Enumber*8000).astype(int)\n",
    "        locs1      = np.random.choice(range(0,8000),number_of_errors,False)\n",
    "        Errortype1 = np.random.choice(possible_errors_under_8000, number_of_errors, True)\n",
    "        locs2      = np.random.choice(range(8000,16000),number_of_errors,False)\n",
    "        Errortype2 = np.random.choice(possible_errors_above_8000, number_of_errors, True)\n",
    "        locs       = np.concatenate([locs1,locs2])\n",
    "        Errortype  = np.concatenate([Errortype1,Errortype2])\n",
    "        acc,loss   = CheckAccuracyAndLoss('PilotNet', test_dataset, wgtDir, outputShape=1, inputShape = (500),\n",
    "                                            aFracSize = 14, aIntSize = 1, wFracSize = 15, wIntSize = 0,\n",
    "                                            batchSize=32, verbose = 0, aging = mask,\n",
    "                                            faultyAddresses = locs, maskedFaults = Errortype)\n",
    "        Accs[Enumber].append(acc)\n",
    "        Loss[Enumber].append(loss)\n",
    "        if index % 10 == 0:\n",
    "            print(index)\n",
    "    print(str(Enumber)+' completada: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    #save_obj(Accs,'Data/Errors/SentimentalNet/IMDB Reviews Dataset/Accs')\n",
    "    #save_obj(Loss,'Data/Errors/SentimentalNet/IMDB Reviews Dataset/Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_first",
   "language": "python",
   "name": "env_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
